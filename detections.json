{"detections": [{"name": "Abnormally High Number Of Cloud Infrastructure API Calls", "author": "David Dorsey, Splunk", "date": "2020-09-07", "version": 1, "id": "0840ddf1-8c89-46ff-b730-c8d6722478c0", "description": "This search will detect a spike in the number of API calls made to your cloud infrastructure environment by a user.", "tags": {"name": "Abnormally High Number Of Cloud Infrastructure API Calls", "analytic_story": ["Suspicious Cloud User Activities", "Compromised User Account"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "user $user$ has made $api_calls$ api calls, violating the dynamic threshold of $expected_upper_threshold$ with the following command $command$.", "risk_score": 15, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats count as api_calls values(All_Changes.command) as command from datamodel=Change where All_Changes.user!=unknown All_Changes.status=success by All_Changes.user _time span=1h | `drop_dm_object_name(\"All_Changes\")` | eval HourOfDay=strftime(_time, \"%H\") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, \"%w\") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join user HourOfDay isWeekend [ summary cloud_excessive_api_calls_v1] | where cardinality >=16 | apply cloud_excessive_api_calls_v1 threshold=0.005 | rename \"IsOutlier(api_calls)\" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), \":\"), 0) | where api_calls > expected_upper_threshold | eval distance_from_threshold = api_calls - expected_upper_threshold | table _time, user, command, api_calls, expected_upper_threshold, distance_from_threshold | `abnormally_high_number_of_cloud_infrastructure_api_calls_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Infrastructure API Calls Per User` to create the probability density function.", "known_false_positives": "", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "abnormally_high_number_of_cloud_infrastructure_api_calls_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Abnormally High Number Of Cloud Infrastructure API Calls:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Abnormally High Number Of Cloud Instances Destroyed", "author": "David Dorsey, Splunk", "date": "2020-08-21", "version": 1, "id": "ef629fc9-1583-4590-b62a-f2247fbf7bbf", "description": "This search finds for the number successfully destroyed cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.", "tags": {"name": "Abnormally High Number Of Cloud Instances Destroyed", "analytic_story": ["Suspicious Cloud Instance Activities"], "asset_type": "Cloud Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "dest", "type": "Hostname", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "Cloud", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats count as instances_destroyed values(All_Changes.object_id) as object_id from datamodel=Change where All_Changes.action=deleted AND All_Changes.status=success AND All_Changes.object_category=instance by All_Changes.user _time span=1h | `drop_dm_object_name(\"All_Changes\")` | eval HourOfDay=strftime(_time, \"%H\") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, \"%w\") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join HourOfDay isWeekend [summary cloud_excessive_instances_destroyed_v1] | where cardinality >=16 | apply cloud_excessive_instances_destroyed_v1 threshold=0.005 | rename \"IsOutlier(instances_destroyed)\" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), \":\"), 0) | eval distance_from_threshold = instances_destroyed - expected_upper_threshold | table _time, user, instances_destroyed, expected_upper_threshold, distance_from_threshold, object_id | `abnormally_high_number_of_cloud_instances_destroyed_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Instances Destroyed` to create the probability density function.", "known_false_positives": "Many service accounts configured within a cloud infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "abnormally_high_number_of_cloud_instances_destroyed_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "Abnormally High Number Of Cloud Instances Launched", "author": "David Dorsey, Splunk", "date": "2020-08-21", "version": 2, "id": "f2361e9f-3928-496c-a556-120cd4223a65", "description": "This search finds for the number successfully created cloud instances for every 4 hour block. This is split up between weekdays and the weekend. It then applies the probability densitiy model previously created and alerts on any outliers.", "tags": {"name": "Abnormally High Number Of Cloud Instances Launched", "analytic_story": ["Cloud Cryptomining", "Suspicious Cloud Instance Activities"], "asset_type": "Cloud Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "Cloud", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats count as instances_launched values(All_Changes.object_id) as object_id from datamodel=Change where (All_Changes.action=created) AND All_Changes.status=success AND All_Changes.object_category=instance by All_Changes.user _time span=1h | `drop_dm_object_name(\"All_Changes\")` | eval HourOfDay=strftime(_time, \"%H\") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, \"%w\") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join HourOfDay isWeekend [summary cloud_excessive_instances_created_v1] | where cardinality >=16 | apply cloud_excessive_instances_created_v1 threshold=0.005 | rename \"IsOutlier(instances_launched)\" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), \":\"), 0) | eval distance_from_threshold = instances_launched - expected_upper_threshold | table _time, user, instances_launched, expected_upper_threshold, distance_from_threshold, object_id | `abnormally_high_number_of_cloud_instances_launched_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Instances Launched` to create the probability density function.", "known_false_positives": "Many service accounts configured within an AWS infrastructure are known to exhibit this behavior. Please adjust the threshold values and filter out service accounts from the output. Always verify if this search alerted on a human user.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "abnormally_high_number_of_cloud_instances_launched_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "Abnormally High Number Of Cloud Security Group API Calls", "author": "David Dorsey, Splunk", "date": "2020-09-07", "version": 1, "id": "d4dfb7f3-7a37-498a-b5df-f19334e871af", "description": "This search will detect a spike in the number of API calls made to your cloud infrastructure environment about security groups by a user.", "tags": {"name": "Abnormally High Number Of Cloud Security Group API Calls", "analytic_story": ["Suspicious Cloud User Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "user $user$ has made $api_calls$ api calls related to security groups, violating the dynamic threshold of $expected_upper_threshold$ with the following command $command$.", "risk_score": 15, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats count as security_group_api_calls values(All_Changes.command) as command from datamodel=Change where All_Changes.object_category=firewall AND All_Changes.status=success by All_Changes.user _time span=1h | `drop_dm_object_name(\"All_Changes\")` | eval HourOfDay=strftime(_time, \"%H\") | eval HourOfDay=floor(HourOfDay/4)*4 | eval DayOfWeek=strftime(_time, \"%w\") | eval isWeekend=if(DayOfWeek >= 1 AND DayOfWeek <= 5, 0, 1) | join user HourOfDay isWeekend [ summary cloud_excessive_security_group_api_calls_v1] | where cardinality >=16 | apply cloud_excessive_security_group_api_calls_v1 threshold=0.005 | rename \"IsOutlier(security_group_api_calls)\" as isOutlier | where isOutlier=1 | eval expected_upper_threshold = mvindex(split(mvindex(BoundaryRanges, -1), \":\"), 0) | where security_group_api_calls > expected_upper_threshold | eval distance_from_threshold = security_group_api_calls - expected_upper_threshold | table _time, user, command, security_group_api_calls, expected_upper_threshold, distance_from_threshold | `abnormally_high_number_of_cloud_security_group_api_calls_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs. You also must run the baseline search `Baseline Of Cloud Security Group API Calls Per User` to create the probability density function model.", "known_false_positives": "", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "abnormally_high_number_of_cloud_security_group_api_calls_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Abnormally High Number Of Cloud Security Group API Calls:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Amazon EKS Kubernetes cluster scan detection", "author": "Rod Soto, Splunk", "date": "2020-04-15", "version": 1, "id": "294c4686-63dd-4fe6-93a2-ca807626704a", "description": "This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster in AWS", "tags": {"name": "Amazon EKS Kubernetes cluster scan detection", "analytic_story": ["Kubernetes Scanning Activity"], "asset_type": "Amazon EKS Kubernetes cluster", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_cloudwatchlogs_eks` \"user.username\"=\"system:anonymous\" userAgent!=\"AWS Security Scanner\" | rename sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(responseStatus.reason) values(source) as cluster_name values(responseStatus.code) values(userAgent) as http_user_agent values(verb) values(requestURI) by src_ip user.username user.groups{} | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` |`amazon_eks_kubernetes_cluster_scan_detection_filter` ", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your CloudWatch EKS Logs inputs.", "known_false_positives": "Not all unauthenticated requests are malicious, but frequency, UA and source IPs will provide context.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_cloudwatchlogs_eks", "definition": "sourcetype=\"aws:cloudwatchlogs:eks\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "amazon_eks_kubernetes_cluster_scan_detection_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "Amazon EKS Kubernetes Pod scan detection", "author": "Rod Soto, Splunk", "date": "2020-04-15", "version": 1, "id": "dbfca1dd-b8e5-4ba4-be0e-e565e5d62002", "description": "The following analytic detects unauthenticated requests made against the Kubernetes' Pods API through proactive monitoring to protect the Kubernetes environment from unauthorized access and potential security breaches. The detection is made by using the Splunk query `aws_cloudwatchlogs_eks` with specific filters to identify these requests. Identifies events where the `user.username` is set to \"system:anonymous\", the `verb` is set to \"list\", and the `objectRef.resource` is set to \"pods\". Additionally, the search checks if the `requestURI` is equal to \"/api/v1/pods\". Analyzing these events helps you to identify any unauthorized access attempts to the Kubernetes' Pods API. Unauthenticated requests can indicate potential security breaches or unauthorized access to sensitive resources within the Kubernetes environment. The detection is important because unauthorized access to Kubernetes' Pods API can lead to the compromise of sensitive data, unauthorized execution of commands, or even the potential for lateral movement within the Kubernetes cluster. False positives might occur since there might be legitimate use cases for unauthenticated requests in certain scenarios. Therefore, you must review and validate any detected events before taking any action.  Next steps include investigating the incident to mitigate any ongoing threats, and strengthening the security measures to prevent future unauthorized access attempts.", "tags": {"name": "Amazon EKS Kubernetes Pod scan detection", "analytic_story": ["Kubernetes Scanning Activity"], "asset_type": "Amazon EKS Kubernetes cluster Pod", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_cloudwatchlogs_eks` \"user.username\"=\"system:anonymous\" verb=list objectRef.resource=pods requestURI=\"/api/v1/pods\" | rename source as cluster_name sourceIPs{} as src_ip | stats count min(_time) as firstTime max(_time) as lastTime values(responseStatus.reason) values(responseStatus.code) values(userAgent) values(verb) values(requestURI) by src_ip cluster_name user.username user.groups{} | `security_content_ctime(lastTime)` | `security_content_ctime(firstTime)` | `amazon_eks_kubernetes_pod_scan_detection_filter` ", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on forAWS (version 4.4.0 or later), then configure your AWS CloudWatch EKS Logs.Please also customize the `kubernetes_pods_aws_scan_fingerprint_detection` macro to filter out the false positives.", "known_false_positives": "Not all unauthenticated requests are malicious, but frequency, UA and source IPs and direct request to API provide context.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_cloudwatchlogs_eks", "definition": "sourcetype=\"aws:cloudwatchlogs:eks\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "amazon_eks_kubernetes_pod_scan_detection_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "ASL AWS Concurrent Sessions From Different Ips", "author": "Patrick Bareiss, Splunk", "date": "2023-05-23", "version": 1, "id": "b3424bbe-3204-4469-887b-ec144483a336", "description": "The following analytic identifies an AWS IAM account with concurrent sessions coming from more than one unique IP address within the span of 5 minutes. This behavior could represent a session hijacking attack whereby an adversary has extracted cookies from a victims browser and is using them from a different location to access corporate online resources. When a user navigates the AWS Console after authentication, the API call with the event name `DescribeEventAggregates` is registered in the AWS CloudTrail logs. The Splunk Threat Research team leveraged this event name to identify 2 concurrent sessions. The presence of this event occurring from two different IP addresses is highly unlikely. As users may behave differently across organizations, security teams should test and customize this detection to fit their environments.", "tags": {"name": "ASL AWS Concurrent Sessions From Different Ips", "analytic_story": ["Compromised User Account", "AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1185"], "nist": ["DE.AE"], "observable": [{"name": "identity.user.credential_uid", "type": "User", "role": ["Victim"]}, {"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $identity.user.name$ has concurrent sessions from more than one unique IP address $src_endpoint.ip$ in the span of 5 minutes.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `amazon_security_lake` api.operation=DescribeEventAggregates src_endpoint.domain!=\"AWS Internal\" | bin span=5m _time | stats values(src_endpoint.ip) as src_endpoint.ip dc(src_endpoint.ip) as distinct_ip_count by _time identity.user.credential_uid identity.user.name | where distinct_ip_count > 1 | `aws_concurrent_sessions_from_different_ips_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "A user with concurrent sessions from different Ips may also represent the legitimate use of more than one device. Filter as needed and/or customize the threshold to fit your environment.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1185/", "https://breakdev.org/evilginx-2-next-generation-of-phishing-2fa-tokens/", "https://github.com/kgretzky/evilginx2"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "asl_aws_concurrent_sessions_from_different_ips_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": []}, {"name": "ASL AWS CreateAccessKey", "author": "Patrick Bareiss, Splunk", "date": "2022-05-23", "version": 1, "id": "ccb3e4af-23d6-407f-9842-a26212816c9e", "description": "This detection rule monitors for the creation of AWS Identity and Access Management (IAM) access keys. An IAM access key consists of an access key ID and secret access key, which are used to sign programmatic requests to AWS services. While IAM access keys can be legitimately used by developers and administrators for API access, their creation can also be indicative of malicious activity. Attackers who have gained unauthorized access to an AWS environment might create access keys as a means to establish persistence or to exfiltrate data through the APIs. Moreover, because access keys can be used to authenticate with AWS services without the need for further interaction, they can be particularly appealing for bad actors looking to operate under the radar. Consequently, it's important to vigilantly monitor and scrutinize access key creation events, especially if they are associated with unusual activity or are created by users who don't typically perform these actions. This hunting query identifies when a potentially compromised user creates a IAM access key for another user who may have higher privilleges, which can be a sign for privilege escalation. Hunting queries are designed to be executed manual during threat hunting.", "tags": {"name": "ASL AWS CreateAccessKey", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Attacker"]}], "message": "User $responseElements.accessKey.userName$ is attempting to create access keys for $responseElements.accessKey.userName$ from this IP $src_endpoint.ip$", "risk_score": 63, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` api.operation=CreateAccessKey http_request.user_agent!=console.amazonaws.com api.response.error=null | rename unmapped{}.key as unmapped_key , unmapped{}.value as unmapped_value | eval keyjoin=mvzip(unmapped_key,unmapped_value) | mvexpand keyjoin | rex field=keyjoin \"^(?<key>[^,]+),(?<value>.*)$\" | eval {key} = value | search responseElements.accessKey.userName = * | rename identity.user.name as identity_user_name, responseElements.accessKey.userName as responseElements_accessKey_userName | eval match=if(identity_user_name=responseElements_accessKey_userName,1,0) | search match=0 | rename identity_user_name as identity.user.name , responseElements_accessKey_userName as responseElements.accessKey.userName | stats count min(_time) as firstTime max(_time) as lastTime by responseElements.accessKey.userName api.operation api.service.name identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |`asl_aws_createaccesskey_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.", "check_references": false, "references": ["https://bishopfox.com/blog/privilege-escalation-in-aws", "https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation-part-2/"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_createaccesskey_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS CreateAccessKey:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "ASL AWS Defense Evasion Delete Cloudtrail", "author": "Patrick Bareiss, Splunk", "date": "2023-05-31", "version": 1, "id": "1f0b47e5-0134-43eb-851c-e3258638945e", "description": "This analytic identifies AWS `DeleteTrail` events within CloudTrail logs. Adversaries often try to impair their target's defenses by stopping their malicious activity from being logged, so that they may operate with stealth and avoid detection. When the adversary has the right type of permissions in the compromised AWS environment, they may delete the the entire cloudtrail that is logging activities in the environment.", "tags": {"name": "ASL AWS Defense Evasion Delete Cloudtrail", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.008", "T1562"], "nist": ["DE.CM"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Victim"]}], "message": "User $identity.user.name$ has delete a CloudTrail logging for account id $identity.user.account_uid$", "risk_score": 90, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` api.operation=DeleteTrail | stats count min(_time) as firstTime max(_time) as lastTime by identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `asl_aws_defense_evasion_delete_cloudtrail_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has stopped cloudTrail logging. Please investigate this activity.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_defense_evasion_delete_cloudtrail_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS Defense Evasion Delete Cloudtrail:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/stop_delete_cloudtrail/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/stop_delete_cloudtrail/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl"}]}]}, {"name": "ASL AWS Defense Evasion Delete CloudWatch Log Group", "author": "Patrick Bareiss, Splunk", "date": "2023-05-31", "version": 1, "id": "0f701b38-a0fb-43fd-a83d-d12265f71f33", "description": "This analytic identifies AWS `DeleteLogGroup` events in CloudTrail logs. Attackers may evade the logging capability by deleting the log group in CloudWatch. This will stop sending the logs and metrics to CloudWatch. When the adversary has the right type of permissions within the compromised AWS environment, they may delete the CloudWatch log group that is logging activities in the environment.", "tags": {"name": "ASL AWS Defense Evasion Delete CloudWatch Log Group", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562", "T1562.008"], "nist": ["DE.CM"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Victim"]}], "message": "User $identity.user.name$ has deleted a CloudWatch logging group for account id $identity.user.account_uid$", "risk_score": 90, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` api.operation=DeleteLogGroup | stats count min(_time) as firstTime max(_time) as lastTime by identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `asl_aws_defense_evasion_delete_cloudwatch_log_group_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has deleted CloudWatch logging. Please investigate this activity.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_defense_evasion_delete_cloudwatch_log_group_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS Defense Evasion Delete CloudWatch Log Group:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/delete_cloudwatch_log_group/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/delete_cloudwatch_log_group/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "ASL AWS Defense Evasion Impair Security Services", "author": "Patrick Bareiss, Bhavin Patel, Gowthamaraj Rajendran, Splunk", "date": "2023-06-01", "version": 1, "id": "5029b681-0462-47b7-82e7-f7e3d37f5a2d", "description": "This analytic looks for several delete specific API calls made to AWS Security Services like CloudWatch, GuardDuty and Web Application Firewalls. These API calls are often leveraged by adversaries to weaken existing security defenses by deleting logging configurations in the CloudWatch alarm, delete a set of detectors from your Guardduty environment or simply delete a bunch of CloudWatch alarms to remain stealthy and avoid detection.", "tags": {"name": "ASL AWS Defense Evasion Impair Security Services", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.008", "T1562"], "nist": ["DE.AE"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Attacker"]}], "message": "User $identity.user.name$ has made potentially risky api calls $api.operation$ that could impair AWS security services for account id $identity.user.account_uid$", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` api.operation IN (\"DeleteLogStream\",\"DeleteDetector\",\"DeleteIPSet\",\"DeleteWebACL\",\"DeleteRule\",\"DeleteRuleGroup\",\"DeleteLoggingConfiguration\",\"DeleteAlarms\") | stats count min(_time) as firstTime max(_time) as lastTime by api.operation identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|  `asl_aws_defense_evasion_impair_security_services_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "While this search has no known false positives, it is possible that it is a legitimate admin activity. Please consider filtering out these noisy events using userAgent, user_arn field names.", "check_references": false, "references": ["https://docs.aws.amazon.com/cli/latest/reference/guardduty/index.html", "https://docs.aws.amazon.com/cli/latest/reference/waf/index.html", "https://www.elastic.co/guide/en/security/current/prebuilt-rules.html"], "datamodel": ["Web"], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_defense_evasion_impair_security_services_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS Defense Evasion Impair Security Services:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/aws_delete_security_services/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/aws_delete_security_services/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "ASL AWS Excessive Security Scanning", "author": "Patrick Bareiss, Splunk", "date": "2023-06-01", "version": 1, "id": "ff2bfdbc-65b7-4434-8f08-d55761d1d446", "description": "This search looks for AWS CloudTrail events and analyse the amount of eventNames which starts with Describe by a single user. This indicates that this user scans the configuration of your AWS cloud environment.", "tags": {"name": "ASL AWS Excessive Security Scanning", "analytic_story": ["AWS User Monitoring"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.AE"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Attacker"]}], "message": "user $identity.user.name$ has excessive number of api calls.", "risk_score": 18, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` api.operation=Describe* OR api.operation=List* OR api.operation=Get* | stats dc(api.operation) as dc_api_operations min(_time) as firstTime max(_time) as lastTime values(http_request.user_agent) as http_request.user_agent values(src_endpoint.ip) as src_endpoint.ip values(cloud.region) as cloud.region values(identity.user.account_uid) as identity.user.account_uid by identity.user.name | where dc_api_operations > 50 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`asl_aws_excessive_security_scanning_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "While this search has no known false positives.", "check_references": false, "references": ["https://github.com/aquasecurity/cloudsploit"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_excessive_security_scanning_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": []}, {"name": "ASL AWS IAM Delete Policy", "author": "Patrick Bareiss, Splunk", "date": "2023-06-02", "version": 1, "id": "609ced68-d420-4ff7-8164-ae98b4b4018c", "description": "The following detection identifes when a policy is deleted on AWS. This does not identify whether successful or failed, but the error messages tell a story of suspicious attempts. There is a specific process to follow when deleting a policy. First, detach the policy from all users, groups, and roles that the policy is attached to, using DetachUserPolicy , DetachGroupPolicy , or DetachRolePolicy.", "tags": {"name": "ASL AWS IAM Delete Policy", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.AE"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has deleted AWS Policies from IP address $src$ by executing the following command $eventName$", "risk_score": 10, "security_domain": "access", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` api.operation=DeletePolicy | stats count min(_time) as firstTime max(_time) as lastTime by api.operation api.service.name identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `asl_aws_iam_delete_policy_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "This detection will require tuning to provide high fidelity detection capabilties. Tune based on src addresses (corporate offices, VPN terminations) or by groups of users. Not every user with AWS access should have permission to delete policies (least privilege). In addition, this may be saved seperately and tuned for failed or success attempts only.", "check_references": false, "references": ["https://docs.aws.amazon.com/IAM/latest/APIReference/API_DeletePolicy.html", "https://docs.aws.amazon.com/cli/latest/reference/iam/delete-policy.html"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_iam_delete_policy_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS IAM Delete Policy:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_delete_policy/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_delete_policy/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "ASL AWS Multi-Factor Authentication Disabled", "author": "Patrick Bareiss, Splunk", "date": "2023-06-02", "version": 1, "id": "4d2df5e0-1092-4817-88a8-79c7fa054668", "description": "The following analytic identifies an attempt to disable multi-factor authentication for an AWS IAM user. An adversary who has obtained access to an AWS tenant may disable multi-factor authentication as a way to plant a backdoor and maintain persistence using a valid account. This way the attackers can keep persistance in the environment without adding new users.", "tags": {"name": "ASL AWS Multi-Factor Authentication Disabled", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1621", "T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "identity.user.account_uid", "type": "Other", "role": ["Victim"]}, {"name": "identity.user.name", "type": "User", "role": ["Victim"]}, {"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user_name$ has disabled Multi-Factor authentication for AWS account $aws_account_id$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` (api.operation=DeleteVirtualMFADevice OR api.operation=DeactivateMFADevice) | stats count min(_time) as firstTime max(_time) as lastTime by api.operation api.service.name identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `asl_aws_multi_factor_authentication_disabled_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "AWS Administrators may disable MFA but it is highly unlikely for this event to occur without prior notice to the company", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://aws.amazon.com/what-is/mfa/"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_multi_factor_authentication_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS Multi-Factor Authentication Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_mfa_disabled/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_mfa_disabled/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "ASL AWS New MFA Method Registered For User", "author": "Patrick Bareiss, Splunk", "date": "2023-05-22", "version": 1, "id": "33ae0931-2a03-456b-b1d7-b016c5557fbd", "description": "The following analytic identifies the registration of a new Multi Factor authentication method for an AWS account logged through Amazon Secruity Lake (ASL). Adversaries who have obtained unauthorized access to an AWS account may register a new MFA method to maintain persistence.", "tags": {"name": "ASL AWS New MFA Method Registered For User", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "identity.user.name", "type": "User", "role": ["Victim"]}, {"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}], "message": "A new virtual device is added to user $identity.user.name$", "risk_score": 64, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `amazon_security_lake` api.operation=CreateVirtualMFADevice | stats count min(_time) as firstTime max(_time) as lastTime by api.operation api.service.name identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `asl_aws_new_mfa_method_registered_for_user_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "Newly onboarded users who are registering an MFA method for the first time will also trigger this detection.", "check_references": false, "references": ["https://aws.amazon.com/blogs/security/you-can-now-assign-multiple-mfa-devices-in-iam/", "https://attack.mitre.org/techniques/T1556/", "https://attack.mitre.org/techniques/T1556/006/", "https://twitter.com/jhencinski/status/1618660062352007174"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_new_mfa_method_registered_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS New MFA Method Registered For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556.006/aws_new_mfa_method_registered_for_user/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556.006/aws_new_mfa_method_registered_for_user/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "ASL AWS Password Policy Changes", "author": "Patrick Bareiss, Splunk", "date": "2023-05-22", "version": 1, "id": "5ade5937-11a2-4363-ba6b-39a3ee8d5b1a", "description": "This search looks for AWS CloudTrail events from Amazon Security Lake where a user is making successful API calls to view/update/delete the existing password policy in an AWS organization. It is unlikely for a regular user to conduct this operation. These events may potentially be malicious, adversaries often use this information to gain more understanding of the password defenses in place and exploit them to increase their attack surface when a user account is compromised.", "tags": {"name": "ASL AWS Password Policy Changes", "analytic_story": ["AWS IAM Privilege Escalation", "Compromised User Account"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1201"], "nist": ["DE.AE"], "observable": [{"name": "src_endpoint.ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "identity.user.name", "type": "User", "role": ["Attacker"]}], "message": "User $identity.user.name$ is attempting to $api.operation$ the password policy for accounts", "risk_score": 72, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`amazon_security_lake` \"api.service.name\"=\"iam.amazonaws.com\" \"api.operation\" IN (\"UpdateAccountPasswordPolicy\",\"GetAccountPasswordPolicy\",\"DeleteAccountPasswordPolicy\") \"api.response.error\"=null | stats count min(_time) as firstTime max(_time) as lastTime by identity.user.account_uid identity.user.credential_uid identity.user.name identity.user.type identity.user.uid identity.user.uuid http_request.user_agent src_endpoint.ip cloud.region | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `asl_aws_password_policy_changes_filter`", "how_to_implement": "You must install Splunk Add-On for AWS Version v7.0.0 (https://splunkbase.splunk.com/app/1876) that includes includes a merge of all the capabilities of the Splunk Add-on for Amazon Security Lake. This search works with Amazon Security Lake logs which are parsed in the Open Cybersecurity Schema Framework (OCSF)format.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately triggered an AWS audit tool activity which may trigger this event.", "check_references": false, "references": ["https://www.trendmicro.com/cloudoneconformity/knowledge-base/aws/IAM/password-policy.html"], "datamodel": [], "macros": [{"name": "amazon_security_lake", "definition": "sourcetype=aws:asl", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "asl_aws_password_policy_changes_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Security Lake"], "enabled_by_default": false, "test_groups": [{"name": "ASL AWS Password Policy Changes:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1201/aws_password_policy/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1201/aws_password_policy/amazon_security_lake.json", "source": "aws_asl", "sourcetype": "aws:asl", "update_timestamp": true}]}]}, {"name": "AWS AMI Attribute Modification for Exfiltration", "author": "Bhavin Patel, Splunk", "date": "2023-03-31", "version": 2, "id": "f2132d74-cf81-4c5e-8799-ab069e67dc9f", "description": "This search looks for suspicious AWS AMI attribute modifications, such as sharing it with another AWS account or making the full AMI image public. Adversaries are known to abuse these APIs to exfiltrate sensitive organization information stored in the AWS Resources, there by its very important to monitor these seemingly benign API activity in Cloudtrail logs.", "tags": {"name": "AWS AMI Attribute Modification for Exfiltration", "analytic_story": ["Suspicious Cloud Instance Activities", "Data Exfiltration"], "asset_type": "EC2 Snapshot", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1537"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "AWS AMI from account $aws_account_id$ is shared externally with $accounts_added$ from $src_ip$ or AMI made is made Public.", "risk_score": 80, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=ModifyImageAttribute (requestParameters.launchPermission.add.items{}.userId = * OR requestParameters.launchPermission.add.items{}.group = all) |  rename requestParameters.launchPermission.add.items{}.group as group_added |  rename requestParameters.launchPermission.add.items{}.userId as accounts_added | eval ami_status=if(match(group_added,\"all\") ,\"Public AMI\", \"Not Public\")  | stats count min(_time) as firstTime max(_time) as lastTime  values(group_added) values(accounts_added) as accounts_added values(ami_status) by  src_ip region eventName userAgent user_arn aws_account_id userIdentity.principalId |  `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_ami_attribute_modification_for_exfiltration_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that an AWS admin has legitimately shared a snapshot with others for  a specific purpose.", "check_references": false, "references": ["https://labs.nettitude.com/blog/how-to-exfiltrate-aws-ec2-data/", "https://stratus-red-team.cloud/attack-techniques/AWS/aws.exfiltration.ec2-share-ami/", "https://hackingthe.cloud/aws/enumeration/loot_public_ebs_snapshots/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_ami_attribute_modification_for_exfiltration_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS AMI Attribute Modification for Exfiltration:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_ami_shared_public/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_ami_shared_public/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Concurrent Sessions From Different Ips", "author": "Bhavin Patel, Splunk", "date": "2023-02-01", "version": 1, "id": "51c04fdb-2746-465a-b86e-b413a09c9085", "description": "The following analytic identifies an AWS IAM account with concurrent sessions coming from more than one unique IP address within the span of 5 minutes. This behavior could represent a session hijacking attack whereby an adversary has extracted cookies from a victims browser and is using them from a different location to access corporate online resources. When a user navigates the AWS Console after authentication, the API call with the event name `DescribeEventAggregates` is registered in the AWS CloudTrail logs. The Splunk Threat Research team leveraged this event name to identify 2 concurrent sessions. The presence of this event occurring from two different IP addresses is highly unlikely. As users may behave differently across organizations, security teams should test and customize this detection to fit their environments.", "tags": {"name": "AWS Concurrent Sessions From Different Ips", "analytic_story": ["Compromised User Account", "AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1185"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user_arn$ has concurrent sessions from more than one unique IP address $src_ip$ in the span of 5 minutes.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `cloudtrail` eventName = DescribeEventAggregates src_ip!=\"AWS Internal\" | bin span=5m _time | stats values(userAgent) values(eventName) values(src_ip) as src_ip  dc(src_ip) as distinct_ip_count by _time user_arn | where distinct_ip_count > 1 | `aws_concurrent_sessions_from_different_ips_filter`", "how_to_implement": "You must install Splunk AWS Add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "A user with concurrent sessions from different Ips may also represent the legitimate use of more than one device. Filter as needed and/or customize the threshold to fit your environment.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1185/", "https://breakdev.org/evilginx-2-next-generation-of-phishing-2fa-tokens/", "https://github.com/kgretzky/evilginx2"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_concurrent_sessions_from_different_ips_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Concurrent Sessions From Different Ips:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1185/aws_concurrent_sessions_from_different_ips/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1185/aws_concurrent_sessions_from_different_ips/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Console Login Failed During MFA Challenge", "author": "Bhavin Patel, Splunk", "date": "2022-10-03", "version": 1, "id": "55349868-5583-466f-98ab-d3beb321961e", "description": "The following analytic identifies an authentication attempt event against an AWS Console that fails during the Multi Factor Authentication challenge. AWS Cloudtrail logs provide a a very useful field called `additionalEventData` that logs information regarding usage of MFA. This behavior may represent an adversary trying to authenticate with compromised credentials for an account that has multi-factor authentication enabled.", "tags": {"name": "AWS Console Login Failed During MFA Challenge", "analytic_story": ["AWS Identity and Access Management Account Takeover", "Compromised User Account"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1621"], "nist": ["DE.CM"], "observable": [{"name": "user_name", "type": "User", "role": ["Victim"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user_name$ failed to pass MFA challenge while logging into console from $src$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName= ConsoleLogin errorMessage=\"Failed authentication\" additionalEventData.MFAUsed = \"Yes\" | stats count min(_time) as firstTime max(_time) as lastTime by src eventName eventSource aws_account_id errorCode errorMessage userAgent eventID awsRegion user_name userIdentity.arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `aws_console_login_failed_during_mfa_challenge_filter`", "how_to_implement": "The Splunk AWS Add-on is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "Legitimate users may miss to reply the MFA challenge within the time window or deny it by mistake.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://aws.amazon.com/what-is/mfa/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_console_login_failed_during_mfa_challenge_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Console Login Failed During MFA Challenge:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_failed_mfa/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_failed_mfa/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Create Policy Version to allow all resources", "author": "Bhavin Patel, Splunk", "date": "2022-05-17", "version": 3, "id": "2a9b80d3-6340-4345-b5ad-212bf3d0dac4", "description": "This search looks for AWS CloudTrail events where a user created a policy version that allows them to access any resource in their account.", "tags": {"name": "AWS Create Policy Version to allow all resources", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ created a policy version that allows them to access any resource in their account.", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=CreatePolicyVersion eventSource = iam.amazonaws.com errorCode = success | spath input=requestParameters.policyDocument output=key_policy_statements path=Statement{} | mvexpand key_policy_statements | spath input=key_policy_statements output=key_policy_action_1 path=Action | where key_policy_action_1 = \"*\" | stats count min(_time) as firstTime max(_time) as lastTime values(key_policy_statements) as policy_added by eventName eventSource aws_account_id errorCode userAgent eventID awsRegion user user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`aws_create_policy_version_to_allow_all_resources_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created a policy to allow a user to access all resources. That said, AWS strongly advises against granting full control to all AWS resources and you must verify this activity.", "check_references": false, "references": ["https://bishopfox.com/blog/privilege-escalation-in-aws", "https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation-part-2/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_create_policy_version_to_allow_all_resources_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Create Policy Version to allow all resources:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_create_policy_version/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_create_policy_version/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS CreateAccessKey", "author": "Bhavin Patel, Splunk", "date": "2022-03-03", "version": 3, "id": "2a9b80d3-6340-4345-11ad-212bf3d0d111", "description": "This detection rule monitors for the creation of AWS Identity and Access Management (IAM) access keys. An IAM access key consists of an access key ID and secret access key, which are used to sign programmatic requests to AWS services. While IAM access keys can be legitimately used by developers and administrators for API access, their creation can also be indicative of malicious activity. Attackers who have gained unauthorized access to an AWS environment might create access keys as a means to establish persistence or to exfiltrate data through the APIs. Moreover, because access keys can be used to authenticate with AWS services without the need for further interaction, they can be particularly appealing for bad actors looking to operate under the radar. Consequently, it's important to vigilantly monitor and scrutinize access key creation events, especially if they are associated with unusual activity or are created by users who don't typically perform these actions. This hunting query identifies when a potentially compromised user creates a IAM access key for another user who may have higher privilleges, which can be a sign for privilege escalation. Hunting queries are designed to be executed manual during threat hunting.", "tags": {"name": "AWS CreateAccessKey", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003", "T1136"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Attacker"]}], "message": "User $user_arn$ is attempting to create access keys for $requestParameters.userName$ from this IP $src$", "risk_score": 63, "security_domain": "network", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = CreateAccessKey userAgent !=console.amazonaws.com errorCode = success | eval match=if(match(userIdentity.userName,requestParameters.userName),1,0) | search match=0 | stats count min(_time) as firstTime max(_time) as lastTime by requestParameters.userName src eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |`aws_createaccesskey_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.", "check_references": false, "references": ["https://bishopfox.com/blog/privilege-escalation-in-aws", "https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation-part-2/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_createaccesskey_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS CreateAccessKey:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_createaccesskey/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_createaccesskey/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS CreateLoginProfile", "author": "Bhavin Patel, Splunk", "date": "2021-07-19", "version": 2, "id": "2a9b80d3-6340-4345-11ad-212bf444d111", "description": "This search looks for AWS CloudTrail events where a user A(victim A) creates a login profile for user B, followed by a AWS Console login event from user B from the same src_ip as user B. This correlated event can be indicative of privilege escalation since both events happened from the same src_ip", "tags": {"name": "AWS CreateLoginProfile", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003", "T1136"], "nist": ["DE.CM"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Attacker"]}], "message": "User $user_arn$ is attempting to create a login profile for $requestParameters.userName$ and did a console login from this IP $src_ip$", "risk_score": 72, "security_domain": "network", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = CreateLoginProfile | rename requestParameters.userName as new_login_profile | table src_ip eventName new_login_profile userIdentity.userName  | join new_login_profile src_ip [| search `cloudtrail` eventName = ConsoleLogin | rename userIdentity.userName  as new_login_profile | stats count values(eventName) min(_time) as firstTime max(_time) as lastTime by eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn new_login_profile src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`] | `aws_createloginprofile_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created a login profile for another user.", "check_references": false, "references": ["https://bishopfox.com/blog/privilege-escalation-in-aws", "https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation-part-2/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_createloginprofile_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS CreateLoginProfile:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_createloginprofile/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_createloginprofile/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Credential Access Failed Login", "author": "Gowthamaraj Rajendran, Bhavin Patel, Splunk", "date": "2022-08-07", "version": 1, "id": "a19b354d-0d7f-47f3-8ea6-1a7c36434968", "description": "It shows that there have been an unsuccessful attempt to log in using the user identity to the AWS management console. Since the user identity has access to AWS account services and resources, an attacker might try to brute force the password for that identity.", "tags": {"name": "AWS Credential Access Failed Login", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.001"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ has a login failure from IP $src$", "risk_score": 49, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats count earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Authentication where Authentication.action = failure Authentication.app=AwsConsoleSignIn Authentication.signature=ConsoleLogin BY Authentication.app Authentication.signature Authentication.dest  Authentication.user Authentication.action Authentication.user_id Authentication.src | `drop_dm_object_name(Authentication)`  | `security_content_ctime(firstTime)`|  `security_content_ctime(lastTime)` | `aws_credential_access_failed_login_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "Users may genuinely mistype or forget the password.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/001/"], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_credential_access_failed_login_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": [{"name": "AWS Credential Access Failed Login:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/aws_login_failure/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/aws_login_failure/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Credential Access GetPasswordData", "author": "Bhavin Patel, Splunk", "date": "2022-08-10", "version": 1, "id": "4d347c4a-306e-41db-8d10-b46baf71b3e2", "description": "This detection analytic identifies more than 10 GetPasswordData API calls made to your AWS account with a time window of 5 minutes. Attackers can retrieve the encrypted administrator password for a running Windows instance.", "tags": {"name": "AWS Credential Access GetPasswordData", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.001"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ is seen to make mulitple `GetPasswordData` API calls to instance ids $instance_ids$ from IP $src_ip$", "risk_score": 49, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=GetPasswordData eventSource = ec2.amazonaws.com |  bin _time span=5m |  stats count values(errorCode) as errorCode dc(requestParameters.instanceId) as distinct_instance_ids values(requestParameters.instanceId) as instance_ids by aws_account_id src_ip user_arn userAgent eventName _time |  where distinct_instance_ids > 10 | `aws_credential_access_getpassworddata_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs. We encourage the users to adjust the values of `distinct_instance_ids` and tweak the `span` value according to their environment.", "known_false_positives": "Administrator tooling or automated scripts may make these calls but it is highly unlikely to make several calls in a short period of time.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1552/", "https://stratus-red-team.cloud/attack-techniques/AWS/aws.credential-access.ec2-get-password-data/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_credential_access_getpassworddata_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Credential Access GetPasswordData:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552/aws_getpassworddata/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552/aws_getpassworddata/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Credential Access RDS Password reset", "author": "Gowthamaraj Rajendran, Splunk", "date": "2024-03-19", "version": 2, "id": "6153c5ea-ed30-4878-81e6-21ecdb198189", "description": "The master user password for Amazon RDS DB instance can be reset using the Amazon RDS console. Using this technique, the attacker can get access to the sensitive data from the DB. Usually, the production databases may have sensitive data like Credit card information, PII, Health care Data. This event should be investigated further.", "tags": {"name": "AWS Credential Access RDS Password reset", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110"], "nist": ["DE.CM"], "observable": [{"name": "database_id", "type": "Endpoint", "role": ["Victim"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}], "message": "$database_id$ password has been reset from IP $src$", "risk_score": 49, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=\"rds.amazonaws.com\" eventName=ModifyDBInstance \"requestParameters.masterUserPassword\"=* | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.dBInstanceIdentifier) as database_id by src awsRegion eventName userAgent user_arn| `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_credential_access_rds_password_reset_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "Users may genuinely reset the RDS password.", "check_references": false, "references": ["https://aws.amazon.com/premiumsupport/knowledge-center/reset-master-user-password-rds"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_credential_access_rds_password_reset_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Credential Access RDS Password reset:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.002/aws_rds_password_reset/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.002/aws_rds_password_reset/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Cross Account Activity From Previously Unseen Account", "author": "Rico Valdez, Splunk", "date": "2020-05-28", "version": 1, "id": "21193641-cb96-4a2c-a707-d9b9a7f7792b", "description": "This search looks for AssumeRole events where an IAM role in a different account is requested for the first time.", "tags": {"name": "AWS Cross Account Activity From Previously Unseen Account", "analytic_story": ["Suspicious Cloud Authentication Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "requestingAccountId", "type": "Other", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Victim"]}], "message": "AWS account $requestingAccountId$ is trying to access resource from some other account $requestedAccountId$, for the first time.", "risk_score": 15, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats min(_time) as firstTime max(_time) as lastTime from datamodel=Authentication where Authentication.signature=AssumeRole by Authentication.vendor_account Authentication.user Authentication.src Authentication.user_role | `drop_dm_object_name(Authentication)` | rex field=user_role \"arn:aws:sts:*:(?<dest_account>.*):\" | where vendor_account != dest_account | rename vendor_account as requestingAccountId dest_account as requestedAccountId | lookup previously_seen_aws_cross_account_activity requestingAccountId, requestedAccountId, OUTPUTNEW firstTime | eval status = if(firstTime > relative_time(now(), \"-24h@h\"),\"New Cross Account Activity\",\"Previously Seen\") |  where status = \"New Cross Account Activity\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `aws_cross_account_activity_from_previously_unseen_account_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen AWS Cross Account Activity - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen AWS Cross Account Activity - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `aws_cross_account_activity_from_previously_unseen_account_filter` macro.", "known_false_positives": "Using multiple AWS accounts and roles is perfectly valid behavior. It's suspicious when an account requests privileges of an account it hasn't before. You should validate with the account owner that this is a legitimate request.", "check_references": false, "references": [], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_cross_account_activity_from_previously_unseen_account_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_aws_cross_account_activity", "description": "A placeholder for a list of AWS accounts and assumed roles", "collection": "previously_seen_aws_cross_account_activity", "fields_list": "_key,firstTime,lastTime,requestingAccountId,requestedAccountId", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_aws_cross_account_activity.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "AWS Cross Account Activity From Previously Unseen Account:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Defense Evasion Delete Cloudtrail", "author": "Bhavin Patel, Splunk", "date": "2022-07-13", "version": 1, "id": "82092925-9ca1-4e06-98b8-85a2d3889552", "description": "This analytic identifies AWS `DeleteTrail` events within CloudTrail logs. Adversaries often try to impair their target's defenses by stopping their malicious activity from being logged, so that they may operate with stealth and avoid detection. When the adversary has the right type of permissions in the compromised AWS environment, they may delete the the entire cloudtrail that is logging activities in the environment.", "tags": {"name": "AWS Defense Evasion Delete Cloudtrail", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.008", "T1562"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has delete a CloudTrail logging for account id $aws_account_id$ from IP $src$", "risk_score": 90, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = DeleteTrail eventSource = cloudtrail.amazonaws.com userAgent !=console.amazonaws.com errorCode = success| stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.name) as deleted_cloudtrail_name by src region eventName userAgent user_arn aws_account_id | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `aws_defense_evasion_delete_cloudtrail_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable CloudTrail logs in your AWS Environment.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has stopped cloudTrail logging. Please investigate this activity.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_defense_evasion_delete_cloudtrail_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Defense Evasion Delete Cloudtrail:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/stop_delete_cloudtrail/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/stop_delete_cloudtrail/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS Defense Evasion Delete CloudWatch Log Group", "author": "Gowthamaraj Rajendran, Splunk", "date": "2022-07-17", "version": 1, "id": "d308b0f1-edb7-4a62-a614-af321160710f", "description": "This analytic identifies AWS `DeleteLogGroup` events in CloudTrail logs. Attackers may evade the logging capability by deleting the log group in CloudWatch. This will stop sending the logs and metrics to CloudWatch. When the adversary has the right type of permissions within the compromised AWS environment, they may delete the CloudWatch log group that is logging activities in the environment.", "tags": {"name": "AWS Defense Evasion Delete CloudWatch Log Group", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562", "T1562.008"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has deleted a CloudWatch logging group for account id $aws_account_id$ from IP $src$", "risk_score": 90, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = DeleteLogGroup eventSource = logs.amazonaws.com userAgent !=console.amazonaws.com errorCode = success| stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.logGroupName) as log_group_name by src region eventName userAgent user_arn aws_account_id | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `aws_defense_evasion_delete_cloudwatch_log_group_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable CloudTrail logs in your AWS Environment.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has deleted CloudWatch logging. Please investigate this activity.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_defense_evasion_delete_cloudwatch_log_group_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Defense Evasion Delete CloudWatch Log Group:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/delete_cloudwatch_log_group/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/delete_cloudwatch_log_group/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Defense Evasion Impair Security Services", "author": "Bhavin Patel, Gowthamaraj Rajendran, Splunk", "date": "2022-07-26", "version": 1, "id": "b28c4957-96a6-47e0-a965-6c767aac1458", "description": "This analytic looks for several delete specific API calls made to AWS Security Services like CloudWatch, GuardDuty and Web Application Firewalls. These API calls are often leveraged by adversaries to weaken existing security defenses by deleting logging configurations in the CloudWatch alarm, delete a set of detectors from your Guardduty environment or simply delete a bunch of CloudWatch alarms to remain stealthy and avoid detection.", "tags": {"name": "AWS Defense Evasion Impair Security Services", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.008", "T1562"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Attacker"]}], "message": "User $user_arn$ has made potentially risky api calls $eventName$ that could impair AWS security services for account id $aws_account_id$", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName IN (\"DeleteLogStream\",\"DeleteDetector\",\"DeleteIPSet\",\"DeleteWebACL\",\"DeleteRule\",\"DeleteRuleGroup\",\"DeleteLoggingConfiguration\",\"DeleteAlarms\") | stats count min(_time) as firstTime max(_time) as lastTime values(eventName)  as eventName values(eventSource) as eventSource values(requestParameters.*) as * by src region user_arn aws_account_id user_type user_agent errorCode| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|  `aws_defense_evasion_impair_security_services_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable CloudTrail logs in your AWS Environment.", "known_false_positives": "While this search has no known false positives, it is possible that it is a legitimate admin activity. Please consider filtering out these noisy events using userAgent, user_arn field names.", "check_references": false, "references": ["https://docs.aws.amazon.com/cli/latest/reference/guardduty/index.html", "https://docs.aws.amazon.com/cli/latest/reference/waf/index.html", "https://www.elastic.co/guide/en/security/current/prebuilt-rules.html"], "datamodel": ["Web"], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_defense_evasion_impair_security_services_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Defense Evasion Impair Security Services:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/aws_delete_security_services/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/aws_delete_security_services/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Defense Evasion PutBucketLifecycle", "author": "Bhavin Patel", "date": "2022-07-25", "version": 1, "id": "ce1c0e2b-9303-4903-818b-0d9002fc6ea4", "description": "This analytic identifies `PutBucketLifecycle` events in CloudTrail logs where a user has created a new lifecycle rule for an S3 bucket with a short expiration period. Attackers may use this API call to impair the CloudTrail logging by removing logs from the S3 bucket by changing the object expiration day to 1 day, in which case the CloudTrail logs will be deleted.", "tags": {"name": "AWS Defense Evasion PutBucketLifecycle", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.008", "T1562"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Attacker"]}], "message": "User $user_arn$ has created a new rule to on an S3 bucket $bucket_name$ with short expiration days", "risk_score": 20, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=PutBucketLifecycle user_type=IAMUser errorCode=success |  spath path=requestParameters{}.LifecycleConfiguration{}.Rule{}.Expiration{}.Days output=expiration_days |  spath path=requestParameters{}.bucketName output=bucket_name | stats count min(_time) as firstTime max(_time) as lastTime  by src region eventName userAgent user_arn aws_account_id expiration_days  bucket_name user_type| `security_content_ctime(firstTime)` |  `security_content_ctime(lastTime)` | where expiration_days < 3 | `aws_defense_evasion_putbucketlifecycle_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable CloudTrail logs in your AWS Environment. We recommend our users to set the expiration days value according to your company's log retention policies.", "known_false_positives": "While this search has no known false positives, it is possible that it is a legitimate admin activity. Please consider filtering out these noisy events using userAgent, user_arn field names.", "check_references": false, "references": ["https://stratus-red-team.cloud/attack-techniques/AWS/aws.defense-evasion.cloudtrail-lifecycle-rule/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_defense_evasion_putbucketlifecycle_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Defense Evasion PutBucketLifecycle:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/put_bucketlifecycle/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/put_bucketlifecycle/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Defense Evasion Stop Logging Cloudtrail", "author": "Bhavin Patel, Splunk", "date": "2022-07-12", "version": 1, "id": "8a2f3ca2-4eb5-4389-a549-14063882e537", "description": "This analytic identifies `StopLogging` events in CloudTrail logs. Adversaries often try to impair their target's defenses by stopping their macliious activity from being logged, so that they may operate with stealth and avoid detection. When the adversary has the right type of permissions in the compromised AWS environment, they may easily stop logging.", "tags": {"name": "AWS Defense Evasion Stop Logging Cloudtrail", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.008", "T1562"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has stopped Cloudtrail logging for account id $aws_account_id$ from IP $src$", "risk_score": 90, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = StopLogging eventSource = cloudtrail.amazonaws.com userAgent !=console.amazonaws.com errorCode = success| stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.name) as stopped_cloudtrail_name by src region eventName userAgent user_arn aws_account_id | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_defense_evasion_stop_logging_cloudtrail_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable Cloudtrail logs in your AWS Environment.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has stopped cloudtrail logging. Please investigate this activity.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_defense_evasion_stop_logging_cloudtrail_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Defense Evasion Stop Logging Cloudtrail:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/stop_delete_cloudtrail/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/stop_delete_cloudtrail/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS Defense Evasion Update Cloudtrail", "author": "Gowthamaraj Rajendran, Splunk", "date": "2022-07-17", "version": 1, "id": "7c921d28-ef48-4f1b-85b3-0af8af7697db", "description": "This analytic identifies `UpdateTrail` events in CloudTrail logs. Attackers may evade the logging capability by updating the settings and impairing them with wrong parameters. For example, Attackers may change the multi-regional log into a single region logs, which evades the logging for other regions. When the adversary has the right type of permissions in the compromised AWS environment, they may update the CloudTrail settings that is logging activities in your environment.", "tags": {"name": "AWS Defense Evasion Update Cloudtrail", "analytic_story": ["AWS Defense Evasion"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562", "T1562.008"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has updated a cloudtrail logging for account id $aws_account_id$ from IP $src$", "risk_score": 90, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = UpdateTrail eventSource = cloudtrail.amazonaws.com userAgent !=console.amazonaws.com errorCode = success| stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.name) as cloudtrail_name by src region eventName userAgent user_arn aws_account_id | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `aws_defense_evasion_update_cloudtrail_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable CloudTrail logs in your AWS Environment.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has updated cloudtrail logging. Please investigate this activity.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_defense_evasion_update_cloudtrail_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Defense Evasion Update Cloudtrail:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/update_cloudtrail/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/update_cloudtrail/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "aws detect attach to role policy", "author": "Rod Soto, Splunk", "date": "2020-07-27", "version": 1, "id": "88fc31dd-f331-448c-9856-d3d51dd5d3a1", "description": "This search provides detection of an user attaching itself to a different role trust policy. This can be used for lateral movement and escalation of privileges.", "tags": {"name": "aws detect attach to role policy", "analytic_story": ["AWS Cross Account Activity"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_cloudwatchlogs_eks` attach policy| spath requestParameters.policyArn | table sourceIPAddress user_access_key userIdentity.arn userIdentity.sessionContext.sessionIssuer.arn eventName errorCode errorMessage status action requestParameters.policyArn userIdentity.sessionContext.attributes.mfaAuthenticated userIdentity.sessionContext.attributes.creationDate  | `aws_detect_attach_to_role_policy_filter`", "how_to_implement": "You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs", "known_false_positives": "Attach to policy can create a lot of noise. This search can be adjusted to provide specific values to identify cases of abuse (i.e status=failure). The search can provide context for common users attaching themselves to higher privilege policies or even newly created policies.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_cloudwatchlogs_eks", "definition": "sourcetype=\"aws:cloudwatchlogs:eks\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_detect_attach_to_role_policy_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "aws detect permanent key creation", "author": "Rod Soto, Splunk", "date": "2020-07-27", "version": 1, "id": "12d6d713-3cb4-4ffc-a064-1dca3d1cca01", "description": "This search provides detection of accounts creating permanent keys. Permanent keys are not created by default and they are only needed for programmatic calls. Creation of Permanent key is an important event to monitor.", "tags": {"name": "aws detect permanent key creation", "analytic_story": ["AWS Cross Account Activity"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_cloudwatchlogs_eks` CreateAccessKey | spath eventName | search eventName=CreateAccessKey \"userIdentity.type\"=IAMUser | table sourceIPAddress userName userIdentity.type userAgent action status responseElements.accessKey.createDate responseElements.accessKey.status responseElements.accessKey.accessKeyId |`aws_detect_permanent_key_creation_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs", "known_false_positives": "Not all permanent key creations are malicious. If there is a policy of rotating keys this search can be adjusted to provide better context.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_cloudwatchlogs_eks", "definition": "sourcetype=\"aws:cloudwatchlogs:eks\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_detect_permanent_key_creation_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "aws detect role creation", "author": "Rod Soto, Splunk", "date": "2020-07-27", "version": 1, "id": "5f04081e-ddee-4353-afe4-504f288de9ad", "description": "This search provides detection of role creation by IAM users. Role creation is an event by itself if user is creating a new role with trust policies different than the available in AWS and it can be used for lateral movement and escalation of privileges.", "tags": {"name": "aws detect role creation", "analytic_story": ["AWS Cross Account Activity"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_cloudwatchlogs_eks` event_name=CreateRole action=created userIdentity.type=AssumedRole requestParameters.description=Allows* | table sourceIPAddress userIdentity.principalId userIdentity.arn action event_name awsRegion http_user_agent mfa_auth msg requestParameters.roleName requestParameters.description responseElements.role.arn responseElements.role.createDate | `aws_detect_role_creation_filter`", "how_to_implement": "You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs", "known_false_positives": "CreateRole is not very common in common users. This search can be adjusted to provide specific values to identify cases of abuse. In general AWS provides plenty of trust policies that fit most use cases.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_cloudwatchlogs_eks", "definition": "sourcetype=\"aws:cloudwatchlogs:eks\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_detect_role_creation_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "aws detect sts assume role abuse", "author": "Rod Soto, Splunk", "date": "2020-07-27", "version": 1, "id": "8e565314-b6a2-46d8-9f05-1a34a176a662", "description": "This search provides detection of suspicious use of sts:AssumeRole. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.", "tags": {"name": "aws detect sts assume role abuse", "analytic_story": ["AWS Cross Account Activity"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` user_type=AssumedRole userIdentity.sessionContext.sessionIssuer.type=Role | table sourceIPAddress userIdentity.arn user_agent user_access_key status action requestParameters.roleName responseElements.role.roleName responseElements.role.createDate | `aws_detect_sts_assume_role_abuse_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs", "known_false_positives": "Sts:AssumeRole can be very noisy as it is a standard mechanism to provide cross account and cross resources access. This search can be adjusted to provide specific values to identify cases of abuse.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_detect_sts_assume_role_abuse_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": []}, {"name": "aws detect sts get session token abuse", "author": "Rod Soto, Splunk", "date": "2020-07-27", "version": 1, "id": "85d7b35f-b8b5-4b01-916f-29b81e7a0551", "description": "This search provides detection of suspicious use of sts:GetSessionToken. These tokens can be created on the go and used by attackers to move laterally and escalate privileges.", "tags": {"name": "aws detect sts get session token abuse", "analytic_story": ["AWS Cross Account Activity"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1550"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_cloudwatchlogs_eks` ASIA  userIdentity.type=IAMUser| spath eventName | search eventName=GetSessionToken | table sourceIPAddress eventTime userIdentity.arn userName userAgent user_type status region | `aws_detect_sts_get_session_token_abuse_filter`", "how_to_implement": "You must install splunk AWS add-on and Splunk App for AWS. This search works with cloudwatch logs", "known_false_positives": "Sts:GetSessionToken can be very noisy as in certain environments numerous calls of this type can be executed. This search can be adjusted to provide specific values to identify cases of abuse. In specific environments the use of field requestParameters.serialNumber will need to be used.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_cloudwatchlogs_eks", "definition": "sourcetype=\"aws:cloudwatchlogs:eks\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_detect_sts_get_session_token_abuse_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "AWS Detect Users creating keys with encrypt policy without MFA", "author": "Rod Soto, Patrick Bareiss Splunk", "date": "2021-01-11", "version": 1, "id": "c79c164f-4b21-4847-98f9-cf6a9f49179e", "description": "This search provides detection of KMS keys where action kms:Encrypt is accessible for everyone (also outside of your organization). This is an indicator that your account is compromised and the attacker uses the encryption key to compromise another company.", "tags": {"name": "AWS Detect Users creating keys with encrypt policy without MFA", "analytic_story": ["Ransomware Cloud"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1486"], "nist": ["DE.CM"], "observable": [{"name": "userIdentity.principalId", "type": "User", "role": ["Attacker"]}], "message": "AWS account is potentially compromised and user $userIdentity.principalId$ is trying to compromise other accounts.", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=CreateKey OR eventName=PutKeyPolicy | spath input=requestParameters.policy output=key_policy_statements path=Statement{} | mvexpand key_policy_statements | spath input=key_policy_statements output=key_policy_action_1 path=Action | spath input=key_policy_statements output=key_policy_action_2 path=Action{} | eval key_policy_action=mvappend(key_policy_action_1, key_policy_action_2) | spath input=key_policy_statements output=key_policy_principal path=Principal.AWS | search key_policy_action=\"kms:Encrypt\" AND key_policy_principal=\"*\" | stats count min(_time) as firstTime max(_time) as lastTime by eventName eventSource eventID awsRegion userIdentity.principalId | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_detect_users_creating_keys_with_encrypt_policy_without_mfa_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs", "known_false_positives": "unknown", "check_references": false, "references": ["https://rhinosecuritylabs.com/aws/s3-ransomware-part-1-attack-vector/", "https://github.com/d1vious/git-wild-hunt", "https://www.youtube.com/watch?v=PgzNib37g0M"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_detect_users_creating_keys_with_encrypt_policy_without_mfa_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Detect Users creating keys with encrypt policy without MFA:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1486/aws_kms_key/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1486/aws_kms_key/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Detect Users with KMS keys performing encryption S3", "author": "Rod Soto, Patrick Bareiss Splunk", "date": "2022-11-11", "version": 2, "id": "884a5f59-eec7-4f4a-948b-dbde18225fdc", "description": "This search provides detection of users with KMS keys performing encryption specifically against S3 buckets.", "tags": {"name": "AWS Detect Users with KMS keys performing encryption S3", "analytic_story": ["Ransomware Cloud"], "asset_type": "S3 Bucket", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1486"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "dest_file", "type": "File", "role": ["Target"]}], "message": "User $user$ with KMS keys is performing encryption, against S3 buckets on these files $dest_file$", "risk_score": 15, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=CopyObject requestParameters.x-amz-server-side-encryption=\"aws:kms\" | rename requestParameters.bucketName AS bucketName, requestParameters.x-amz-copy-source AS src_file, requestParameters.key AS dest_file | stats count min(_time) as firstTime max(_time) as lastTime values(bucketName) as bucketName values(src_file) AS src_file values(dest_file) AS dest_file values(userAgent) AS userAgent values(region) AS region values(src) AS src by user | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_detect_users_with_kms_keys_performing_encryption_s3_filter`", "how_to_implement": "You must install Splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs", "known_false_positives": "There maybe buckets provisioned with S3 encryption", "check_references": false, "references": ["https://rhinosecuritylabs.com/aws/s3-ransomware-part-1-attack-vector/", "https://github.com/d1vious/git-wild-hunt", "https://www.youtube.com/watch?v=PgzNib37g0M"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_detect_users_with_kms_keys_performing_encryption_s3_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Detect Users with KMS keys performing encryption S3:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1486/s3_file_encryption/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1486/s3_file_encryption/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Disable Bucket Versioning", "author": "Bhavin Patel, Splunk", "date": "2023-05-01", "version": 1, "id": "657902a9-987d-4879-a1b2-e7a65512824b", "description": "The following analytic detects AWS cloudtrail events where bucket versioning is suspended by a user. Versioning allows the AWS Administrators to maintain different version of the S3 bucket which can be used to recover deleted data. Adversaries have leveraged this technique in the wild during a ransomware incident to disable versioning so the client cannot recover the data.", "tags": {"name": "AWS Disable Bucket Versioning", "analytic_story": ["Suspicious AWS S3 Activities", "Data Exfiltration"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1490"], "nist": ["DE.AE"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "Bucket Versioning is suspended for S3 buckets- $bucket_name$ by user $user_arn$ from IP address $src_ip$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName= PutBucketVersioning \"requestParameters.VersioningConfiguration.Status\"=Suspended |  stats count values(requestParameters.bucketName) as bucket_name values(resources{}.ARN) as resource_arn by src_ip aws_account_id awsRegion eventName userAgent user_arn userIdentity.principalId  errorCode | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `aws_disable_bucket_versioning_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that an AWS Administrator has legitimately disabled versioning on certain buckets to avoid costs.", "check_references": false, "references": ["https://invictus-ir.medium.com/ransomware-in-the-cloud-7f14805bbe82", "https://bleemb.medium.com/data-exfiltration-with-native-aws-s3-features-c94ae4d13436"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_disable_bucket_versioning_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Disable Bucket Versioning:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1490/aws_bucket_version/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1490/aws_bucket_version/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS EC2 Snapshot Shared Externally", "author": "Bhavin Patel, Splunk", "date": "2023-03-20", "version": 3, "id": "2a9b80d3-6340-4345-b5ad-290bf3d222c4", "description": "The following analytic utilizes AWS CloudTrail events to identify when an EC2 snapshot permissions are modified to be shared with a different AWS account. This method is used by adversaries to exfiltrate the EC2 snapshot.", "tags": {"name": "AWS EC2 Snapshot Shared Externally", "analytic_story": ["Suspicious Cloud Instance Activities", "Data Exfiltration"], "asset_type": "EC2 Snapshot", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1537"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "AWS EC2 snapshot from account $aws_account_id$ is shared with $requested_account_id$ by user $user_arn$ from $src_ip$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=ModifySnapshotAttribute | rename requestParameters.createVolumePermission.add.items{}.userId as requested_account_id | search requested_account_id != NULL | eval match=if(requested_account_id==aws_account_id,\"Match\",\"No Match\") | table _time user_arn src_ip requestParameters.attributeType requested_account_id aws_account_id match vendor_region user_agent userIdentity.principalId | where match = \"No Match\" | `aws_ec2_snapshot_shared_externally_filter` ", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that an AWS admin has legitimately shared a snapshot with others for  a specific purpose.", "check_references": false, "references": ["https://labs.nettitude.com/blog/how-to-exfiltrate-aws-ec2-data/", "https://stratus-red-team.cloud/attack-techniques/AWS/aws.exfiltration.ec2-share-ebs-snapshot/", "https://hackingthe.cloud/aws/enumeration/loot_public_ebs_snapshots/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_ec2_snapshot_shared_externally_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS EC2 Snapshot Shared Externally:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_snapshot_exfil/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_snapshot_exfil/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS ECR Container Scanning Findings High", "author": "Patrick Bareiss, Splunk", "date": "2023-11-09", "version": 2, "id": "30a0e9f8-f1dd-4f9d-8fc2-c622461d781c", "description": "This search looks for AWS CloudTrail events from AWS Elastic Container Service (ECR). You need to activate image scanning in order to get the event DescribeImageScanFindings with the results.", "tags": {"name": "AWS ECR Container Scanning Findings High", "analytic_story": ["Dev Sec Ops"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204.003", "T1204"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "repository", "type": "Other", "role": ["Victim"]}], "message": "Vulnerabilities with severity high found in repository $repository$", "risk_score": 70, "security_domain": "network", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=ecr.amazonaws.com eventName=DescribeImageScanFindings | spath path=responseElements.imageScanFindings.findings{} output=findings | mvexpand findings | spath input=findings | search severity=HIGH | rename name as finding_name, description as finding_description, requestParameters.imageId.imageDigest as imageDigest, requestParameters.repositoryName as repository, userIdentity.principalId as user | eval finding = finding_name.\", \".finding_description | eval phase=\"release\" | eval severity=\"high\" | stats min(_time) as firstTime max(_time) as lastTime by awsRegion, eventName, eventSource, imageDigest, repository, user, src_ip, finding, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_ecr_container_scanning_findings_high_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_ecr_container_scanning_findings_high_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS ECR Container Scanning Findings High:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_image_scanning/aws_ecr_scanning_findings_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_image_scanning/aws_ecr_scanning_findings_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS ECR Container Scanning Findings Low Informational Unknown", "author": "Patrick Bareiss, Eric McGinnis Splunk", "date": "2023-11-09", "version": 2, "id": "cbc95e44-7c22-443f-88fd-0424478f5589", "description": "This search looks for AWS CloudTrail events from AWS Elastic Container Service (ECR). You need to activate image scanning in order to get the event DescribeImageScanFindings with the results.", "tags": {"name": "AWS ECR Container Scanning Findings Low Informational Unknown", "analytic_story": ["Dev Sec Ops"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204.003", "T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "repository", "type": "Other", "role": ["Victim"]}], "message": "Vulnerabilities with severity $severity$ found in repository $repository$", "risk_score": 5, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=ecr.amazonaws.com eventName=DescribeImageScanFindings | spath path=responseElements.imageScanFindings.findings{} output=findings | mvexpand findings | spath input=findings| search severity IN (\"LOW\", \"INFORMATIONAL\", \"UNKNOWN\") | rename name as finding_name, description as finding_description, requestParameters.imageId.imageDigest as imageDigest, requestParameters.repositoryName as repository, userIdentity.principalId as user | eval finding = finding_name.\", \".finding_description | eval phase=\"release\" | eval severity=\"low\" | stats min(_time) as firstTime max(_time) as lastTime by awsRegion, eventName, eventSource, imageDigest, repository, user, src_ip, finding, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_ecr_container_scanning_findings_low_informational_unknown_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_ecr_container_scanning_findings_low_informational_unknown_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS ECR Container Scanning Findings Low Informational Unknown:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_image_scanning/aws_ecr_scanning_findings_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_image_scanning/aws_ecr_scanning_findings_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS ECR Container Scanning Findings Medium", "author": "Patrick Bareiss, Splunk", "date": "2023-11-09", "version": 2, "id": "0b80e2c8-c746-4ddb-89eb-9efd892220cf", "description": "This search looks for AWS CloudTrail events from AWS Elastic Container Service (ECR). You need to activate image scanning in order to get the event DescribeImageScanFindings with the results.", "tags": {"name": "AWS ECR Container Scanning Findings Medium", "analytic_story": ["Dev Sec Ops"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204.003", "T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "repository", "type": "Other", "role": ["Victim"]}], "message": "Vulnerabilities with severity $severity$ found in repository $repository$", "risk_score": 21, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=ecr.amazonaws.com eventName=DescribeImageScanFindings | spath path=responseElements.imageScanFindings.findings{} output=findings | mvexpand findings | spath input=findings| search severity=MEDIUM | rename name as finding_name, description as finding_description, requestParameters.imageId.imageDigest as imageDigest, requestParameters.repositoryName as repository, userIdentity.principalId as user| eval finding = finding_name.\", \".finding_description | eval phase=\"release\" | eval severity=\"medium\" | stats min(_time) as firstTime max(_time) as lastTime by awsRegion, eventName, eventSource, imageDigest, repository, user, src_ip, finding, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_ecr_container_scanning_findings_medium_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_ecr_container_scanning_findings_medium_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS ECR Container Scanning Findings Medium:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_image_scanning/aws_ecr_scanning_findings_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_image_scanning/aws_ecr_scanning_findings_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS ECR Container Upload Outside Business Hours", "author": "Patrick Bareiss, Splunk", "date": "2023-11-09", "version": 2, "id": "d4c4d4eb-3994-41ca-a25e-a82d64e125bb", "description": "This search looks for AWS CloudTrail events from AWS Elastic Container Service (ECR). A upload of a new container is normally done during business hours. When done outside business hours, we want to take a look into it.", "tags": {"name": "AWS ECR Container Upload Outside Business Hours", "analytic_story": ["Dev Sec Ops"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204.003", "T1204"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Container uploaded outside business hours from $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=ecr.amazonaws.com eventName=PutImage date_hour>=20 OR date_hour<8 OR date_wday=saturday OR date_wday=sunday | rename requestParameters.* as * | rename repositoryName AS repository | eval phase=\"release\" | eval severity=\"medium\" | stats min(_time) as firstTime max(_time) as lastTime by awsRegion, eventName, eventSource, user, userName, src_ip, imageTag, registryId, repository, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_ecr_container_upload_outside_business_hours_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "When your development is spreaded in different time zones, applying this rule can be difficult.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1204/003/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_ecr_container_upload_outside_business_hours_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS ECR Container Upload Outside Business Hours:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_container_upload/aws_ecr_container_upload.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_container_upload/aws_ecr_container_upload.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS ECR Container Upload Unknown User", "author": "Patrick Bareiss, Splunk", "date": "2021-08-19", "version": 1, "id": "300688e4-365c-4486-a065-7c884462b31d", "description": "This search looks for AWS CloudTrail events from AWS Elastic Container Service (ECR). A upload of a new container is normally done from only a few known users. When the user was never seen before, we should have a closer look into the event.", "tags": {"name": "AWS ECR Container Upload Unknown User", "analytic_story": ["Dev Sec Ops"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204.003", "T1204"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Container uploaded from unknown user $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=ecr.amazonaws.com eventName=PutImage NOT `aws_ecr_users` | rename requestParameters.* as * | rename repositoryName AS image | eval phase=\"release\" | eval severity=\"high\" | stats min(_time) as firstTime max(_time) as lastTime by awsRegion, eventName, eventSource, user, userName, src_ip, imageTag, registryId, image, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_ecr_container_upload_unknown_user_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1204/003/"], "datamodel": [], "macros": [{"name": "aws_ecr_users", "definition": "userName IN (user)", "description": "specify the user allowed to push Images to AWS ECR."}, {"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_ecr_container_upload_unknown_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS ECR Container Upload Unknown User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_container_upload/aws_ecr_container_upload.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204.003/aws_ecr_container_upload/aws_ecr_container_upload.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS Excessive Security Scanning", "author": "Patrick Bareiss, Splunk", "date": "2021-04-13", "version": 1, "id": "1fdd164a-def8-4762-83a9-9ffe24e74d5a", "description": "This search looks for AWS CloudTrail events and analyse the amount of eventNames which starts with Describe by a single user. This indicates that this user scans the configuration of your AWS cloud environment.", "tags": {"name": "AWS Excessive Security Scanning", "analytic_story": ["AWS User Monitoring"], "asset_type": "AWS Account", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ has excessive number of api calls $dc_events$ from these IP addresses $src$, violating the threshold of 50, using the following commands $command$.", "risk_score": 18, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=Describe* OR eventName=List* OR eventName=Get*  | stats dc(eventName) as dc_events min(_time) as firstTime max(_time) as lastTime values(eventName) as command values(src) as src values(userAgent) as userAgent by user userIdentity.arn | where dc_events > 50 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`|`aws_excessive_security_scanning_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives.", "check_references": false, "references": ["https://github.com/aquasecurity/cloudsploit"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_excessive_security_scanning_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Excessive Security Scanning:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1526/aws_security_scanner/aws_security_scanner.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1526/aws_security_scanner/aws_security_scanner.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Exfiltration via Anomalous GetObject API Activity", "author": "Bhavin Patel, Splunk", "date": "2023-04-10", "version": 1, "id": "e4384bbf-5835-4831-8d85-694de6ad2cc6", "description": "This search uses built in  Splunk command `| anomalydetection` to detect anomalies with respect to users making high number of GetObject API calls to download objects from S3 in a 10 minute time window. The field `probable_cause` is the name of the field that best explains why the event is anomalous. This command identifies anomalous events by computing a probability for each GetObject event by \"count\" \"user_type\" \"user_arn\" and detects anomaly based on the frequencies.", "tags": {"name": "AWS Exfiltration via Anomalous GetObject API Activity", "analytic_story": ["Data Exfiltration"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1119"], "nist": ["DE.AE"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "Anomalous S3 activities detected by user $user_arn$ from $src_ip$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=GetObject | bin _time span=10m |  stats count values(requestParameters.bucketName) as bucketName by _time src_ip aws_account_id user_type user_arn userIdentity.principalId | anomalydetection \"count\" \"user_type\" \"user_arn\" action=annotate | search probable_cause=* |`aws_exfiltration_via_anomalous_getobject_api_activity_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that a user downloaded these files to use them locally and there are AWS services in configured that perform these activities for a legitimate reason. Filter is needed.", "check_references": false, "references": ["https://labs.nettitude.com/blog/how-to-exfiltrate-aws-ec2-data/", "https://docs.splunk.com/Documentation/Splunk/9.0.4/SearchReference/Anomalydetection", "https://www.vectra.ai/blogpost/abusing-the-replicator-silently-exfiltrating-data-with-the-aws-s3-replication-service"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_exfiltration_via_anomalous_getobject_api_activity_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Exfiltration via Anomalous GetObject API Activity:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1530/aws_exfil_high_no_getobject/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1530/aws_exfil_high_no_getobject/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Exfiltration via Batch Service", "author": "Bhavin Patel, Splunk", "date": "2023-04-24", "version": 1, "id": "04455dd3-ced7-480f-b8e6-5469b99e98e2", "description": "This search looks for events where AWS Batch Service is used for creating a job that could potentially abuse the AWS Bucket Replication feature on S3 buckets. This AWS service can used to transfer data between different AWS S3 buckets and an attacker can leverage this to exfiltrate data by creating a malicious batch job.", "tags": {"name": "AWS Exfiltration via Batch Service", "analytic_story": ["Data Exfiltration"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1119"], "nist": ["DE.CM"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "AWS Batch Job is created on account id - $aws_account_id$ from src_ip $src_ip$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = JobCreated |  stats count min(_time) as firstTime max(_time) as lastTime values(serviceEventDetails.jobArn) as job_arn values(serviceEventDetails.status) as status by src_ip  aws_account_id eventName errorCode userAgent| `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_exfiltration_via_datasync_task_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that an AWS Administrator or a user has legitimately created this job for some tasks.", "check_references": false, "references": ["https://hackingthe.cloud/aws/exploitation/s3-bucket-replication-exfiltration/", "https://bleemb.medium.com/data-exfiltration-with-native-aws-s3-features-c94ae4d13436"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_exfiltration_via_batch_service_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Exfiltration via Batch Service:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1119/aws_exfil_datasync/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1119/aws_exfil_datasync/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Exfiltration via Bucket Replication", "author": "Bhavin Patel, Splunk", "date": "2023-04-28", "version": 1, "id": "eeb432d6-2212-43b6-9e89-fcd753f7da4c", "description": "The following analytic detects API calls made to an S3 bucket when bucket replication services are enabled. S3 bucket replication is a feature offered by Amazon Web Services (AWS) that allows you to automatically and asynchronously copy data from one S3 bucket to another in the same or different region.\\\nS3 bucket replication can also be used for cross-account replication, where data is replicated from a source bucket owned by one AWS account to a destination bucket owned by a different AWS account.", "tags": {"name": "AWS Exfiltration via Bucket Replication", "analytic_story": ["Suspicious AWS S3 Activities", "Data Exfiltration"], "asset_type": "EC2 Snapshot", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1537"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "AWS Bucket Replication rule $rule$ added on $source_bucket$ to $destination_bucket$ by user $user_arn$ from IP Address - $src_ip$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail`  eventName = PutBucketReplication eventSource = s3.amazonaws.com |  rename requestParameters.* as * | stats count values(bucketName) as source_bucket values(ReplicationConfiguration.Rule.ID) as rule_id values(ReplicationConfiguration.Rule.Destination.Bucket) as destination_bucket by _time user_arn userName user_type src_ip aws_account_id userIdentity.principalId user_agent | `aws_exfiltration_via_ec2_snapshot_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that an AWS admin has legitimately implemented data replication to ensure data availability and improve data protection/backup strategies.", "check_references": false, "references": ["https://hackingthe.cloud/aws/exploitation/s3-bucket-replication-exfiltration/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_exfiltration_via_bucket_replication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Exfiltration via Bucket Replication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1119/aws_exfil_datasync/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1119/aws_exfil_datasync/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Exfiltration via DataSync Task", "author": "Bhavin Patel, Splunk", "date": "2023-04-10", "version": 1, "id": "05c4b09f-ea28-4c7c-a7aa-a246f665c8a2", "description": "This search looks for potential misuse of an AWS service known as DataSync. This AWS service is used to transfer data between different AWS cloud storage services, such as Amazon S3, Amazon EFS, and Amazon FSx for Windows File Server. Attackers can create a task in AWS to periodically copy data from a private AWS location to a public location resulting in the compromise of the data.", "tags": {"name": "AWS Exfiltration via DataSync Task", "analytic_story": ["Suspicious AWS S3 Activities", "Data Exfiltration"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1119"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "DataSync task created on account id - $aws_account_id$ by user $user_arn$ from src_ip $src_ip$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName = CreateTask eventSource=\"datasync.amazonaws.com\" | rename  requestParameters.*  as *  | stats count min(_time) as firstTime max(_time) as lastTime by src_ip aws_account_id awsRegion eventName destinationLocationArn sourceLocationArn userAgent user_arn userIdentity.principalId  errorCode | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_exfiltration_via_datasync_task_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "It is possible that an AWS Administrator has legitimately created this task for creating backup. Please check the `sourceLocationArn` and `destinationLocationArn` of this task", "check_references": false, "references": ["https://labs.nettitude.com/blog/how-to-exfiltrate-aws-ec2-data/", "https://www.shehackske.com/how-to/data-exfiltration-on-cloud-1606/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_exfiltration_via_datasync_task_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Exfiltration via DataSync Task:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1119/aws_exfil_datasync/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1119/aws_exfil_datasync/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Exfiltration via EC2 Snapshot", "author": "Bhavin Patel, Splunk", "date": "2023-03-22", "version": 1, "id": "ac90b339-13fc-4f29-a18c-4abbba1f2171", "description": "This search detects a series of AWS API calls, made in a short time window, related to EC2 snapshots that can detect a potential exfiltration via EC2 Snapshot modifications. In this attack, the attacker typically proceeds by listing and creating EC2 snapshots of the available EC2 instances followed by modifying snapshot attributes such that it can be shared externally. Once this is done, the attacker can then load that EC2 snapshot and access all the sensitive information.", "tags": {"name": "AWS Exfiltration via EC2 Snapshot", "analytic_story": ["Suspicious Cloud Instance Activities", "Data Exfiltration"], "asset_type": "EC2 Snapshot", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1537"], "nist": ["DE.CM"], "observable": [{"name": "userName", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "aws_account_id", "type": "Other", "role": ["Victim"]}], "message": "Potential AWS EC2 Exfiltration detected on account id - $aws_account_id$ by user $userName$ from src_ip $src_ip$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName IN (\"CreateSnapshot\", \"DescribeSnapshotAttribute\", \"ModifySnapshotAttribute\", \"DeleteSnapshot\") src_ip !=\"guardduty.amazonaws.com\" |  bin _time span=5m |  stats count dc(eventName) as distinct_api_calls values(eventName)  values(requestParameters.attributeType) as attributeType values(requestParameters.createVolumePermission.add.items{}.userId) as aws_account_id_added values(userAgent) as userAgent by _time userName src_ip aws_account_id | where distinct_api_calls >= 2 | `aws_exfiltration_via_ec2_snapshot_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs. We have intentionally removed `guardduty.amazonaws.com` from src_ip to remove false positives caused by guard duty. We recommend you adjust the time window as per your environment.", "known_false_positives": "It is possible that an AWS admin has legitimately shared a snapshot with an other account for a specific purpose. Please check any recent change requests filed in your organization.", "check_references": false, "references": ["https://labs.nettitude.com/blog/how-to-exfiltrate-aws-ec2-data/", "https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_ModifySnapshotAttribute.html", "https://bleemb.medium.com/data-exfiltration-with-native-aws-s3-features-c94ae4d13436", "https://stratus-red-team.cloud/attack-techniques/list/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_exfiltration_via_ec2_snapshot_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Exfiltration via EC2 Snapshot:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_snapshot_exfil/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_snapshot_exfil/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS High Number Of Failed Authentications For User", "author": "Bhavin Patel, Splunk", "date": "2023-01-27", "version": 1, "id": "e3236f49-daf3-4b70-b808-9290912ac64d", "description": "The following analytic identifies an AWS account with more than 20 failed authentication events in the span of 5 minutes. This behavior could represent a brute force attack against the account. As environments differ across organizations, security teams should customize the threshold of this detection.", "tags": {"name": "AWS High Number Of Failed Authentications For User", "analytic_story": ["Compromised User Account", "AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1201"], "nist": ["DE.AE"], "observable": [{"name": "user_name", "type": "User", "role": ["Attacker"]}], "message": "User $user_name$ failed to authenticate more than 20 times in the span of 5 minutes for AWS Account $aws_account_id$", "risk_score": 35, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=ConsoleLogin action=failure | bucket span=10m _time | stats dc(_raw) AS failed_attempts values(src_ip) as src_ip values(user_agent) by _time, user_name, eventName, eventSource aws_account_id | where failed_attempts > 20 | `aws_high_number_of_failed_authentications_for_user_filter`", "how_to_implement": "You must install Splunk AWS Add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "A user with more than 20 failed authentication attempts in the span of 5 minutes may also be triggered by a broken application.", "check_references": false, "references": ["https://www.trendmicro.com/cloudoneconformity/knowledge-base/aws/IAM/password-policy.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_high_number_of_failed_authentications_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS High Number Of Failed Authentications For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_multiple_login_fail_per_user/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_multiple_login_fail_per_user/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS High Number Of Failed Authentications From Ip", "author": "Bhavin Patel, Splunk", "date": "2023-01-30", "version": 1, "id": "f75b7f1a-b8eb-4975-a214-ff3e0a944757", "description": "The following analytic identifies an IP address failing to authenticate 20 or more times to the AWS Web Console in the span of 5 minutes. This behavior could represent a brute force attack against an AWS tenant to obtain initial access or elevate privileges. As environments differ across organizations, security teams should customize the threshold of this detection.", "tags": {"name": "AWS High Number Of Failed Authentications From Ip", "analytic_story": ["AWS Identity and Access Management Account Takeover", "Compromised User Account"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "tried_accounts", "type": "User", "role": ["Victim"]}], "message": "Multiple failed console login attempts against users $tried_accounts$ seen from $src_ip$", "risk_score": 54, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=ConsoleLogin action=failure | bucket span=5m _time | stats dc(_raw) AS failed_attempts values(user_name) as tried_accounts values(user_agent) by _time, src_ip, eventName, eventSource aws_account_id | where failed_attempts > 20 | `aws_high_number_of_failed_authentications_from_ip_filter`", "how_to_implement": "You must install Splunk Add-on for AWS in order to ingest Cloudtrail. We recommend the users to try different combinations of the bucket span time and the tried account threshold to tune this search according to their environment.", "known_false_positives": "An Ip address with more than 20 failed authentication attempts in the span of 5 minutes may also be triggered by a broken application.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://www.whiteoaksecurity.com/blog/goawsconsolespray-password-spraying-tool/", "https://softwaresecuritydotblog.wordpress.com/2019/09/28/how-to-protect-against-credential-stuffing-on-aws/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_high_number_of_failed_authentications_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS High Number Of Failed Authentications From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_mulitple_failed_console_login/aws_cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_mulitple_failed_console_login/aws_cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS IAM AccessDenied Discovery Events", "author": "Michael Haag, Splunk", "date": "2021-11-12", "version": 2, "id": "3e1f1568-9633-11eb-a69c-acde48001122", "description": "The following detection identifies excessive AccessDenied events within an hour timeframe. It is possible that an access key to AWS may have been stolen and is being misused to perform discovery events. In these instances, the access is not available with the key stolen therefore these events will be generated.", "tags": {"name": "AWS IAM AccessDenied Discovery Events", "analytic_story": ["Suspicious Cloud User Activities"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1580"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "userIdentity.arn", "type": "User", "role": ["Attacker"]}], "message": "User $userIdentity.arn$ is seen to perform excessive number of discovery related api calls- $failures$, within an hour where the access was denied.", "risk_score": 10, "security_domain": "access", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` (errorCode = \"AccessDenied\") user_type=IAMUser (userAgent!=*.amazonaws.com) | bucket _time span=1h | stats count as failures min(_time) as firstTime max(_time) as lastTime, dc(eventName) as methods, dc(eventSource) as sources by src_ip, userIdentity.arn, _time | where failures >= 5 and methods >= 1 and sources >= 1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_iam_accessdenied_discovery_events_filter`", "how_to_implement": "The Splunk AWS Add-on and Splunk App for AWS is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "It is possible to start this detection will need to be tuned by source IP or user. In addition, change the count values to an upper threshold to restrict false positives.", "check_references": false, "references": ["https://aws.amazon.com/premiumsupport/knowledge-center/troubleshoot-iam-permission-errors/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_iam_accessdenied_discovery_events_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS IAM AccessDenied Discovery Events:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1580/aws_iam_accessdenied_discovery_events/aws_iam_accessdenied_discovery_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1580/aws_iam_accessdenied_discovery_events/aws_iam_accessdenied_discovery_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS IAM Assume Role Policy Brute Force", "author": "Michael Haag, Splunk", "date": "2021-04-01", "version": 1, "id": "f19e09b0-9308-11eb-b7ec-acde48001122", "description": "The following detection identifies any malformed policy document exceptions with a status of `failure`. A malformed policy document exception occurs in instances where roles are attempted to be assumed, or brute forced. In a brute force attempt, using a tool like CloudSploit or Pacu, an attempt will look like `arn:aws:iam::111111111111:role/aws-service-role/rds.amazonaws.com/AWSServiceRoleForRDS`.  Meaning, when an adversary is attempting to identify a role name, multiple failures will occur. This detection focuses on the errors of a remote attempt that is failing.", "tags": {"name": "AWS IAM Assume Role Policy Brute Force", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1580", "T1110"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has caused multiple failures with errorCode $errorCode$, which potentially means adversary is attempting to identify a role name.", "risk_score": 28, "security_domain": "access", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` (errorCode=MalformedPolicyDocumentException) status=failure (userAgent!=*.amazonaws.com) | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.policyName) as policy_name by src eventName eventSource aws_account_id errorCode requestParameters.policyDocument userAgent eventID awsRegion userIdentity.principalId user_arn | where count >= 2 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_iam_assume_role_policy_brute_force_filter`", "how_to_implement": "The Splunk AWS Add-on and Splunk App for AWS is required to utilize this data. The search requires AWS Cloudtrail logs. Set the `where count` greater than a value to identify suspicious activity in your environment.", "known_false_positives": "This detection will require tuning to provide high fidelity detection capabilties. Tune based on src addresses (corporate offices, VPN terminations) or by groups of users.", "check_references": false, "references": ["https://www.praetorian.com/blog/aws-iam-assume-role-vulnerabilities/", "https://rhinosecuritylabs.com/aws/assume-worst-aws-assume-role-enumeration/", "https://www.elastic.co/guide/en/security/current/aws-iam-brute-force-of-assume-role-policy.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_iam_assume_role_policy_brute_force_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS IAM Assume Role Policy Brute Force:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1580/aws_iam_assume_role_policy_brute_force/aws_iam_assume_role_policy_brute_force.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1580/aws_iam_assume_role_policy_brute_force/aws_iam_assume_role_policy_brute_force.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS IAM Delete Policy", "author": "Michael Haag, Splunk", "date": "2021-04-01", "version": 1, "id": "ec3a9362-92fe-11eb-99d0-acde48001122", "description": "The following detection identifies when a policy is deleted on AWS. This does not identify whether successful or failed, but the error messages tell a story of suspicious attempts. There is a specific process to follow when deleting a policy. First, detach the policy from all users, groups, and roles that the policy is attached to, using DetachUserPolicy , DetachGroupPolicy , or DetachRolePolicy.", "tags": {"name": "AWS IAM Delete Policy", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has deleted AWS Policies from IP address $src$ by executing the following command $eventName$", "risk_score": 10, "security_domain": "access", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=DeletePolicy (userAgent!=*.amazonaws.com) | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.policyArn) as policyArn by src user_arn eventName eventSource aws_account_id errorCode errorMessage userAgent eventID awsRegion userIdentity.principalId | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_iam_delete_policy_filter`", "how_to_implement": "The Splunk AWS Add-on and Splunk App for AWS is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "This detection will require tuning to provide high fidelity detection capabilties. Tune based on src addresses (corporate offices, VPN terminations) or by groups of users. Not every user with AWS access should have permission to delete policies (least privilege). In addition, this may be saved seperately and tuned for failed or success attempts only.", "check_references": false, "references": ["https://docs.aws.amazon.com/IAM/latest/APIReference/API_DeletePolicy.html", "https://docs.aws.amazon.com/cli/latest/reference/iam/delete-policy.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_iam_delete_policy_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS IAM Delete Policy:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_delete_policy/aws_iam_delete_policy.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_delete_policy/aws_iam_delete_policy.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS IAM Failure Group Deletion", "author": "Michael Haag, Splunk", "date": "2023-11-07", "version": 2, "id": "723b861a-92eb-11eb-93b8-acde48001122", "description": "This detection identifies failure attempts to delete groups. We want to identify when a group is attempting to be deleted, but either access is denied, there is a conflict or there is no group. This is indicative of administrators performing an action, but also could be suspicious behavior occurring. Review parallel IAM events - recently added users, new groups and so forth.", "tags": {"name": "AWS IAM Failure Group Deletion", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has had mulitple failures while attempting to delete groups from $src$", "risk_score": 5, "security_domain": "cloud", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=iam.amazonaws.com eventName=DeleteGroup errorCode IN (NoSuchEntityException,DeleteConflictException, AccessDenied) (userAgent!=*.amazonaws.com) | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.groupName) as group_name by src eventName eventSource aws_account_id errorCode errorMessage userAgent eventID awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_iam_failure_group_deletion_filter`", "how_to_implement": "The Splunk AWS Add-on and Splunk App for AWS is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "This detection will require tuning to provide high fidelity detection capabilties. Tune based on src addresses (corporate offices, VPN terminations) or by groups of users. Not every user with AWS access should have permission to delete groups (least privilege).", "check_references": false, "references": ["https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-group.html", "https://docs.aws.amazon.com/IAM/latest/APIReference/API_DeleteGroup.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_iam_failure_group_deletion_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS IAM Failure Group Deletion:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_failure_group_deletion/aws_iam_failure_group_deletion.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_failure_group_deletion/aws_iam_failure_group_deletion.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS IAM Successful Group Deletion", "author": "Michael Haag, Splunk", "date": "2021-03-31", "version": 1, "id": "e776d06c-9267-11eb-819b-acde48001122", "description": "The following query uses IAM events to track the success of a group being deleted on AWS. This is typically not indicative of malicious behavior, but a precurser to additional events thay may unfold. Review parallel IAM events - recently added users, new groups and so forth. Inversely, review failed attempts in a similar manner.", "tags": {"name": "AWS IAM Successful Group Deletion", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1069.003", "T1098", "T1069"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}, {"name": "group_deleted", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has sucessfully deleted mulitple groups $group_deleted$ from $src$", "risk_score": 5, "security_domain": "cloud", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=iam.amazonaws.com eventName=DeleteGroup errorCode=success (userAgent!=*.amazonaws.com) | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.groupName) as group_deleted by src eventName eventSource errorCode user_agent awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_iam_successful_group_deletion_filter`", "how_to_implement": "The Splunk AWS Add-on and Splunk App for AWS is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "This detection will require tuning to provide high fidelity detection capabilties. Tune based on src addresses (corporate offices, VPN terminations) or by groups of users. Not every user with AWS access should have permission to delete groups (least privilege).", "check_references": false, "references": ["https://awscli.amazonaws.com/v2/documentation/api/latest/reference/iam/delete-group.html", "https://docs.aws.amazon.com/IAM/latest/APIReference/API_DeleteGroup.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_iam_successful_group_deletion_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS IAM Successful Group Deletion:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_successful_group_deletion/aws_iam_successful_group_deletion.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/aws_iam_successful_group_deletion/aws_iam_successful_group_deletion.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Lambda UpdateFunctionCode", "author": "Bhavin Patel, Splunk", "date": "2022-02-24", "version": 1, "id": "211b80d3-6340-4345-11ad-212bf3d0d111", "description": "This analytic is designed to detect IAM users attempting to update/modify AWS lambda code via the AWS CLI to gain persistence, futher access into your AWS environment and to facilitate planting backdoors. In this instance, an attacker may upload malicious code/binary to a lambda function which will be executed automatically when the funnction is triggered.", "tags": {"name": "AWS Lambda UpdateFunctionCode", "analytic_story": ["Suspicious Cloud User Activities"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Attacker"]}], "message": "User $user_arn$ is attempting to update the lambda function code of $function_updated$ from this IP $src_ip$", "risk_score": 63, "security_domain": "cloud", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=lambda.amazonaws.com eventName=UpdateFunctionCode*  errorCode = success  user_type=IAMUser | stats  count min(_time) as firstTime max(_time) as lastTime  values(requestParameters.functionName) as function_updated by src_ip user_arn user_agent user_type eventName aws_account_id |`aws_lambda_updatefunctioncode_filter`", "how_to_implement": "You must install Splunk AWS Add on and enable Cloudtrail logs in your AWS Environment.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin or an autorized IAM user has updated the lambda fuction code legitimately.", "check_references": false, "references": ["http://detectioninthe.cloud/execution/modify_lambda_function_code/", "https://sysdig.com/blog/exploit-mitigate-aws-lambdas-mitre/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_lambda_updatefunctioncode_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Lambda UpdateFunctionCode:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/aws_updatelambdafunctioncode/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/aws_updatelambdafunctioncode/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Multi-Factor Authentication Disabled", "author": "Bhavin Patel, Splunk", "date": "2022-10-04", "version": 1, "id": "374832b1-3603-420c-b456-b373e24d34c0", "description": "The following analytic identifies an attempt to disable multi-factor authentication for an AWS IAM user. An adversary who has obtained access to an AWS tenant may disable multi-factor authentication as a way to plant a backdoor and maintain persistence using a valid account. This way the attackers can keep persistance in the environment without adding new users.", "tags": {"name": "AWS Multi-Factor Authentication Disabled", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1621", "T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "aws_account_id", "type": "Other", "role": ["Victim"]}, {"name": "user_name", "type": "User", "role": ["Victim"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user_name$ has disabled Multi-Factor authentication for AWS account $aws_account_id$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` (eventName= DeleteVirtualMFADevice OR eventName=DeactivateMFADevice) | stats count min(_time) as firstTime max(_time) as lastTime by src eventName eventSource aws_account_id userAgent eventID awsRegion user_name userIdentity.arn status | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_multi_factor_authentication_disabled_filter`", "how_to_implement": "The Splunk AWS Add-on is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "AWS Administrators may disable MFA but it is highly unlikely for this event to occur without prior notice to the company", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://aws.amazon.com/what-is/mfa/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_multi_factor_authentication_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Multi-Factor Authentication Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_mfa_disabled/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_mfa_disabled/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Multiple Failed MFA Requests For User", "author": "Bhavin Patel", "date": "2022-10-03", "version": 1, "id": "1fece617-e614-4329-9e61-3ba228c0f353", "description": "The following analytic identifies multiple failed multi-factor authentication requests to an AWS Console for a single user. AWS Cloudtrail logs provide a a very useful field called `additionalEventData` that logs information regarding usage of MFA. Specifically, the analytic triggers when more than 10 MFA user prompts fail within 10 minutes. AWS Environments can be very different depending on the organization, Security teams should test this detection and customize these arbitrary thresholds. The detected behavior may represent an adversary who has obtained legitimate credentials for a user and continuously repeats login attempts in order to bombard users with MFA push notifications, SMS messages, and phone calls potentially resulting in the user finally accepting the authentication request. Threat actors like the Lapsus team and APT29 have leveraged this technique to bypass multi-factor authentication controls as reported by Mandiant and others.", "tags": {"name": "AWS Multiple Failed MFA Requests For User", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1621"], "nist": ["DE.AE"], "observable": [{"name": "user_name", "type": "User", "role": ["Victim"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user_name$ is seen to have high number of MFA prompt failures within a short period of time.", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName= ConsoleLogin \"additionalEventData.MFAUsed\"=Yes errorMessage=\"Failed authentication\" | bucket span=5m _time |  stats dc(_raw) as mfa_prompts values(userAgent) as userAgent values(src) as src by _time user_name user_arn aws_account_id eventName errorMessage | where mfa_prompts > 10| `aws_multiple_failed_mfa_requests_for_user_filter`", "how_to_implement": "The Splunk AWS Add-on is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "Multiple Failed MFA requests may also be a sign of authentication or application issues. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://aws.amazon.com/what-is/mfa/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_multiple_failed_mfa_requests_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Multiple Failed MFA Requests For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_failed_mfa/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/aws_failed_mfa/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Multiple Users Failing To Authenticate From Ip", "author": "Bhavin Patel", "date": "2022-09-27", "version": 1, "id": "71e1fb89-dd5f-4691-8523-575420de4630", "description": "The following analytic identifies one source Ip failing to authenticate into the AWS Console with 30 unique valid users within 10 minutes. This behavior could represent an adversary performing a Password Spraying attack against an AWS environment tenant to obtain initial access or elevate privileges.", "tags": {"name": "AWS Multiple Users Failing To Authenticate From Ip", "analytic_story": ["AWS Identity and Access Management Account Takeover", "Compromised User Account"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "tried_accounts", "type": "User", "role": ["Victim"]}], "message": "Multiple failed console login attempts against users $tried_accounts$ seen from $src_ip$", "risk_score": 54, "security_domain": "threat", "risk_severity": "medium", "manual_test": "This search needs a specific number of events in a time window for the alert to trigger and events split up in CI testing while updating timestamp.", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=ConsoleLogin action=failure | bucket span=10m _time | stats  dc(user_name) AS unique_accounts values(user_name) as tried_accounts by _time, src_ip, eventName, action, user_agent |  where unique_accounts > 30 |`aws_unusual_number_of_failed_authentications_from_ip_filter`", "how_to_implement": "You must install Splunk Add-on for AWS in order to ingest Cloudtrail. We recommend the users to try different combinations of the bucket span time and the tried account threshold to tune this search according to their environment.", "known_false_positives": "No known false postives for this detection. Please review this alert", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://www.whiteoaksecurity.com/blog/goawsconsolespray-password-spraying-tool/", "https://softwaresecuritydotblog.wordpress.com/2019/09/28/how-to-protect-against-credential-stuffing-on-aws/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_multiple_users_failing_to_authenticate_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Multiple Users Failing To Authenticate From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_mulitple_failed_console_login/aws_cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_mulitple_failed_console_login/aws_cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "AWS Network Access Control List Created with All Open Ports", "author": "Bhavin Patel, Patrick Bareiss, Splunk", "date": "2021-01-11", "version": 2, "id": "ada0f478-84a8-4641-a3f1-d82362d6bd75", "description": "The search looks for AWS CloudTrail events to detect if any network ACLs were created with all the ports open to a specified CIDR.", "tags": {"name": "AWS Network Access Control List Created with All Open Ports", "analytic_story": ["AWS Network ACL Activity"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.007", "T1562"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has created network ACLs with all the ports open to a specified CIDR $requestParameters.cidrBlock$", "risk_score": 48, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=CreateNetworkAclEntry OR eventName=ReplaceNetworkAclEntry requestParameters.ruleAction=allow requestParameters.egress=false requestParameters.aclProtocol=-1 | append [search `cloudtrail` eventName=CreateNetworkAclEntry OR eventName=ReplaceNetworkAclEntry requestParameters.ruleAction=allow requestParameters.egress=false requestParameters.aclProtocol!=-1 | eval port_range='requestParameters.portRange.to' - 'requestParameters.portRange.from' | where port_range>1024] | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by userName user_arn userIdentity.principalId eventName requestParameters.ruleAction requestParameters.egress requestParameters.aclProtocol requestParameters.portRange.to requestParameters.portRange.from src userAgent requestParameters.cidrBlock | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_network_access_control_list_created_with_all_open_ports_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS, version 4.4.0 or later, and configure your AWS CloudTrail inputs.", "known_false_positives": "It's possible that an admin has created this ACL with all ports open for some legitimate purpose however, this should be scoped and not allowed in production environment.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_network_access_control_list_created_with_all_open_ports_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Network Access Control List Created with All Open Ports:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.007/aws_create_acl/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.007/aws_create_acl/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Network Access Control List Deleted", "author": "Bhavin Patel, Patrick Bareiss, Splunk", "date": "2021-01-12", "version": 2, "id": "ada0f478-84a8-4641-a3f1-d82362d6fd75", "description": "Enforcing network-access controls is one of the defensive mechanisms used by cloud administrators to restrict access to a cloud instance. After the attacker has gained control of the AWS console by compromising an admin account, they can delete a network ACL and gain access to the instance from anywhere. This search will query the AWS CloudTrail logs to detect users deleting network ACLs.", "tags": {"name": "AWS Network Access Control List Deleted", "analytic_story": ["AWS Network ACL Activity"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.007", "T1562"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ from $src$ has sucessfully deleted network ACLs entry (eventName= $eventName$), such that the instance is accessible from anywhere", "risk_score": 5, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=DeleteNetworkAclEntry requestParameters.egress=false | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by user_arn userIdentity.principalId eventName requestParameters.egress src userAgent | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `aws_network_access_control_list_deleted_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your AWS CloudTrail inputs.", "known_false_positives": "It's possible that a user has legitimately deleted a network ACL.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_network_access_control_list_deleted_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Network Access Control List Deleted:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.007/aws_delete_acl/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.007/aws_delete_acl/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS New MFA Method Registered For User", "author": "Bhavin Patel, Splunk", "date": "2023-01-31", "version": 1, "id": "4e3c26f2-4fb9-4bd7-ab46-1b76ffa2a23b", "description": "The following analytic identifies the registration of a new Multi Factor authentication method for an AWS account. Adversaries who have obtained unauthorized access to an AWS account may register a new MFA method to maintain persistence.", "tags": {"name": "AWS New MFA Method Registered For User", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "A new virtual device $virtualMFADeviceName$ is added to user $user_arn$", "risk_score": 64, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `cloudtrail` eventName=CreateVirtualMFADevice | stats count values(requestParameters.virtualMFADeviceName) as virtualMFADeviceName min(_time) as firstTime max(_time) as lastTime by eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_new_mfa_method_registered_for_user_filter`", "how_to_implement": "You must install Splunk AWS add on and Splunk App for AWS. This search works when AWS CloudTrail logs.", "known_false_positives": "Newly onboarded users who are registering an MFA method for the first time will also trigger this detection.", "check_references": false, "references": ["https://aws.amazon.com/blogs/security/you-can-now-assign-multiple-mfa-devices-in-iam/", "https://attack.mitre.org/techniques/T1556/", "https://attack.mitre.org/techniques/T1556/006/", "https://twitter.com/jhencinski/status/1618660062352007174"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_new_mfa_method_registered_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS New MFA Method Registered For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556.006/aws_new_mfa_method_registered_for_user/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556.006/aws_new_mfa_method_registered_for_user/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Password Policy Changes", "author": "Bhavin Patel, Splunk", "date": "2023-01-26", "version": 1, "id": "aee4a575-7064-4e60-b511-246f9baf9895", "description": "This search looks for AWS CloudTrail events where a user is making successful API calls to view/update/delete the existing password policy in an AWS organization. It is unlikely for a regular user to conduct this operation. These events may potentially be malicious, adversaries often use this information to gain more understanding of the password defenses in place and exploit them to increase their attack surface when a user account is compromised.", "tags": {"name": "AWS Password Policy Changes", "analytic_story": ["AWS IAM Privilege Escalation", "Compromised User Account"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1201"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Attacker"]}], "message": "User $user_arn$ is attempting to $eventName$ the password policy for account id $aws_account_id$", "risk_score": 72, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName IN (\"UpdateAccountPasswordPolicy\",\"GetAccountPasswordPolicy\",\"DeleteAccountPasswordPolicy\") errorCode=success | stats count values(eventName) as eventName values(userAgent) min(_time) as firstTime max(_time) as lastTime by eventSource aws_account_id errorCode  awsRegion userIdentity.principalId user_arn src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`  | `aws_password_policy_changes_filter`", "how_to_implement": "You must install Splunk AWS Add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately triggered an AWS audit tool activity which may trigger this event.", "check_references": false, "references": ["https://www.trendmicro.com/cloudoneconformity/knowledge-base/aws/IAM/password-policy.html"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_password_policy_changes_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Password Policy Changes:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1201/aws_password_policy/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1201/aws_password_policy/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS S3 Exfiltration Behavior Identified", "author": "Bhavin Patel, Splunk", "date": "2023-11-07", "version": 2, "id": "85096389-a443-42df-b89d-200efbb1b560", "description": "This correlation search looks at the risk events created by the detection analytics related Collection and Exfiltration techniques used by adversaries. The rule is designed to identify instances where 2 or more analytics unique AWS analytics and 2 or more distinct mitre IDs has triggered for a particular risk object. This alert when triggered may indicate a potential exfiltration in progress. By aggregating these analytics, security teams can swiftly respond to and investigate any suspicious activities, enhancing their ability to protect critical assets and prevent unauthorized access to sensitive information.", "tags": {"name": "AWS S3 Exfiltration Behavior Identified", "analytic_story": ["Suspicious Cloud Instance Activities", "Data Exfiltration"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1537"], "nist": ["DE.AE"], "observable": [{"name": "risk_object", "type": "Hostname", "role": ["Victim"]}], "message": "Multiple AWS Exfiltration detections $source$ and techniques $annotations.mitre_attack.mitre_tactic_id$ trigged for risk object $risk_object$", "risk_score": 81, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "| tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime sum(All_Risk.calculated_risk_score) as risk_score, count(All_Risk.calculated_risk_score) as risk_event_count, values(All_Risk.annotations.mitre_attack.mitre_tactic_id) as annotations.mitre_attack.mitre_tactic_id, dc(All_Risk.annotations.mitre_attack.mitre_tactic_id) as mitre_tactic_id_count, values(All_Risk.annotations.mitre_attack.mitre_technique_id) as annotations.mitre_attack.mitre_technique_id, dc(All_Risk.annotations.mitre_attack.mitre_technique_id) as mitre_technique_id_count, values(All_Risk.tag) as tag, values(source) as source, dc(source) as source_count values(All_Risk.risk_message) as risk_message  from datamodel=Risk.All_Risk where All_Risk.annotations.mitre_attack.mitre_tactic = \"collection\" OR All_Risk.annotations.mitre_attack.mitre_tactic = \"exfiltration\" source = *AWS*  by All_Risk.risk_object | `drop_dm_object_name(All_Risk)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | where source_count >= 2 and mitre_tactic_id_count>=2 | `aws_s3_exfiltration_behavior_identified_filter`", "how_to_implement": "You must enable all the detection searches in the Data Exfiltration Analytic story to create risk events in Enterprise Security.", "known_false_positives": "alse positives may be present based on automated tooling or system administrators. Filter as needed.", "check_references": false, "references": ["https://labs.nettitude.com/blog/how-to-exfiltrate-aws-ec2-data/", "https://stratus-red-team.cloud/attack-techniques/AWS/aws.exfiltration.ec2-share-ebs-snapshot/", "https://hackingthe.cloud/aws/enumeration/loot_public_ebs_snapshots/"], "datamodel": ["Risk"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "security_content_summariesonly", "definition": "summariesonly=false allow_old_summaries=true fillnull_value=null", "description": "search data model's summaries only"}, {"name": "aws_s3_exfiltration_behavior_identified_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": [{"name": "AWS S3 Exfiltration Behavior Identified:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_exfil_risk_events/aws_risk.log", "source": "aws_exfil", "sourcetype": "stash", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1537/aws_exfil_risk_events/aws_risk.log", "source": "aws_exfil", "sourcetype": "stash", "update_timestamp": true}]}]}, {"name": "AWS SAML Access by Provider User and Principal", "author": "Rod Soto, Splunk", "date": "2021-01-26", "version": 1, "id": "bbe23980-6019-11eb-ae93-0242ac130002", "description": "This search provides specific SAML access from specific Service Provider, user and targeted principal at AWS. This search provides specific information to detect abnormal access or potential credential hijack or forgery, specially in federated environments using SAML protocol inside the perimeter or cloud provider.", "tags": {"name": "AWS SAML Access by Provider User and Principal", "analytic_story": ["Cloud Federated Credential Abuse"], "asset_type": "AWS Federated Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "sourceIPAddress", "type": "IP Address", "role": ["Attacker"]}, {"name": "recipientAccountId", "type": "Other", "role": ["Victim", "Target"]}], "message": "From IP address $sourceIPAddress$, user agent $userAgent$ has trigged an event $eventName$ for account ID $recipientAccountId$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=Assumerolewithsaml | stats count min(_time) as firstTime max(_time) as lastTime by requestParameters.principalArn requestParameters.roleArn requestParameters.roleSessionName recipientAccountId responseElements.issuer sourceIPAddress userAgent | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_saml_access_by_provider_user_and_principal_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs", "known_false_positives": "Attacks using a Golden SAML or SAML assertion hijacks or forgeries are very difficult to detect as accessing cloud providers with these assertions looks exactly like normal access, however things such as source IP sourceIPAddress user, and principal targeted at receiving cloud provider along with endpoint credential access and abuse detection searches can provide the necessary context to detect these attacks.", "check_references": false, "references": ["https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://www.splunk.com/en_us/blog/security/a-golden-saml-journey-solarwinds-continued.html", "https://www.fireeye.com/content/dam/fireeye-www/blog/pdfs/wp-m-unc2452-2021-000343-01.pdf", "https://www.cyberark.com/resources/threat-research-blog/golden-saml-newly-discovered-attack-technique-forges-authentication-to-cloud-apps"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_saml_access_by_provider_user_and_principal_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS SAML Access by Provider User and Principal:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/assume_role_with_saml/assume_role_with_saml.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/assume_role_with_saml/assume_role_with_saml.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS SAML Update identity provider", "author": "Rod Soto, Splunk", "date": "2021-01-26", "version": 1, "id": "2f0604c6-6030-11eb-ae93-0242ac130002", "description": "This search provides detection of updates to SAML provider in AWS. Updates to SAML provider need to be monitored closely as they may indicate possible perimeter compromise of federated credentials, or backdoor access from another cloud provider set by attacker.", "tags": {"name": "AWS SAML Update identity provider", "analytic_story": ["Cloud Federated Credential Abuse"], "asset_type": "AWS Federated Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.CM"], "observable": [{"name": "sourceIPAddress", "type": "IP Address", "role": ["Attacker"]}, {"name": "userIdentity.principalId", "type": "User", "role": ["Victim", "Target"]}], "message": "User $userIdentity.principalId$ from IP address $sourceIPAddress$ has trigged an event $eventName$ to update the SAML provider to $requestParameters.sAMLProviderArn$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=UpdateSAMLProvider | stats count min(_time) as firstTime max(_time) as lastTime by eventType eventName requestParameters.sAMLProviderArn userIdentity.sessionContext.sessionIssuer.arn sourceIPAddress userIdentity.accessKeyId userIdentity.principalId | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` |`aws_saml_update_identity_provider_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "Updating a SAML provider or creating a new one may not necessarily be malicious however it needs to be closely monitored.", "check_references": false, "references": ["https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://www.splunk.com/en_us/blog/security/a-golden-saml-journey-solarwinds-continued.html", "https://www.fireeye.com/content/dam/fireeye-www/blog/pdfs/wp-m-unc2452-2021-000343-01.pdf", "https://www.cyberark.com/resources/threat-research-blog/golden-saml-newly-discovered-attack-technique-forges-authentication-to-cloud-apps"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_saml_update_identity_provider_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS SAML Update identity provider:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/update_saml_provider/update_saml_provider.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/update_saml_provider/update_saml_provider.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS SetDefaultPolicyVersion", "author": "Bhavin Patel, Splunk", "date": "2021-03-02", "version": 1, "id": "2a9b80d3-6340-4345-11ad-212bf3d0dac4", "description": "This search looks for AWS CloudTrail events where a user has set a default policy versions. Attackers have been know to use this technique for Privilege Escalation in case the previous versions of the policy had permissions to access more resources than the current version of the policy", "tags": {"name": "AWS SetDefaultPolicyVersion", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "From IP address $src$, user $user_arn$ has trigged an event $eventName$ for updating the the default policy version", "risk_score": 30, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=SetDefaultPolicyVersion eventSource = iam.amazonaws.com | stats count min(_time) as firstTime max(_time) as lastTime values(requestParameters.policyArn) as policy_arn by src requestParameters.versionId eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.principalId user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_setdefaultpolicyversion_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately set a default policy to allow a user to access all resources. That said, AWS strongly advises against granting full control to all AWS resources", "check_references": false, "references": ["https://bishopfox.com/blog/privilege-escalation-in-aws", "https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation-part-2/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_setdefaultpolicyversion_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS SetDefaultPolicyVersion:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_setdefaultpolicyversion/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_setdefaultpolicyversion/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Successful Console Authentication From Multiple IPs", "author": "Bhavin Patel, Splunk", "date": "2023-11-07", "version": 2, "id": "395e50e1-2b87-4fa3-8632-0dfbdcbcd2cb", "description": "The following analytic identifies an AWS account successfully authenticating from more than one unique Ip address in the span of 5 minutes. This behavior could represent an adversary who has stolen credentials via a phishing attack or some other method and using them to access corporate online resources around the same time as a legitimate user. As users may behave differently across organizations, security teams should test and customize this detection to fit their environments.", "tags": {"name": "AWS Successful Console Authentication From Multiple IPs", "analytic_story": ["Suspicious AWS Login Activities", "Compromised User Account"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1535"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "User $user_arn$ has successfully logged into the AWS Console from different IP addresses $src_ip$ within 5 mins", "risk_score": 72, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `cloudtrail` eventName = ConsoleLogin | bin span=5m _time | stats values(userAgent) as userAgent values(eventName) as eventName values(src_ip) as src_ip dc(src_ip) as distinct_ip_count by _time user_arn | where distinct_ip_count>1 | `aws_successful_console_authentication_from_multiple_ips_filter`", "how_to_implement": "You must install Splunk AWS add on and Splunk App for AWS. This search works when AWS CloudTrail events are normalized use the Authentication datamodel.", "known_false_positives": "A user with successful authentication events from different Ips may also represent the legitimate use of more than one device. Filter as needed and/or customize the threshold to fit your environment.", "check_references": false, "references": ["https://rhinosecuritylabs.com/aws/mfa-phishing-on-aws/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_successful_console_authentication_from_multiple_ips_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Successful Console Authentication From Multiple IPs:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1586.003/aws_console_login_multiple_ips/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1586.003/aws_console_login_multiple_ips/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Successful Single-Factor Authentication", "author": "Bhavin Patel, Splunk", "date": "2022-10-04", "version": 1, "id": "a520b1fe-cc9e-4f56-b762-18354594c52f", "description": "The following analytic identifies a successful Console Login authentication event against an AWS IAM user for an account without Multi-Factor Authentication enabled. This could be evidence of a misconfiguration, a policy violation or an account take over attempt that should be investigated", "tags": {"name": "AWS Successful Single-Factor Authentication", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "user_name", "type": "User", "role": ["Victim"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user_name$ has successfully logged into an AWS Console without Multi-Factor Authentication from $src$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName= ConsoleLogin errorCode=success \"additionalEventData.MFAUsed\"=No | stats count min(_time) as firstTime max(_time) as lastTime by src eventName eventSource aws_account_id errorCode additionalEventData.MFAUsed userAgent eventID awsRegion user_name userIdentity.arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_successful_single_factor_authentication_filter`", "how_to_implement": "The Splunk AWS Add-on is required to utilize this data. The search requires AWS Cloudtrail logs.", "known_false_positives": "It is possible that some accounts do not have MFA enabled for the AWS account however its agaisnt the best practices of securing AWS.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://attack.mitre.org/techniques/T1078/004/", "https://aws.amazon.com/what-is/mfa/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_successful_single_factor_authentication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Successful Single-Factor Authentication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/aws_login_sfa/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/aws_login_sfa/cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS Unusual Number of Failed Authentications From Ip", "author": "Bhavin Patel, Splunk", "date": "2023-11-07", "version": 2, "id": "0b5c9c2b-e2cb-4831-b4f1-af125ceb1386", "description": "The following analytic identifies one source IP failing to authenticate into the AWS Console with multiple valid users. This behavior could represent an adversary performing a Password Spraying attack against an AWS environment to obtain initial access or elevate privileges. The detection calculates the standard deviation for source IP and leverages the 3-sigma statistical rule to identify an unusual number of failed authentication attempts. To customize this analytic, users can try different combinations of the bucket span time and the calculation of the upperBound field. This logic can be used for real time security monitoring as well as threat hunting exercises. While looking for anomalies using statistical methods like the standard deviation can have benefits, we also recommend using threshold-based detections to complement coverage. A similar analytic following the threshold model is `AWS Multiple Users Failing To Authenticate From Ip`.", "tags": {"name": "AWS Unusual Number of Failed Authentications From Ip", "analytic_story": ["AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "tried_accounts", "type": "User", "role": ["Victim"]}], "message": "Unusual number of failed console login attempts against users $tried_accounts$ seen from $src_ip$", "risk_score": 54, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=ConsoleLogin action=failure | bucket span=10m _time | stats  dc(_raw) AS distinct_attempts values(user_name) as tried_accounts by _time, src_ip | eventstats  avg(distinct_attempts) as avg_attempts , stdev(distinct_attempts) as ip_std by _time | eval  upperBound=(avg_attempts+ip_std*3) | eval  isOutlier=if(distinct_attempts > 10 and distinct_attempts >= upperBound, 1, 0) | where isOutlier = 1 |`aws_unusual_number_of_failed_authentications_from_ip_filter`", "how_to_implement": "You must install Splunk Add-on for AWS in order to ingest Cloudtrail. We recommend the users to try different combinations of the bucket span time and the calculation of the upperBound field to tune this search according to their environment", "known_false_positives": "No known false postives for this detection. Please review this alert", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://www.whiteoaksecurity.com/blog/goawsconsolespray-password-spraying-tool/", "https://softwaresecuritydotblog.wordpress.com/2019/09/28/how-to-protect-against-credential-stuffing-on-aws/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "aws_unusual_number_of_failed_authentications_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS Unusual Number of Failed Authentications From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_mulitple_failed_console_login/aws_cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/aws_mulitple_failed_console_login/aws_cloudtrail.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "AWS UpdateLoginProfile", "author": "Bhavin Patel, Splunk", "date": "2022-03-03", "version": 3, "id": "2a9b80d3-6a40-4115-11ad-212bf3d0d111", "description": "This search looks for AWS CloudTrail events where a user A who has already permission to update login profile, makes an API call to update login profile for another user B . Attackers have been know to use this technique for Privilege Escalation in case new victim(user B) has more permissions than old victim(user B)", "tags": {"name": "AWS UpdateLoginProfile", "analytic_story": ["AWS IAM Privilege Escalation"], "asset_type": "AWS Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003", "T1136"], "nist": ["DE.CM"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_arn", "type": "User", "role": ["Victim"]}], "message": "From IP address $src$, user agent $userAgent$ has trigged an event $eventName$ for updating the existing login profile, potentially giving user $user_arn$ more access privilleges", "risk_score": 30, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `cloudtrail` eventName = UpdateLoginProfile userAgent !=console.amazonaws.com errorCode = success | eval match=if(match(userIdentity.userName,requestParameters.userName), 1,0) | search match=0 | stats count min(_time) as firstTime max(_time) as lastTime by requestParameters.userName src eventName eventSource aws_account_id errorCode userAgent eventID awsRegion userIdentity.userName user_arn | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `aws_updateloginprofile_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with AWS CloudTrail logs.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created keys for another user.", "check_references": false, "references": ["https://bishopfox.com/blog/privilege-escalation-in-aws", "https://rhinosecuritylabs.com/aws/aws-privilege-escalation-methods-mitigation-part-2/"], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "aws_updateloginprofile_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "AWS UpdateLoginProfile:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_updateloginprofile/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/aws_updateloginprofile/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Azure Active Directory High Risk Sign-in", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "1ecff169-26d7-4161-9a7b-2ac4c8e61bea", "description": "The following analytic triggers on a high risk sign-in against Azure Active Directory identified by Azure Identity Protection. Identity Protection monitors sign-in events using heuristics and machine learning to identify potentially malicious events and categorizes them in three categories high, medium and low.", "tags": {"name": "Azure Active Directory High Risk Sign-in", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "A high risk event was identified by Identify Protection for user $user$", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=UserRiskEvents properties.riskLevel=high | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by src_ip, activity, riskLevel, riskEventType, additionalInfo | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_active_directory_high_risk_sign_in_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. Specifically, this analytic leverages the RiskyUsers and UserRiskEvents log category in the azure:monitor:aad sourcetype.", "known_false_positives": "Details for the risk calculation algorithm used by Identity Protection are unknown and may be prone to false positives.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://docs.microsoft.com/en-us/azure/active-directory/identity-protection/overview-identity-protection", "https://docs.microsoft.com/en-us/azure/active-directory/identity-protection/concept-identity-protection-risks"], "datamodel": ["Risk"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_active_directory_high_risk_sign_in_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure Active Directory High Risk Sign-in:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/azuread_highrisk/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/azuread_highrisk/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Admin Consent Bypassed by Service Principal", "author": "Mauricio Velazco, Splunk", "date": "2024-02-09", "version": 1, "id": "9d4fea43-9182-4c5a-ada8-13701fd5615d", "description": "This detection focuses on identifying instances in Azure Active Directory where a service principal assigns app roles without standard admin consent, using Entra ID logs. It operates on the azure_monitor_aad data source, scrutinizing the \"Add app role assignment to service principal\" operation, specifically from service principals. The query dissects details such as role ID, value, and description, important for understanding the nature of the roles being assigned. Monitoring this in a SOC is critical as it flags potential bypasses of vital administrative consent processes in Azure AD, which could result in unauthorized privileges being granted. A true positive detection suggests that a service principal may be exploiting automation to assign sensitive permissions without proper oversight.", "tags": {"name": "Azure AD Admin Consent Bypassed by Service Principal", "analytic_story": ["Azure Active Directory Privilege Escalation", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "src_user", "type": "User", "role": ["Attacker"]}], "message": "Service principal $src_user$ bypassed the admin consent process and granted permissions to $dest_user$", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` operationName=\"Add app role assignment to service principal\" src_user_type=servicePrincipal | rename properties.* as *  | eval roleId = mvindex('targetResources{}.modifiedProperties{}.newValue', 0) | eval roleValue = mvindex('targetResources{}.modifiedProperties{}.newValue', 1) | eval roleDescription = mvindex('targetResources{}.modifiedProperties{}.newValue', 2) | eval dest_user = mvindex('targetResources{}.id', 0) | rename initiatedBy.app.displayName as src_user | stats count earliest(_time) as firstTime latest(_time) as lastTime by src_user dest_user roleId roleValue roleDescription | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`  | `azure_ad_admin_consent_bypassed_by_service_principal_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Auditlog log category", "known_false_positives": "Service Principals are sometimes configured to legitimately bypass the consent process for purposes of automation. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/003/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_admin_consent_bypassed_by_service_principal_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Admin Consent Bypassed by Service Principal:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_bypass_admin_consent/azure_ad_bypass_admin_consent.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_bypass_admin_consent/azure_ad_bypass_admin_consent.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Application Administrator Role Assigned", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "eac4de87-7a56-4538-a21b-277897af6d8d", "description": "The following analytic identifies the assignment of the Application Administrator role to an Azure AD user. Users in this role can create and manage all aspects of enterprise applications, application registrations, and application proxy settings. This role also grants the ability to manage application credentials. Users assigned this role can add credentials to an application, and use those credentials to impersonate the applications identity. If the applications identity has been granted access to a resource, such as the ability to create or update User or other objects, then a user assigned to this role could perform those actions while impersonating the application. This ability to impersonate the applications identity may be an elevation of privilege over what the user can do via their role assignments. Red teams and adversaries alike may abuse this role to escalate their privileges in an Azure AD tenant.", "tags": {"name": "Azure AD Application Administrator Role Assigned", "analytic_story": ["Azure Active Directory Privilege Escalation"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "The privileged Azure AD role Application Administrator was assigned for User $user$ initiated by $initiatedBy$", "risk_score": 35, "security_domain": "endpoint", "risk_severity": "low", "atomic_guid": [], "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  \"operationName\"=\"Add member to role\"  \"properties.targetResources{}.modifiedProperties{}.newValue\"=\"\\\"Application Administrator\\\"\" | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | stats count min(_time) as firstTime max(_time) as lastTime by user initiatedBy, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_application_administrator_role_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Auditlog log category", "known_false_positives": "Administrators may legitimately assign the Application Administrator role to a user. Filter as needed.", "check_references": false, "references": ["https://dirkjanm.io/azure-ad-privilege-escalation-application-admin/", "https://posts.specterops.io/azure-privilege-escalation-via-service-principal-abuse-210ae2be2a5", "https://docs.microsoft.com/en-us/azure/active-directory/roles/concept-understand-roles", "https://attack.mitre.org/techniques/T1098/003/", "https://learn.microsoft.com/en-us/azure/active-directory/roles/permissions-reference#application-administrator"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_application_administrator_role_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Application Administrator Role Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_privileged_role/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_privileged_role/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Authentication Failed During MFA Challenge", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "e62c9c2e-bf51-4719-906c-3074618fcc1c", "description": "The following analytic identifies an authentication attempt event against an Azure AD tenant that fails during the Multi Factor Authentication challenge. Error Code 500121 represents a failed attempt to authenticate using a second factor. This behavior may represent an adversary trying to authenticate with compromised credentials for an account that has multi-factor authentication enabled. ", "tags": {"name": "Azure AD Authentication Failed During MFA Challenge", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1078", "T1078.004", "T1621"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ failed to pass MFA challenge", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=SignInLogs properties.status.errorCode=500121 | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime by user, src_ip, status.additionalDetails, appDisplayName, user_agent | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_authentication_failed_during_mfa_challenge_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "Legitimate users may miss to reply the MFA challenge within the time window or deny it by mistake.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://attack.mitre.org/techniques/T1078/004/", "https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_authentication_failed_during_mfa_challenge_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Authentication Failed During MFA Challenge:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/azuread/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/azuread/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Block User Consent For Risky Apps Disabled", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "875de3d7-09bc-4916-8c0a-0929f4ced3d8", "description": "This analytic detects when the risk-based step-up consent security setting in Azure AD is disabled. This setting, when enabled, prevents regular users from granting consent to potentially malicious OAuth applications, requiring an administrative step-up for consent instead. Disabling this feature could expose the organization to OAuth phishing threats.The detection operates by monitoring Azure Active Directory logs for events where the \"Update authorization policy\" operation is performed. It specifically looks for changes to the \"AllowUserConsentForRiskyApps\" setting, identifying instances where this setting is switched to \"true,\" effectively disabling the risk-based step-up consent. Monitoring for changes to critical security settings like the \"risk-based step-up consent\" is vital for maintaining the integrity of an organization's security posture. Disabling this feature can make the environment more susceptible to OAuth phishing attacks, where attackers trick users into granting permissions to malicious applications. Identifying when this setting is disabled can help blue teams to quickly respond, investigate, and potentially uncover targeted phishing campaigns against their users. If an attacker successfully disables the \"risk-based step-up consent\" and subsequently launches an OAuth phishing campaign, they could gain unauthorized access to user data and other sensitive information within the M365 environment. This could lead to data breaches, unauthorized access to emails, and potentially further compromise within the organization", "tags": {"name": "Azure AD Block User Consent For Risky Apps Disabled", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ disabled the BlockUserConsentForRiskyApps Azure AD setting.", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` operationName=\"Update authorization policy\" | rename properties.* as *  | eval index_number = if(mvfind('targetResources{}.modifiedProperties{}.displayName', \"AllowUserConsentForRiskyApps\") >= 0, mvfind('targetResources{}.modifiedProperties{}.displayName', \"AllowUserConsentForRiskyApps\"), -1) | search index_number >= 0  | eval AllowUserConsentForRiskyApps = mvindex('targetResources{}.modifiedProperties{}.newValue',index_number) | search AllowUserConsentForRiskyApps = \"[true]\" | stats count min(_time) as firstTime max(_time) as lastTime by user, src_ip, operationName, AllowUserConsentForRiskyApps | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_block_user_consent_for_risky_apps_disabled_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Legitimate changes to the 'risk-based step-up consent' setting by administrators, perhaps as part of a policy update or security assessment, may trigger this alert, necessitating verification of the change's intent and authorization", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/", "https://goodworkaround.com/2020/10/19/a-look-behind-the-azure-ad-permission-classifications-preview/", "https://learn.microsoft.com/en-us/entra/identity/enterprise-apps/configure-risk-based-step-up-consent", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth"], "datamodel": ["Risk"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_block_user_consent_for_risky_apps_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Block User Consent For Risky Apps Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562/azuread_disable_blockconsent_for_riskapps/azuread_disable_blockconsent_for_riskapps.log", "source": "Azure Ad", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562/azuread_disable_blockconsent_for_riskapps/azuread_disable_blockconsent_for_riskapps.log", "source": "Azure Ad", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD Concurrent Sessions From Different Ips", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "a9126f73-9a9b-493d-96ec-0dd06695490d", "description": "The following analytic identifies an Azure AD account with concurrent sessions coming from more than one unique Ip address within the span of 5 minutes. This behavior could represent a session hijacking attack whereby an adversary has extracted cookies from a victims browser and is using them from a different location to access corporate online resources. As users may behave differently across organizations, security teams should test and customize this detection to fit their environments.", "tags": {"name": "Azure AD Concurrent Sessions From Different Ips", "analytic_story": ["Compromised User Account", "Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1185"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ has concurrent sessions from more than one unique IP address in the span of 5 minutes.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` properties.authenticationDetails{}.succeeded=true category=NonInteractiveUserSignInLogs | rename properties.* as * | bucket span=30m _time | stats count min(_time) as firstTime max(_time) as lastTime dc(src_ip) AS unique_ips values(src_ip) as src_ip values(appDisplayName) as appDisplayName by user | where unique_ips  > 1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_concurrent_sessions_from_different_ips_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "A user with concurrent sessions from different Ips may also represent the legitimate use of more than one device. Filter as needed and/or customize the threshold to fit your environment.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1185/", "https://breakdev.org/evilginx-2-next-generation-of-phishing-2fa-tokens/", "https://github.com/kgretzky/evilginx2"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_concurrent_sessions_from_different_ips_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Concurrent Sessions From Different Ips:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1185/azure_ad_concurrent_sessions_from_different_ips/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1185/azure_ad_concurrent_sessions_from_different_ips/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Device Code Authentication", "author": "Mauricio Velazco, Gowthamaraj Rajendran,  Splunk", "date": "2023-12-20", "version": 2, "id": "d68d8732-6f7e-4ee5-a6eb-737f2b990b91", "description": "The following analytic identifies the execution of the Azure Device Code Phishing attack, which can lead to Azure Account Take-Over (ATO). The detection leverages Azure AD logs specifically focusing on authentication requests to identify the attack. This technique involves creating malicious infrastructure, bypassing Multi-Factor Authentication (MFA), and bypassing Conditional Access Policies (CAPs). The attack aims to compromise users by sending them phishing emails from attacker-controlled domains and trick the victims into performing OAuth 2.0 device authentication. A successful execution of this attack can result in adversaries gaining unauthorized access to Azure AD, Exchange mailboxes, and the target's Outlook Web Application (OWA). This attack technique was detailed by security researchers including Bobby Cooke, Stephan Borosh, and others. It's crucial for organizations to be aware of this threat, as it can lead to unauthorized access and potential data breaches.", "tags": {"name": "Azure AD Device Code Authentication", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528", "T1566", "T1566.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Device code requested for $user$ from $src_ip$", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` category=SignInLogs \"properties.authenticationProtocol\"=deviceCode | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime by user src_ip, appDisplayName, userAgent | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_device_code_authentication_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "In most organizations, device code authentication will be used to access common Microsoft service but it may be legitimate for others. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528", "https://github.com/rvrsh3ll/TokenTactics", "https://embracethered.com/blog/posts/2022/device-code-phishing/", "https://0xboku.com/2021/07/12/ArtOfDeviceCodePhish.html", "https://learn.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-device-code"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_device_code_authentication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Device Code Authentication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/device_code_authentication/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/device_code_authentication/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD External Guest User Invited", "author": "Gowthamaraj Rajendran, Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "c1fb4edb-cab1-4359-9b40-925ffd797fb5", "description": "The following analytic identifies the invitation of an external guest user within Azure AD. With Azure AD B2B collaboration, users and administrators can invite external users to collaborate with internal users. External guest account invitations should be monitored by security teams as they could potentially lead to unauthorized access. An example of this attack vector was described at BlackHat 2022 by security researcher Dirk-Jan during his tall `Backdooring and Hijacking Azure AD Accounts by Abusing External Identities`", "tags": {"name": "Azure AD External Guest User Invited", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "External Guest User $user$ initiated by $initiatedBy$", "risk_score": 45, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` operationName=\"Invite external user\" | rename properties.*  as * | rename initiatedBy.user.userPrincipalName as initiatedBy | rename targetResources{}.type as type | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by type, initiatedBy, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_external_guest_user_invited_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "Administrator may legitimately invite external guest users. Filter as needed.", "check_references": false, "references": ["https://dirkjanm.io/assets/raw/US-22-Mollema-Backdooring-and-hijacking-Azure-AD-accounts_final.pdf", "https://www.blackhat.com/us-22/briefings/schedule/#backdooring-and-hijacking-azure-ad-accounts-by-abusing-external-identities-26999", "https://attack.mitre.org/techniques/T1136/003/", "https://docs.microsoft.com/en-us/azure/active-directory/external-identities/b2b-quickstart-add-guest-users-portal"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_external_guest_user_invited_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD External Guest User Invited:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_external_guest_user_invited/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_external_guest_user_invited/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD FullAccessAsApp Permission Assigned", "author": "Mauricio Velazco, Splunk", "date": "2024-01-29", "version": 1, "id": "ae286126-f2ad-421c-b240-4ea83bd1c43a", "description": "The following analytic identifies when the 'full_access_as_app' permission, marked by the GUID 'dc890d15-9560-4a4c-9b7f-a736ec74ec40', is assigned to an application within Office 365 Exchange Online, identified by ResourceAppId '00000002-0000-0ff1-ce00-000000000000'. This permission grants broad control over Office 365 operations, including full access to all mailboxes and the capability to send emails as any user. The query utilizes the azure_monitor_aad data source, focusing on AuditLogs with the operation name 'Update application'. This monitoring is crucial for early detection of potential unauthorized access or data exfiltration, as the 'full_access_as_app' permission could lead to significant security incidents if exploited.", "tags": {"name": "Azure AD FullAccessAsApp Permission Assigned", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098.002", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ assigned the full_access_as_app permission to the app registration $object$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` category=AuditLogs operationName=\"Update application\"  | eval newvalue = mvindex('properties.targetResources{}.modifiedProperties{}.newValue',0) | spath input=newvalue  | search \"{}.ResourceAppId\"=\"00000002-0000-0ff1-ce00-000000000000\"  \"{}.RequiredAppPermissions{}.EntitlementId\"=\"dc890d15-9560-4a4c-9b7f-a736ec74ec40\" | eval Permissions = '{}.RequiredAppPermissions{}.EntitlementId' | stats count earliest(_time) as firstTime latest(_time) as lastTime values(Permissions) by user, object, user_agent, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_fullaccessasapp_permission_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "The full_access_as_app API permission may be assigned to legitimate applications. Filter as needed.", "check_references": false, "references": ["https://msrc.microsoft.com/blog/2024/01/microsoft-actions-following-attack-by-nation-state-actor-midnight-blizzard/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/", "https://attack.mitre.org/techniques/T1098/002/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_fullaccessasapp_permission_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD FullAccessAsApp Permission Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.002/full_access_as_app_permission_assigned/full_access_as_app_permission_assigned.log", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.002/full_access_as_app_permission_assigned/full_access_as_app_permission_assigned.log", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Global Administrator Role Assigned", "author": "Gowthamaraj Rajendran, Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 4, "id": "825fed20-309d-4fd1-8aaf-cd49c1bb093c", "description": "The following analytic identifies the assignment of the Azure AD Global Administrator role to an Azure AD user. The Global Administrator role is the most powerful administrator role in Azure AD and provides almost unlimited access to data, resources and settings. It is equivalent to the Domain Administrator group in an Active Directory environment. While Azure AD roles do not grant access to Azure services and resources, it is possible for a Global Administrator account to gain control of Azure resources. Adversaries and red teams alike may assign this role to a compromised account to establish Persistence or escalate their privileges in an Azure AD environment.", "tags": {"name": "Azure AD Global Administrator Role Assigned", "analytic_story": ["Azure Active Directory Persistence", "Azure Active Directory Privilege Escalation"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "Global Administrator Role assigned for User $user$ initiated by $initiatedBy$", "risk_score": 72, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad`  operationName=\"Add member to role\"  properties.targetResources{}.modifiedProperties{}.newValue=\"\\\"Global Administrator\\\"\" | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by initiatedBy, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_global_administrator_role_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "Administrators may legitimately assign the Global Administrator role to a user. Filter as needed.", "check_references": false, "references": ["https://o365blog.com/post/admin/", "https://adsecurity.org/?p=4277", "https://www.mandiant.com/resources/detecting-microsoft-365-azure-active-directory-backdoors", "https://docs.microsoft.com/en-us/azure/active-directory/roles/security-planning", "https://docs.microsoft.com/en-us/azure/role-based-access-control/elevate-access-global-admin", "https://attack.mitre.org/techniques/T1098/003/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_global_administrator_role_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Global Administrator Role Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_global_administrator/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_global_administrator/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD High Number Of Failed Authentications For User", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "630b1694-210a-48ee-a450-6f79e7679f2c", "description": "The following analytic identifies an Azure AD account with more than 20 failed authentication events in the span of 10 minutes. This behavior could represent a brute force attack against the account. As environments differ across organizations, security teams should customize the threshold of this detection.", "tags": {"name": "Azure AD High Number Of Failed Authentications For User", "analytic_story": ["Compromised User Account", "Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110", "T1110.001"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ failed to authenticate more than 20 times in the span of 5 minutes.", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category= SignInLogs properties.status.errorCode=50126 properties.authenticationDetails{}.succeeded=false | rename properties.* as * | bucket span=10m _time | stats count min(_time) as firstTime max(_time) as lastTime values(src_ip) as src_ip by user | where count > 20 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_high_number_of_failed_authentications_for_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "A user with more than 20 failed authentication attempts in the span of 5 minutes may also be triggered by a broken application.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/", "https://attack.mitre.org/techniques/T1110/001/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_high_number_of_failed_authentications_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD High Number Of Failed Authentications For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/azure_ad_high_number_of_failed_authentications_for_user/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/azure_ad_high_number_of_failed_authentications_for_user/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD High Number Of Failed Authentications From Ip", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "e5ab41bf-745d-4f72-a393-2611151afd8e", "description": "The following analytic identifies an Ip address failing to authenticate 20 or more times to an Azure AD tenant in the span of 10 minutes. This behavior could represent a brute force attack againstan Azure AD to obtain initial access or elevate privileges. As environments differ across organizations, security teams should customize the threshold of this detection.", "tags": {"name": "Azure AD High Number Of Failed Authentications From Ip", "analytic_story": ["Compromised User Account", "Azure Active Directory Account Takeover", "NOBELIUM Group"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110", "T1110.001", "T1110.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "$src_ip$ failed to authenticate more than 20 times in the span of 10 minutes minutes.", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category= SignInLogs properties.status.errorCode=50126 properties.authenticationDetails{}.succeeded=false | rename properties.* as * | bucket span=10m _time | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by src_ip | where count > 20 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_high_number_of_failed_authentications_from_ip_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "An Ip address with more than 20 failed authentication attempts in the span of 10 minutes may also be triggered by a broken application.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/", "https://attack.mitre.org/techniques/T1110/001/", "https://attack.mitre.org/techniques/T1110/003/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_high_number_of_failed_authentications_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD High Number Of Failed Authentications From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/azure_ad_high_number_of_failed_authentications_for_user/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/azure_ad_high_number_of_failed_authentications_for_user/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Multi-Factor Authentication Disabled", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "482dd42a-acfa-486b-a0bb-d6fcda27318e", "description": "The following analytic identifies an attempt to disable multi-factor authentication for an Azure AD user. An adversary who has obtained access to an Azure AD tenant may disable multi-factor authentication as a way to plant a backdoor and maintain persistence using a valid account. This way the attackers can keep persistance in the environment without adding new users.", "tags": {"name": "Azure AD Multi-Factor Authentication Disabled", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "MFA disabled for User $user$ initiated by $initiatedBy$", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` category=AuditLogs operationName=\"Disable Strong Authentication\" | rename properties.* as * | rename targetResources{}.type as type | rename initiatedBy.user.userPrincipalName as initiatedBy | stats count min(_time) as firstTime max(_time) as lastTime by user, type, operationName, initiatedBy, result | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multi_factor_authentication_disabled_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "Legitimate use case may require for users to disable MFA. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks", "https://docs.microsoft.com/en-us/azure/active-directory/authentication/howto-mfa-userstates", "https://attack.mitre.org/tactics/TA0005/", "https://attack.mitre.org/techniques/T1556/"], "datamodel": ["Authentication"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multi_factor_authentication_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multi-Factor Authentication Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/azuread/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/azuread/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Multi-Source Failed Authentications Spike", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "116e11a9-63ea-41eb-a66a-6a13bdc7d2c7", "description": "This analytic detects potential distributed password spraying attacks within an Azure AD environment. It identifies a notable increase in failed authentication attempts across a variety of unique user-and-IP address combinations, originating from multiple source IP addresses and countries, and employing different user agents. Such patterns suggest an adversary's attempt to bypass security controls by using a range of IP addresses to test commonly used passwords against numerous user accounts. The detection scrutinizes SignInLogs from Azure AD logs, particularly focusing on events with error code 50126, which signals a failed authentication due to incorrect credentials. By collating data over a five-minute interval, the analytic computes the distinct counts of user-and-IP combinations, unique users, source IPs, and countries. It then applies a set of thresholds to these metrics to pinpoint unusual activities that could indicate a coordinated attack effort. The thresholds set within the analytic (such as unique IPs, unique users, etc.) are initial guidelines and should be customized based on the organization's user behavior and risk profile. Recognizing this behavior is vital for security operations centers (SOCs) as distributed password spraying represents a more complex form of traditional password spraying. Attackers distribute the source of their attempts to evade detection mechanisms that typically monitor for single-source IP anomalies. Prompt detection of such distributed activities is essential to thwart unauthorized access attempts, prevent account compromises, and mitigate the risk of further malicious activities within the organization's network. A true positive alert from this analytic suggests an active distributed password spraying attack against the organization's Azure AD tenant. A successful attack could result in unauthorized access, particularly to accounts with elevated privileges, leading to data breaches, privilege escalation, persistent threats, and lateral movement within the organization's infrastructure.", "tags": {"name": "Azure AD Multi-Source Failed Authentications Spike", "analytic_story": ["Azure Active Directory Account Takeover", "NOBELIUM Group"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [], "message": "An anomalous multi source authentication spike ocurred at $_time$", "risk_score": 42, "security_domain": "identity", "risk_severity": "low", "atomic_guid": [], "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=SignInLogs properties.status.errorCode=50126 properties.authenticationDetails{}.succeeded=false | rename properties.* as * | bucket span=5m _time | eval uniqueIPUserCombo = src_ip . \"-\" . user | stats count min(_time) as firstTime max(_time) as lastTime dc(uniqueIPUserCombo) as uniqueIpUserCombinations, dc(user) as uniqueUsers, dc(src_ip) as uniqueIPs, dc(user_agent) as uniqueUserAgents, dc(location.countryOrRegion) as uniqueCountries values(user) as users, values(src_ip) as ips, values(user_agent) as user_agents, values(location.countryOrRegion) as countries | where uniqueIpUserCombinations > 20 AND uniqueUsers > 20 AND uniqueIPs > 20 AND uniqueUserAgents = 1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multi_source_failed_authentications_spike_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category. The thresholds set within the analytic (such as unique IPs, unique users, etc.) are initial guidelines and should be customized based on the organization's user behavior and risk profile. Security teams are encouraged to adjust these thresholds to optimize the balance between detecting genuine threats and minimizing false positives, ensuring the detection is tailored to their specific environment.", "known_false_positives": "This detection may yield false positives in scenarios where legitimate bulk sign-in activities occur, such as during company-wide system updates or when users are accessing resources from varying locations in a short time frame, such as in the case of VPNs or cloud services that rotate IP addresses. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://docs.microsoft.com/azure/active-directory/reports-monitoring/reference-sign-ins-error-codes"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multi_source_failed_authentications_spike_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multi-Source Failed Authentications Spike:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/azure_ad_distributed_spray/azure_ad_distributed_spray.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/azure_ad_distributed_spray/azure_ad_distributed_spray.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD Multiple AppIDs and UserAgents Authentication Spike", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "5d8bb1f0-f65a-4b4e-af2e-fcdb88276314", "description": "This analytic is crafted to identify unusual and potentially malicious authentication activity within an Azure AD environment. It triggers when a single user account is involved in more than 8 authentication attempts, using 3 or more unique application IDs and more than 5 unique user agents within a short timeframe. This pattern is atypical for regular user behavior and may indicate an adversary's attempt to probe the environment, testing for multi-factor authentication requirements across different applications and platforms. The detection is based on analysis of Azure AD audit logs, specifically focusing on authentication events. It employs statistical thresholds to highlight instances where the volume of authentication attempts and the diversity of application IDs and user agents associated with a single user account exceed normal parameters. Identifying this behavior is crucial as it provides an early indication of potential account compromise. Adversaries, once in possession of user credentials, often conduct reconnaissance to understand the security controls in place, including multi-factor authentication configurations. Tools like Invoke-MFASweep are commonly used for this purpose, automating the process of testing different user agents and application IDs to bypass MFA. By detecting these initial probing attempts, security teams can swiftly respond, potentially stopping an attack in its early stages and preventing further unauthorized access. This proactive stance is vital for maintaining the integrity of the organization's security posture. If validated as a true positive, this detection points to a compromised account, signaling that an attacker is actively attempting to navigate security controls to maintain access and potentially escalate privileges. This could lead to further exploitation, lateral movement within the network, and eventual data exfiltration. Recognizing and responding to this early stage of an attack is vital for preventing substantial harm and safeguarding sensitive organizational data and systems.", "tags": {"name": "Azure AD Multiple AppIDs and UserAgents Authentication Spike", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure AD Tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "$user$ authenticated in a short periof of time with more than 5 different user agents across 3 or more unique application ids.", "risk_score": 48, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=SignInLogs operationName=\"Sign-in activity\" (properties.authenticationRequirement=\"multiFactorAuthentication\" AND properties.status.additionalDetails=\"MFA required in Azure AD\") OR (properties.authenticationRequirement=singleFactorAuthentication AND \"properties.authenticationDetails{}.succeeded\"=true) | bucket span=5m _time | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime dc(appId) as unique_app_ids dc(userAgent) as unique_user_agents values(appDisplayName) values(deviceDetail.operatingSystem) by user, src_ip | where count > 5 and unique_app_ids > 2 and unique_user_agents > 5 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multiple_appids_and_useragents_authentication_spike_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "Rapid authentication from the same user using more than 5 different user agents and 3 application IDs is highly unlikely under normal circumstances. However, there are potential scenarios that could lead to false positives.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1078/", "https://www.blackhillsinfosec.com/exploiting-mfa-inconsistencies-on-microsoft-services/", "https://github.com/dafthack/MFASweep", "https://www.youtube.com/watch?v=SK1zgqaAZ2E"], "datamodel": ["Authentication"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multiple_appids_and_useragents_authentication_spike_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multiple AppIDs and UserAgents Authentication Spike:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/azure_ad_multiple_appids_and_useragents_auth/azure_ad_multiple_appids_and_useragents_auth.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/azure_ad_multiple_appids_and_useragents_auth/azure_ad_multiple_appids_and_useragents_auth.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD Multiple Denied MFA Requests For User", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "d0895c20-de71-4fd2-b56c-3fcdb888eba1", "description": "This analytic targets the detection of an unusually high number of denied Multi-Factor Authentication (MFA) requests for a single user within a 10-minute window, specifically identifying instances where more than nine MFA prompts were declined by the user. Utilizing Azure Active Directory (Azure AD) sign-in logs, particularly focusing on \"Sign-in activity\" events, it filters for scenarios where the MFA request was denied due to the user declining the authentication, as indicated by error code 500121 and additional details stating \"MFA denied; user declined the authentication.\" The data is then aggregated into 10-minute intervals, counting distinct raw events and capturing the earliest and latest times of occurrence for each user. This behavior is significant for a Security Operations Center (SOC) as it could be an early indicator of a targeted attack or an account compromise attempt, with an attacker having obtained the user's credentials and the user actively declining the MFA prompts, preventing unauthorized access. A true positive detection would imply that an attacker is on the verge of gaining full access to the user's account, posing a threat that could lead to data exfiltration, lateral movement, or further malicious activities within the organization, necessitating immediate investigation and response to safeguard the organization's assets.", "tags": {"name": "Azure AD Multiple Denied MFA Requests For User", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1621"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ denied more than 9 MFA requests in a timespan of 10 minutes.", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "atomic_guid": [], "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` category=SignInLogs operationName=\"Sign-in activity\" | rename properties.* as * | search status.errorCode=500121 status.additionalDetails=\"MFA denied; user declined the authentication\" | bucket span=10m _time | stats count min(_time) as firstTime max(_time) as lastTime by user, status.additionalDetails, appDisplayName, user_agent | where count > 9 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multiple_denied_mfa_requests_for_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "Multiple denifed MFA requests in a short period of span may also be a sign of authentication errors. Investigate and filter as needed.", "check_references": false, "references": ["https://www.mandiant.com/resources/blog/russian-targeting-gov-business", "https://arstechnica.com/information-technology/2022/03/lapsus-and-solar-winds-hackers-both-use-the-same-old-trick-to-bypass-mfa/", "https://therecord.media/russian-hackers-bypass-2fa-by-annoying-victims-with-repeated-push-notifications/", "https://attack.mitre.org/techniques/T1621/", "https://attack.mitre.org/techniques/T1078/004/", "https://www.cisa.gov/sites/default/files/publications/fact-sheet-implement-number-matching-in-mfa-applications-508c.pdf"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multiple_denied_mfa_requests_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multiple Denied MFA Requests For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/azure_ad_multiple_denied_mfa_requests/azure_ad_multiple_denied_mfa_requests.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/azure_ad_multiple_denied_mfa_requests/azure_ad_multiple_denied_mfa_requests.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD Multiple Failed MFA Requests For User", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 3, "id": "264ea131-ab1f-41b8-90e0-33ad1a1888ea", "description": "The following analytic identifies multiple failed multi-factor authentication requests for a single user within an Azure AD tenant. Error Code 500121 represents a failed attempt to authenticate using a second factor. Specifically, the analytic triggers when more than 10 MFA user prompts fail within 10 minutes. The reasons for these failure could be several, like the user not responding in time or receiving multiple duplicate MFA requests. Azure AD tenants can be very different depending on the organization, Security teams should test this detection and customize these arbitrary thresholds. The detected behavior may represent an adversary who has obtained legitimate credentials for a user and continuously repeats login attempts in order to bombard users with MFA push notifications, SMS messages, and phone calls potentially resulting in the user finally accepting the authentication request. Threat actors like the Lapsus team and APT29 have leveraged this technique to bypass multi-factor authentication controls as reported by Mandiant and others.", "tags": {"name": "Azure AD Multiple Failed MFA Requests For User", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1621", "T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ failed to complete MFA authentication more than 9 times in a timespan of 10 minutes.", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=SignInLogs operationName=\"Sign-in activity\" properties.status.errorCode=500121 properties.status.additionalDetails!=\"MFA denied; user declined the authentication\" | rename properties.* as * | bucket span=10m _time | stats count min(_time) as firstTime max(_time) as lastTime by user, status.additionalDetails, appDisplayName, user_agent | where count > 9 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multiple_failed_mfa_requests_for_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "Multiple Failed MFA requests may also be a sign of authentication or application issues. Filter as needed.", "check_references": false, "references": ["https://www.mandiant.com/resources/blog/russian-targeting-gov-business", "https://arstechnica.com/information-technology/2022/03/lapsus-and-solar-winds-hackers-both-use-the-same-old-trick-to-bypass-mfa/", "https://therecord.media/russian-hackers-bypass-2fa-by-annoying-victims-with-repeated-push-notifications/", "https://attack.mitre.org/techniques/T1621/", "https://attack.mitre.org/techniques/T1078/004/", "https://www.cisa.gov/sites/default/files/publications/fact-sheet-implement-number-matching-in-mfa-applications-508c.pdf"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multiple_failed_mfa_requests_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multiple Failed MFA Requests For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/multiple_failed_mfa_requests/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/multiple_failed_mfa_requests/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Multiple Service Principals Created by SP", "author": "Mauricio Velazco, Splunk", "date": "2024-02-07", "version": 1, "id": "66cb378f-234d-4fe1-bb4c-e7878ff6b017", "description": "This detection identifies when a single service principal in Azure AD creates more than three unique OAuth applications within a 10-minute span, potentially signaling malicious activity. It monitors the 'Add service principal' operation, focusing on the activity of service principals rather than individual users. By aggregating the creation events over a 10-minute period, the analytic tracks how many distinct OAuth applications are created by each service principal. This is key for SOC teams to pinpoint potential attack staging, where an attacker might use a compromised or malicious service principal to rapidly establish multiple service principals, facilitating network infiltration or expansion. While the default threshold is set to trigger on more than three applications, security teams should adjust this to fit their specific environment's norm", "tags": {"name": "Azure AD Multiple Service Principals Created by SP", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003"], "nist": ["DE.AE"], "observable": [{"name": "src_user", "type": "User", "role": ["Attacker"]}], "message": "Multiple OAuth applications were created by $src_user$ in a short period of time", "risk_score": 42, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` operationName=\"Add service principal\" properties.initiatedBy.app.appId=* | rename properties.* as * | bucket span=10m _time | rename targetResources{}.displayName as displayName | rename targetResources{}.type as type | rename initiatedBy.app.displayName as src_user | stats min(_time) as firstTime max(_time) as lastTime values(displayName) as displayName dc(displayName) as unique_apps by src_user | where unique_apps > 3 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multiple_service_principals_created_by_sp_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "Certain users or applications may create multiple service principals in a short period of time for legitimate purposes. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1136/003/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multiple_service_principals_created_by_sp_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multiple Service Principals Created by SP:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_multiple_service_principals_created/azure_ad_multiple_service_principals_created.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_multiple_service_principals_created/azure_ad_multiple_service_principals_created.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Multiple Service Principals Created by User", "author": "Mauricio Velazco, Splunk", "date": "2024-02-07", "version": 1, "id": "32880707-f512-414e-bd7f-204c0c85b758", "description": "This detection focuses on identifying instances where a single user creates more than three unique OAuth applications within a 10-minute timeframe in Azure AD, a potential indicator of malicious activity. By monitoring the 'Add service principal' operation and aggregating the data with a 10-minute bucket span, it tracks the number of distinct OAuth applications created by each user. This analytic is crucial for SOC teams to detect possible staging of attacks, where an adversary might rapidly create multiple service principals as part of their infiltration or expansion strategy within the network. The threshold of three applications is set to flag unusual behavior, but security teams are advised to adjust this value to suit the normal operational patterns of their environment", "tags": {"name": "Azure AD Multiple Service Principals Created by User", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003"], "nist": ["DE.AE"], "observable": [{"name": "src_user", "type": "User", "role": ["Attacker"]}], "message": "Multiple OAuth applications were created by $src_user$ in a short period of time", "risk_score": 42, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` operationName=\"Add service principal\" properties.initiatedBy.user.id=* | rename properties.* as * | bucket span=10m _time | rename targetResources{}.displayName as displayName | stats min(_time) as firstTime max(_time) as lastTime values(displayName) as displayName dc(displayName) as unique_apps by src_user | where unique_apps > 3 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multiple_service_principals_created_by_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "Certain users or applications may create multiple service principals in a short period of time for legitimate purposes. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1136/003/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multiple_service_principals_created_by_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multiple Service Principals Created by User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_multiple_service_principals_created/azure_ad_multiple_service_principals_created.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_multiple_service_principals_created/azure_ad_multiple_service_principals_created.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Multiple Users Failing To Authenticate From Ip", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "94481a6a-8f59-4c86-957f-55a71e3612a6", "description": "The following analytic identifies one source Ip failing to authenticate with 30 unique valid users within 5 minutes. This behavior could represent an adversary performing a Password Spraying attack against an Azure Active Directory tenant to obtain initial access or elevate privileges. Error Code 50126 represents an invalid password. This logic can be used for real time security monitoring as well as threat hunting exercises.\\\nAzure AD tenants can be very different depending on the organization. Users should test this detection and customize the arbitrary threshold if needed.", "tags": {"name": "Azure AD Multiple Users Failing To Authenticate From Ip", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Source Ip $src_ip$ failed to authenticate with 30 users within 5 minutes.", "risk_score": 63, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  category=SignInLogs properties.status.errorCode=50126 properties.authenticationDetails{}.succeeded=false | rename properties.* as * | bucket span=5m _time | stats count min(_time) as firstTime max(_time) as lastTime dc(user) AS unique_accounts values(user) as user by src_ip | where unique_accounts > 30 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_multiple_users_failing_to_authenticate_from_ip_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "A source Ip failing to authenticate with multiple users is not a common for legitimate behavior.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://docs.microsoft.com/azure/active-directory/reports-monitoring/reference-sign-ins-error-codes"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_multiple_users_failing_to_authenticate_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Multiple Users Failing To Authenticate From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/password_spraying_azuread/azuread_signin.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/password_spraying_azuread/azuread_signin.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD New Custom Domain Added", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "30c47f45-dd6a-4720-9963-0bca6c8686ef", "description": "The following analytic identifies the addition of a new custom domain within an Azure Active Directory tenant. Adding a custom domain is a step required to set up the Azure Active Directory identity federation backdoor technique discovered by security researcher Nestori Syynimaa. Similar to Active Directory, Azure AD uses the concept of domains to manage directories of identities. A new Azure AD tenant will initially contain a single domain that is commonly called the `cloud-only` onmicrosoft.com domain. Organizations can also add their registered custom domains to Azure AD for email addresses to match the organizations domain name. If the organization intends to use a third-party identity provider such as ADFS for authentication, the added custom domains can be configured as federated. An adversary who has obtained privileged access to an Azure AD tenant may leverage this technique to establish persistence and be able to authenticate to Azure AD impersonating any user and bypassing the requirement to have a valid password and/or perform MFA.", "tags": {"name": "Azure AD New Custom Domain Added", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1484", "T1484.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "A new custom domain, $domain$ , was added by $user$", "risk_score": 54, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  operationName=\"Add unverified domain\" properties.result=success | rename properties.* as * | rename targetResources{}.displayName as domain | stats count min(_time) as firstTime max(_time) as lastTime by user, domain, result, operationName, src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_new_custom_domain_added_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "In most organizations, new customm domains will be updated infrequently. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/active-directory/enterprise-users/domains-manage", "https://www.mandiant.com/resources/remediation-and-hardening-strategies-microsoft-365-defend-against-apt29-v13", "https://o365blog.com/post/federation-vulnerability/", "https://www.inversecos.com/2021/11/how-to-detect-azure-active-directory.html", "https://www.mandiant.com/resources/blog/detecting-microsoft-365-azure-active-directory-backdoors", "https://attack.mitre.org/techniques/T1484/002/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_new_custom_domain_added_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD New Custom Domain Added:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1484.002/new_federated_domain/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1484.002/new_federated_domain/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD New Federated Domain Added", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "a87cd633-076d-4ab2-9047-977751a3c1a0", "description": "The following analytic identifies the addition of a new federated domain within an Azure Active Directory tenant. This event could represent the execution of the Azure Active Directory identity federation backdoor technique discovered by security researcher Nestori Syynimaa. Similar to Active Directory, Azure AD uses the concept of domains to manage directories of identities. A new Azure AD tenant will initially contain a single domain that is commonly called the `cloud-only` onmicrosoft.com domain. Organizations can also add their registered custom domains to Azure AD for email addresses to match the organizations domain name. If the organization intends to use a third-party identity provider such as ADFS for authentication, the added custom domains can be configured as federated. An adversary who has obtained privileged access to an Azure AD tenant may leverage this technique to establish persistence and be able to authenticate to Azure AD impersonating any user and bypassing the requirement to have a valid password and/or perform MFA.", "tags": {"name": "Azure AD New Federated Domain Added", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1484", "T1484.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "A new federated domain, $domain$ , was added by $user$", "risk_score": 81, "security_domain": "threat", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  operationName=\"Set domain authentication\" \"properties.result\"=success | rename properties.* as * | rename targetResources{}.displayName as domain | stats count min(_time) as firstTime max(_time) as lastTime by user, domain, result, operationName, src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_new_federated_domain_added_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "In most organizations, domain federation settings will be updated infrequently. Filter as needed.", "check_references": false, "references": ["https://www.mandiant.com/resources/remediation-and-hardening-strategies-microsoft-365-defend-against-apt29-v13", "https://o365blog.com/post/federation-vulnerability/", "https://www.inversecos.com/2021/11/how-to-detect-azure-active-directory.html", "https://www.mandiant.com/resources/blog/detecting-microsoft-365-azure-active-directory-backdoors", "https://attack.mitre.org/techniques/T1484/002/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_new_federated_domain_added_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD New Federated Domain Added:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1484.002/new_federated_domain/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1484.002/new_federated_domain/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD New MFA Method Registered", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "0488e814-eb81-42c3-9f1f-b2244973e3a3", "description": "This analytic detects the registration of a new Multi-Factor Authentication (MFA) method associated with a user account within Azure Active Directory by monitoring Azure AD audit logs and configurations. While adding a new MFA method can be a routine and legitimate action, it can also be indicative of an attacker's attempt to maintain persistence on a compromised account. By registering a new MFA method, attackers can potentially bypass existing security measures, allowing them to authenticate using stolen credentials without raising alarms. Monitoring for such changes is crucial, especially if the addition is not preceded by a user request or if it deviates from typical user behavior. If an attacker successfully registers a new MFA method on a compromised account, they can solidify their access, making it harder for legitimate users to regain control. The attacker can then operate with the privileges of the compromised account, potentially accessing sensitive data, making unauthorized changes, or even escalating their privileges further. Immediate action would be required to verify the legitimacy of the MFA change and, if malicious, to remediate and secure the affected account.", "tags": {"name": "Azure AD New MFA Method Registered", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.005"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "A new MFA method was registered for user $user$", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad`  operationName=\"Update user\" | rename properties.* as *  | eval propertyName = mvindex('targetResources{}.modifiedProperties{}.displayName', 0) | search propertyName = StrongAuthenticationMethod | eval oldvalue = mvindex('targetResources{}.modifiedProperties{}.oldValue',0) | eval newvalue = mvindex('targetResources{}.modifiedProperties{}.newValue',0) | rex field=newvalue max_match=0 \"(?i)(?<new_method_type>\\\"MethodType\\\")\" | rex field=oldvalue max_match=0 \"(?i)(?<old_method_type>\\\"MethodType\\\")\" | eval count_new_method_type = coalesce(mvcount(new_method_type), 0) | eval count_old_method_type = coalesce(mvcount(old_method_type), 0) | stats earliest(_time) as firstTime latest(_time) as lastTime values(propertyName) by user newvalue oldvalue | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_new_mfa_method_registered_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Users may register MFA methods legitimally, investigate and filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/005/", "https://www.microsoft.com/en-us/security/blog/2023/06/08/detecting-and-mitigating-a-multi-stage-aitm-phishing-and-bec-campaign/", "https://www.csoonline.com/article/573451/sophisticated-bec-scammers-bypass-microsoft-365-multi-factor-authentication.html"], "datamodel": ["Authentication"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_new_mfa_method_registered_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD New MFA Method Registered:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.005/azure_ad_register_new_mfa_method/azure_ad_register_new_mfa_method.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.005/azure_ad_register_new_mfa_method/azure_ad_register_new_mfa_method.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD New MFA Method Registered For User", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "2628b087-4189-403f-9044-87403f777a1b", "description": "The following analytic identifies the registration of a new Multi Factor authentication method for an Azure AD account. Adversaries who have obtained unauthorized access to an Azure AD account may register a new MFA method to maintain persistence.", "tags": {"name": "Azure AD New MFA Method Registered For User", "analytic_story": ["Compromised User Account", "Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "A new MFA method was registered for user $user$", "risk_score": 64, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=AuditLogs operationName=\"User registered security info\" properties.operationType=Add | rename properties.* as * | rename targetResources{}.* as * | stats count min(_time) as firstTime max(_time) as lastTime by user, resultDescription, result, src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_new_mfa_method_registered_for_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLogs log category.", "known_false_positives": "Newly onboarded users who are registering an MFA method for the first time will also trigger this detection.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks", "https://attack.mitre.org/techniques/T1556/", "https://attack.mitre.org/techniques/T1556/006/", "https://twitter.com/jhencinski/status/1618660062352007174"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_new_mfa_method_registered_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD New MFA Method Registered For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556.006/azure_ad_new_mfa_method_registered_for_user/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556.006/azure_ad_new_mfa_method_registered_for_user/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD OAuth Application Consent Granted By User", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "10ec9031-015b-4617-b453-c0c1ab729007", "description": "This analytic detects when a user in an Azure AD environment grants consent to an OAuth application, capturing any consent granted regardless of the specific permissions requested. Utilizing Azure AD audit logs, it focuses on events related to OAuth application consents, alerting security teams to instances where users actively grant consent to applications. This monitoring is crucial as it highlights potential risks associated with third-party applications gaining access to organizational data, a tactic often exploited by malicious actors to gain unauthorized access. A true positive from this analytic necessitates immediate investigation to validate the application's legitimacy, review the granted permissions, and assess potential risks, helping to prevent unauthorized access and protect sensitive data and resources. While false positives may occur with legitimate application integrations, ensuring alignment with organizational policies and security best practices is paramount.", "tags": {"name": "Azure AD OAuth Application Consent Granted By User", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ consented an OAuth application.", "risk_score": 36, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` operationName=\"Consent to application\" properties.result=success | rename properties.* as *  | eval permissions_index = if(mvfind('targetResources{}.modifiedProperties{}.displayName', \"ConsentAction.Permissions\") >= 0, mvfind('targetResources{}.modifiedProperties{}.displayName', \"ConsentAction.Permissions\"), -1) | eval permissions = mvindex('targetResources{}.modifiedProperties{}.newValue',permissions_index) | rex field=permissions \"Scope: (?<Scope>[^,]+)\" | stats count min(_time) as firstTime max(_time) as lastTime by operationName, user, Scope | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_oauth_application_consent_granted_by_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "False positives may occur if users are granting consents as part of legitimate application integrations or setups. It is crucial to review the application and the permissions it requests to ensure they align with organizational policies and security best practices.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/protect-against-consent-phishing", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_oauth_application_consent_granted_by_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD OAuth Application Consent Granted By User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/azure_ad_user_consent_granted/azure_ad_user_consent_granted.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/azure_ad_user_consent_granted/azure_ad_user_consent_granted.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD PIM Role Assigned", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "fcd6dfeb-191c-46a0-a29c-c306382145ab", "description": "The following analytic identifies the assignment of the Azure AD PIM role. Privileged Identity Management (PIM) is a service within Azure Azure AD that enables administrators to manage, control, and monitor access to sensitive resources. PIM provides time-based and approval-based role activation to mitigate the risks of excessive, unnecessary, or misused access permissions on resources. Once a user has been made eligible for an administrative role, she must activate this role assignment to perform the privileged actions. When a role is activated, Azure AD PIM temporarily adds active assignment for the role. While PIM can be leveraged as a powerful security control, it may also abused by adversaries to obtain privileged access. Security teams should monitor for the assignment and activation of PIM roles and validate their legitimacy.", "tags": {"name": "Azure AD PIM Role Assigned", "analytic_story": ["Azure Active Directory Privilege Escalation", "Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "An Azure AD PIM role assignment was assiged to $user$", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` operationName=\"Add eligible member to role in PIM completed*\" | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user values(targetResources{}.displayName) as displayName  by result, operationName, initiatedBy.user.displayName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_pim_role_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "As part of legitimate administrative behavior, users may be assigned PIM roles. Filter as needed", "check_references": false, "references": ["https://learn.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-configure", "https://learn.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-how-to-activate-role", "https://microsoft.github.io/Azure-Threat-Research-Matrix/PrivilegeEscalation/AZT401/AZT401/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_pim_role_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD PIM Role Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_pim_role_activated/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_pim_role_activated/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD PIM Role Assignment Activated", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 3, "id": "952e80d0-e343-439b-83f4-808c3e6fbf2e", "description": "The following analytic identifies the assignment of the Azure AD PIM role. Privileged Identity Management (PIM) is a service within Azure Azure AD that enables administrators to manage, control, and monitor access to sensitive resources. PIM provides time-based and approval-based role activation to mitigate the risks of excessive, unnecessary, or misused access permissions on resources. Once a user has been made eligible for an administrative role, she must activate this role assignment to perform the privileged actions. When a role is activated, Azure AD PIM temporarily adds active assignment for the role. While PIM can be leveraged as a powerful security control, it may also abused by adversaries to obtain privileged access. Security teams should monitor for the assignment and activation of PIM roles and validate their legitimacy.", "tags": {"name": "Azure AD PIM Role Assignment Activated", "analytic_story": ["Azure Active Directory Privilege Escalation", "Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "An Azure AD PIM role assignment was activated by $initiatedBy$ by $user$", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` operationName=\"Add member to role completed (PIM activation)\" | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user values(targetResources{}.displayName) as displayName by initiatedBy, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_pim_role_assignment_activated_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "As part of legitimate administrative behavior, users may activate PIM roles. Filter as needed", "check_references": false, "references": ["https://learn.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-configure", "https://learn.microsoft.com/en-us/azure/active-directory/privileged-identity-management/pim-how-to-activate-role", "https://microsoft.github.io/Azure-Threat-Research-Matrix/PrivilegeEscalation/AZT401/AZT401/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_pim_role_assignment_activated_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD PIM Role Assignment Activated:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_pim_role_activated/azure-audit.log", "source": "eventhub://researchhub1.servicebus.windows.net/azureadhub;", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_pim_role_activated/azure-audit.log", "source": "eventhub://researchhub1.servicebus.windows.net/azureadhub;", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD Privileged Authentication Administrator Role Assigned", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "a7da845d-6fae-41cf-b823-6c0b8c55814a", "description": "The following analytic identifies the assignment of the Privileged Authentication Administrato role to an Azure AD user. Users in this role can set or reset authentication methods for any user in Azure Active Directory, including privileged roles like Global Administrators. Users with this role can change credentials for people who may have access to sensitive or private information or critical configuration inside and outside of Azure Active Directory. Changing the credentials of a user may mean the ability to assume that users identity and permissions. Red teams and adversaries alike may abuse this role to escalate their privileges.", "tags": {"name": "Azure AD Privileged Authentication Administrator Role Assigned", "analytic_story": ["Azure Active Directory Privilege Escalation"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1003.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "The privileged Azure AD role Privileged Authentication Administrator was assigned for User $user$ initiated by $initiatedBy$", "risk_score": 50, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  \"operationName\"=\"Add member to role\"  \"properties.targetResources{}.modifiedProperties{}.newValue\"=\"\\\"Privileged Authentication Administrator\\\"\" | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by initiatedBy, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_privileged_authentication_administrator_role_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Administrators may legitimately assign the Privileged Authentication Administrator role as part of administrative tasks. Filter as needed.", "check_references": false, "references": ["https://learn.microsoft.com/en-us/azure/active-directory/roles/permissions-reference#privileged-authentication-administrator", "https://posts.specterops.io/azure-privilege-escalation-via-azure-api-permissions-abuse-74aee1006f48", "https://learn.microsoft.com/en-us/azure/active-directory/roles/permissions-reference"], "datamodel": ["Authentication"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_privileged_authentication_administrator_role_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Privileged Authentication Administrator Role Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_privileged_role/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_privileged_role/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Privileged Graph API Permission Assigned", "author": "Mauricio Velazco, Splunk", "date": "2024-01-30", "version": 1, "id": "5521f8c5-1aa3-473c-9eb7-853701924a06", "description": "This Splunk analytic flags the assignment of three high-risk Graph API permissions in Azure AD, Application.ReadWrite.All (1bfefb4e-e0b5-418b-a88f-73c46d2cc8e9), AppRoleAssignment.ReadWrite.All (06b708a9-e830-4db3-a914-8e69da51d44f), and RoleManagement.ReadWrite.Directory (9e3f62cf-ca93-4989-b6ce-bf83c28f9fe8). These permissions enable broad control over Azure AD, including application and directory settings. Utilizing azure_monitor_aad data, the query scans AuditLogs for 'Update application' operations, identifying when these permissions are assigned. It collects data on user, object, and user agent. Immediate attention is needed upon detection, as misuse of these permissions can lead to unauthorized Azure AD modifications and potential security breaches.", "tags": {"name": "Azure AD Privileged Graph API Permission Assigned", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1003.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ assigned privileged Graph API permissions to $object$", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` category=AuditLogs operationName=\"Update application\"  | eval newvalue = mvindex('properties.targetResources{}.modifiedProperties{}.newValue',0) | spath input=newvalue  | search \"{}.RequiredAppPermissions{}.EntitlementId\"=\"1bfefb4e-e0b5-418b-a88f-73c46d2cc8e9\" OR \"{}.RequiredAppPermissions{}.EntitlementId\"=\"06b708a9-e830-4db3-a914-8e69da51d44f\" OR \"{}.RequiredAppPermissions{}.EntitlementId\"=\"9e3f62cf-ca93-4989-b6ce-bf83c28f9fe8\"  | eval Permissions = '{}.RequiredAppPermissions{}.EntitlementId' | stats count earliest(_time) as firstTime latest(_time) as lastTime values(Permissions) by user, object, user_agent, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`   | `azure_ad_privileged_graph_api_permission_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Privileged Graph API permissions may be assigned for legitimate purposes. Filter as needed.", "check_references": false, "references": ["https://cloudbrothers.info/en/azure-attack-paths/", "https://github.com/mandiant/Mandiant-Azure-AD-Investigator/blob/master/MandiantAzureADInvestigator.json", "https://learn.microsoft.com/en-us/graph/permissions-reference", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/", "https://posts.specterops.io/azure-privilege-escalation-via-azure-api-permissions-abuse-74aee1006f48"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_privileged_graph_api_permission_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Privileged Graph API Permission Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_privileged_graph_perm_assigned/azure_ad_privileged_graph_perm_assigned.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_privileged_graph_perm_assigned/azure_ad_privileged_graph_perm_assigned.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Privileged Role Assigned", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "a28f0bc3-3400-4a6e-a2da-89b9e95f0d2a", "description": "The following analytic identifies the assignment of sensitive and privileged Azure Active Directory roles to an Azure AD user. Adversaries and red teams alike may assign these roles to a compromised account to establish Persistence in an Azure AD environment.", "tags": {"name": "Azure AD Privileged Role Assigned", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "A privileged Azure AD role was assigned for User $user$ initiated by $initiatedBy$", "risk_score": 63, "security_domain": "audit", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  \"operationName\"=\"Add member to role\" | rename properties.*  as * | rename initiatedBy.user.userPrincipalName as initiatedBy | rename targetResources{}.modifiedProperties{}.newValue  as roles | eval role=mvindex(roles,1) | lookup privileged_azure_ad_roles azureadrole AS role OUTPUT isprvilegedadrole description | search isprvilegedadrole = True | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by initiatedBy, result, operationName, role, description | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_privileged_role_assigned_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Administrators will legitimately assign the privileged roles users as part of administrative tasks. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/active-directory/roles/concept-understand-roles", "https://docs.microsoft.com/en-us/azure/active-directory/roles/permissions-reference", "https://adsecurity.org/?p=4277", "https://www.mandiant.com/resources/detecting-microsoft-365-azure-active-directory-backdoors", "https://docs.microsoft.com/en-us/azure/active-directory/roles/security-planning", "https://attack.mitre.org/techniques/T1098/003/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_privileged_role_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "privileged_azure_ad_roles", "description": "A list of privileged Azure Active Directory roles.", "filename": "privileged_azure_ad_roles.csv", "default_match": "false", "match_type": "WILDCARD(azureadrole)", "min_matches": 1, "case_sensitive_match": "false", "file_path": "/home/jose.costa/splunk/content/lookups/privileged_azure_ad_roles.yml"}], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Privileged Role Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_privileged_role/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_assign_privileged_role/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Privileged Role Assigned to Service Principal", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "5dfaa3d3-e2e4-4053-8252-16d9ee528c41", "description": "The following analytic detects potential privilege escalation threats in Azure Active Directory (AD). The detection is made by running a specific search within the ingested Azure Active Directory events to leverage the AuditLogs log category. This detection is important because it identifies instances where privileged roles that hold elevated permissions are assigned to service principals. This prevents unauthorized access or malicious activities, which occur when these non-human entities access Azure resources to exploit them. False positives might occur since administrators can legitimately assign privileged roles to service principals.", "tags": {"name": "Azure AD Privileged Role Assigned to Service Principal", "analytic_story": ["Azure Active Directory Privilege Escalation", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "A privileged Azure AD role was assigned to the Service Principal $displayName$ initiated by $initiatedBy$", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  operationName=\"Add member to role\" | rename properties.* as * | search \"targetResources{}.type\"=ServicePrincipal | rename initiatedBy.user.userPrincipalName as initiatedBy | rename targetResources{}.modifiedProperties{}.newValue  as roles | eval role=mvindex(roles,1) | rename targetResources{}.displayName as apps | eval displayName=mvindex(apps,0) | lookup privileged_azure_ad_roles azureadrole AS role OUTPUT isprvilegedadrole description | search isprvilegedadrole = True | stats count min(_time) as firstTime max(_time) as lastTime values(displayName) as displayName by initiatedBy, result, operationName, role | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_privileged_role_assigned_to_service_principal_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Administrators may legitimately assign the privileged roles to Service Principals as part of administrative tasks. Filter as needed.", "check_references": false, "references": ["https://posts.specterops.io/azure-privilege-escalation-via-service-principal-abuse-210ae2be2a5"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_privileged_role_assigned_to_service_principal_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "privileged_azure_ad_roles", "description": "A list of privileged Azure Active Directory roles.", "filename": "privileged_azure_ad_roles.csv", "default_match": "false", "match_type": "WILDCARD(azureadrole)", "min_matches": 1, "case_sensitive_match": "false", "file_path": "/home/jose.costa/splunk/content/lookups/privileged_azure_ad_roles.yml"}], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Privileged Role Assigned to Service Principal:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_privileged_role_serviceprincipal/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_privileged_role_serviceprincipal/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Service Principal Authentication", "author": "Mauricio Velazco, Splunk", "date": "2024-02-12", "version": 1, "id": "5a2ec401-60bb-474e-b936-1e66e7aa4060", "description": "Monitoring service principal authentication events in Azure Active Directory is crucial, but to effectively leverage this detection, teams should first conduct a thorough inventory of all service principals and their source IPs to establish a baseline of normal behavior. The detection, using azure_monitor_aad, specifically targets \"Sign-in activity\" within ServicePrincipalSignInLogs, gathering key details like sign-in frequency, timing, source IPs, and accessed resources. This baseline is essential for SOC teams to distinguish between regular application authentication and anomalous patterns that might suggest compromised credentials or malicious activities.", "tags": {"name": "Azure AD Service Principal Authentication", "analytic_story": ["Azure Active Directory Account Takeover", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Victim"]}], "message": "Service Principal $user$ authenticated from $src_ip$", "risk_score": 25, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` operationName=\"Sign-in activity\" category=ServicePrincipalSignInLogs | rename properties.* as * | stats count earliest(_time) as firstTime latest(_time) as lastTime by user, user_id, src_ip, resourceDisplayName, resourceId | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_service_principal_authentication_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "Service Principals will legitimally authenticate remotely to your tenant. Implementing this detection after establishing a baseline enables a more accurate identification of security threats, ensuring proactive and informed responses to safeguard the Azure AD environment. source ips.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1078/004/", "https://learn.microsoft.com/en-us/entra/identity/monitoring-health/concept-sign-ins#service-principal-sign-ins"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_service_principal_authentication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Service Principal Authentication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azure_ad_service_principal_authentication/azure_ad_service_principal_authentication.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azure_ad_service_principal_authentication/azure_ad_service_principal_authentication.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Service Principal Created", "author": "Gowthamaraj Rajendran, Mauricio Velazco, Splunk", "date": "2022-08-17", "version": 1, "id": "f8ba49e7-ffd3-4b53-8f61-e73974583c5d", "description": "The following analytic identifies the creation of a Service Principal in an Azure AD environment. An Azure Service Principal is an identity designed to be used with applications, services, and automated tools to access resources. It is similar to a service account within an Active Directory environment. Service Principal authentication does not support multi-factor authentication nor conditional access policies. Adversaries and red teams alike who have obtained administrative access may create a Service Principal to establish Persistence and obtain single-factor access to an Azure AD environment.", "tags": {"name": "Azure AD Service Principal Created", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003"], "nist": ["DE.CM"], "observable": [{"name": "displayName", "type": "Other", "role": ["Victim"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Service Principal named $displayName$ created by $user$", "risk_score": 45, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad`  operationName=\"Add service principal\" properties.initiatedBy.user.id=* | rename properties.* as * | rename targetResources{}.displayName as displayName | rename targetResources{}.type as type | stats count min(_time) as firstTime max(_time) as lastTime values(displayName) as displayName by type, user, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_service_principal_created_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment thorough an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Administrator may legitimately create Service Principal. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals", "https://docs.microsoft.com/en-us/powershell/azure/create-azure-service-principal-azureps?view=azps-8.2.0", "https://www.truesec.com/hub/blog/using-a-legitimate-application-to-create-persistence-and-initiate-email-campaigns", "https://www.inversecos.com/2021/10/how-to-backdoor-azure-applications-and.html", "https://attack.mitre.org/techniques/T1136/003/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_service_principal_created_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Service Principal Created:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_add_service_principal/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_ad_add_service_principal/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Service Principal New Client Credentials", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "e3adc0d3-9e4b-4b5d-b662-12cec1adff2a", "description": "The following analytic identifies the addition of new credentials for Service Principals and Applications in addition to existing legitimate credentials in Azure AD. These credentials include both x509 certificates and passwords. With sufficient permissions, there are a variety of ways to add credentials including the Azure Portal, Azure command line interface, and Azure or Az PowerShell modules. Adversaries and red teams alike who have obtained privileged access to Azure AD may add credentials to Service Principals to maintain persistent access to victim accounts and other instances within the Azure environment. By compromising an account who is an Owner of an application with privileged access, attackers may also escalate their privileges in an Azure AD environment by adding new credentials and logging in as the service principal.", "tags": {"name": "Azure AD Service Principal New Client Credentials", "analytic_story": ["Azure Active Directory Persistence", "Azure Active Directory Privilege Escalation", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.001"], "nist": ["DE.CM"], "observable": [{"name": "displayName", "type": "User", "role": ["Victim"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "New credentials added for Service Principal $properties.targetResources{}.displayName$", "risk_score": 35, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  category=AuditLogs operationName=\"Update application*Certificates and secrets management \" | rename properties.* as * | rename  targetResources{}.* as * | stats count min(_time) as firstTime max(_time) as lastTime values(displayName) as displayName by user, modifiedProperties{}.newValue, src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_service_principal_new_client_credentials_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "Service Principal client credential modifications may be part of legitimate administrative operations. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/001/", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT501/AZT501-2/", "https://hausec.com/2021/10/26/attacking-azure-azure-ad-part-ii/", "https://www.inversecos.com/2021/10/how-to-backdoor-azure-applications-and.html", "https://www.mandiant.com/resources/blog/apt29-continues-targeting-microsoft", "https://microsoft.github.io/Azure-Threat-Research-Matrix/PrivilegeEscalation/AZT405/AZT405-3/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_service_principal_new_client_credentials_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Service Principal New Client Credentials:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.001/azure_ad_service_principal_credentials/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.001/azure_ad_service_principal_credentials/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Service Principal Owner Added", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 3, "id": "7ddf2084-6cf3-4a44-be83-474f7b73c701", "description": "The following analytic identifies the addition of a new owner for a Service Principal within an Azure AD tenant. An Azure Service Principal is an identity designed to be used with applications, services, and automated tools to access resources. It is similar to a service account within an Active Directory environment. Service Principal authentication does not support multi-factor authentication nor conditional access policies. Adversaries and red teams alike who have obtained administrative access may add a new owner for an existing Service Principal to establish Persistence and obtain single-factor access to an Azure AD environment. Attackers who are looking to escalate their privileges by leveraging a Service Principals permissions may also add a new owner.", "tags": {"name": "Azure AD Service Principal Owner Added", "analytic_story": ["Azure Active Directory Persistence", "Azure Active Directory Privilege Escalation", "NOBELIUM Group"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.CM"], "observable": [{"name": "displayName", "type": "Other", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "A new owner was added for service principal $displayName$ by $initiatedBy$", "risk_score": 54, "security_domain": "audit", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  operationName=\"Add owner to application\" | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | rename targetResources{}.userPrincipalName as newOwner | rename targetResources{}.modifiedProperties{}.newValue as displayName | eval displayName = mvindex(displayName,1) | where initiatedBy!=newOwner | stats count min(_time) as firstTime max(_time) as lastTime values(displayName) as displayName by initiatedBy, result, operationName, newOwner | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_service_principal_owner_added_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "Administrator may legitimately add new owners for Service Principals. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_service_principal_owner_added_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Service Principal Owner Added:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/azure_ad_add_serviceprincipal_owner/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/azure_ad_add_serviceprincipal_owner/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Successful Authentication From Different Ips", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 3, "id": "be6d868d-33b6-4aaa-912e-724fb555b11a", "description": "The following analytic identifies an Azure AD account successfully authenticating from more than one unique Ip address in the span of 30 minutes. This behavior could represent an adversary who has stolen credentials via a phishing attack or some other method and using them to access corporate online resources around the same time as a legitimate user. As users may behave differently across organizations, security teams should test and customize this detection to fit their environments.", "tags": {"name": "Azure AD Successful Authentication From Different Ips", "analytic_story": ["Compromised User Account", "Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110", "T1110.001", "T1110.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ has had successful authentication events from more than one unique IP address in the span of 30 minutes.", "risk_score": 56, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  properties.authenticationDetails{}.succeeded=true category=SignInLogs | rename properties.* as * | bucket span=30m _time | stats count min(_time) as firstTime max(_time) as lastTime dc(src_ip) AS unique_ips values(src_ip) as src_ip values(appDisplayName) as appDisplayName by user | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | where unique_ips  > 1 | `azure_ad_successful_authentication_from_different_ips_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "A user with successful authentication events from different Ips may also represent the legitimate use of more than one device. Filter as needed and/or customize the threshold to fit your environment.", "check_references": false, "references": ["T1110", "T1110.001", "T1110.003"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_successful_authentication_from_different_ips_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Successful Authentication From Different Ips:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/azure_ad_successful_authentication_from_different_ips/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/azure_ad_successful_authentication_from_different_ips/azuread.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Successful PowerShell Authentication", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "62f10052-d7b3-4e48-b57b-56f8e3ac7ceb", "description": "The following analytic identifies a successful authentication event against an Azure AD tenant using PowerShell commandlets. This behavior is not common for regular, non administrative users. After compromising an account in Azure AD, attackers and red teams  alike will perform enumeration and discovery techniques. One method of executing these techniques is leveraging the native PowerShell modules.", "tags": {"name": "Azure AD Successful PowerShell Authentication", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Successful authentication for user $user$ using PowerShell.", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  category=SignInLogs properties.authenticationDetails{}.succeeded=true properties.appDisplayName=\"Microsoft Azure PowerShell\" | rename properties.*  as * | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by src_ip, appDisplayName, user_agent | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_successful_powershell_authentication_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "Administrative users will likely use PowerShell commandlets to troubleshoot and maintain the environment. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1078/004/", "https://docs.microsoft.com/en-us/powershell/module/azuread/connect-azuread?view=azureadps-2.0", "https://securitycafe.ro/2022/04/29/pentesting-azure-recon-techniques/", "https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Cloud%20-%20Azure%20Pentest.md"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_successful_powershell_authentication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Successful PowerShell Authentication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azuread_pws/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azuread_pws/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Successful Single-Factor Authentication", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "a560e7f6-1711-4353-885b-40be53101fcd", "description": "The following analytic identifies a successful authentication event against Azure Active Directory for an account without Multi-Factor Authentication enabled. This could be evidence of a missconfiguration, a policy violation or an account take over attempt that should be investigated", "tags": {"name": "Azure AD Successful Single-Factor Authentication", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Successful authentication for user $user$ without MFA", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` category=SignInLogs properties.authenticationRequirement=singleFactorAuthentication properties.authenticationDetails{}.succeeded=true | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by src_ip, appDisplayName, authenticationRequirement | `azure_ad_successful_single_factor_authentication_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "Although not recommended, certain users may be required without multi-factor authentication. Filter as needed", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1078/004/", "https://docs.microsoft.com/en-us/azure/active-directory/authentication/concept-mfa-howitworks*", "https://www.forbes.com/sites/daveywinder/2020/07/08/new-dark-web-audit-reveals-15-billion-stolen-logins-from-100000-breaches-passwords-hackers-cybercrime/?sh=69927b2a180f"], "datamodel": ["Authentication"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "azure_ad_successful_single_factor_authentication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Successful Single-Factor Authentication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azuread/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azuread/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD Tenant Wide Admin Consent Granted", "author": "Mauricio Velazco, Splunk", "date": "2023-09-14", "version": 2, "id": "dc02c0ee-6ac0-4c7f-87ba-8ce43a4e4418", "description": "The following analytic identifies instances where admin consent is granted to an application within an Azure AD tenant. It leverages Azure AD audit logs, specifically events related to the admin consent action within the ApplicationManagement category. The admin consent action allows applications to access data across the entire tenant, potentially encompassing a vast amount of organizational data. Given its broad scope and the sensitivity of some permissions that can only be granted via admin consent, it's crucial to monitor this action. Unauthorized or inadvertent granting of admin consent can lead to significant security risks, including data breaches, unauthorized data access, and potential compliance violations. If an attacker successfully tricks an administrator into granting admin consent to a malicious or compromised application, they can gain extensive and persistent access to organizational data. This can lead to data exfiltration, espionage, further malicious activities within the tenant, and potential breaches of compliance regulations", "tags": {"name": "Azure AD Tenant Wide Admin Consent Granted", "analytic_story": ["Azure Active Directory Persistence", "NOBELIUM Group"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Administrator $user$ consented an OAuth application for the tenant.", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` operationName=\"Consent to application\" | eval new_field=mvindex('properties.targetResources{}.modifiedProperties{}.newValue', 4) | rename properties.* as *  | rex field=new_field \"ConsentType: (?<ConsentType>[^\\,]+)\" | rex field=new_field \"Scope: (?<Scope>[^\\,]+)\"  | search  ConsentType = \"AllPrincipals\"  | stats count min(_time) as firstTime max(_time) as lastTime by operationName, user, targetResources{}.displayName, targetResources{}.id, ConsentType, Scope | `security_content_ctime(firstTime)`  | `security_content_ctime(lastTime)` | `azure_ad_tenant_wide_admin_consent_granted_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Auditlogs log category.", "known_false_positives": "Legitimate applications may be granted tenant wide consent, filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/003/", "https://www.mandiant.com/resources/blog/remediation-and-hardening-strategies-for-microsoft-365-to-defend-against-unc2452", "https://learn.microsoft.com/en-us/security/operations/incident-response-playbook-app-consent", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/grant-admin-consent?pivots=portal", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT501/AZT501-2/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_tenant_wide_admin_consent_granted_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Tenant Wide Admin Consent Granted:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_admin_consent/azure_ad_admin_consent.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/azure_ad_admin_consent/azure_ad_admin_consent.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD Unusual Number of Failed Authentications From Ip", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2022-07-11", "version": 2, "id": "3d8d3a36-93b8-42d7-8d91-c5f24cec223d", "description": "The following analytic identifies one source Ip failing to authenticate with multiple valid users. This behavior could represent an adversary performing a Password Spraying attack against an Azure Active Directory tenant to obtain initial access or elevate privileges. Error Code 50126 represents an invalid password.\\\nThe detection calculates the standard deviation for source Ip and leverages the 3-sigma statistical rule to identify an unusual number of failed authentication attempts. To customize this analytic, users can try different combinations of the `bucket` span time and the calculation of the `upperBound` field. This logic can be used for real time security monitoring as well as threat hunting exercises.\\\nWhile looking for anomalies using statistical methods like the standard deviation can have benefits, we also recommend using threshold-based detections to complement coverage. A similar analytic following the threshold model is `Azure AD Multiple Users Failing To Authenticate From Ip`.", "tags": {"name": "Azure AD Unusual Number of Failed Authentications From Ip", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "userPrincipalName", "type": "User", "role": ["Victim"]}, {"name": "ipAddress", "type": "IP Address", "role": ["Attacker"]}], "message": "Possible Password Spraying attack against Azure AD from source ip $ipAddress$", "risk_score": 54, "security_domain": "access", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  category=SignInLogs properties.status.errorCode=50126 properties.authenticationDetails{}.succeeded=false | rename properties.* as * | bucket span=5m _time | stats  dc(userPrincipalName) AS unique_accounts values(userPrincipalName) as userPrincipalName by _time, ipAddress | eventstats  avg(unique_accounts) as ip_avg, stdev(unique_accounts) as ip_std by ipAddress | eval  upperBound=(ip_avg+ip_std*3) | eval  isOutlier=if(unique_accounts > 10 and unique_accounts >= upperBound, 1,0) | where isOutlier = 1 | `azure_ad_unusual_number_of_failed_authentications_from_ip_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the Signin log category.", "known_false_positives": "A source Ip failing to authenticate with multiple users is not a common for legitimate behavior.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://docs.microsoft.com/azure/active-directory/reports-monitoring/reference-sign-ins-error-codes"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "azure_ad_unusual_number_of_failed_authentications_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD Unusual Number of Failed Authentications From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/password_spraying_azuread/azuread_signin.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/password_spraying_azuread/azuread_signin.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD User Consent Blocked for Risky Application", "author": "Mauricio Velazco, Splunk", "date": "2023-10-27", "version": 1, "id": "06b8ec9a-d3b5-4882-8f16-04b4d10f5eab", "description": "The following analytic identifies instances where Azure AD has blocked a user's attempt to grant consent to an application deemed risky or potentially malicious. This suggests that the application has exhibited behaviors or characteristics that are commonly associated with malicious intent or poses a security risk. This detection leverages the Azure AD audit logs, specifically focusing on events related to user consent actions and system-driven blocks. By filtering for blocked consent actions associated with applications, the analytic highlights instances where Azure's built-in security measures have intervened. Applications that are flagged and blocked by Azure typically exhibit suspicious characteristics or behaviors. Monitoring for these blocked consent attempts helps security teams identify potential threats early on and can provide insights into users who might be targeted or susceptible to such risky applications. It's an essential layer of defense in ensuring that malicious or risky applications don't gain access to organizational data. If the detection is a true positive, it indicates that the built-in security measures of O365 successfully prevented a potentially harmful application from gaining access. However, the attempt itself suggests that either a user might be targeted or that there's a presence of malicious applications trying to infiltrate the organization. Immediate investigation is required to understand the context of the block and to take further preventive measures.", "tags": {"name": "Azure AD User Consent Blocked for Risky Application", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure AD tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "Azure AD has blocked $user$ attempt to grant to consent to an application deemed risky.", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`azure_monitor_aad` operationName=\"Consent to application\" properties.result=failure | rename properties.* as *  | eval reason_index = if(mvfind('targetResources{}.modifiedProperties{}.displayName', \"ConsentAction.Reason\") >= 0, mvfind('targetResources{}.modifiedProperties{}.displayName', \"ConsentAction.Reason\"), -1) | eval permissions_index = if(mvfind('targetResources{}.modifiedProperties{}.displayName', \"ConsentAction.Permissions\") >= 0, mvfind('targetResources{}.modifiedProperties{}.displayName', \"ConsentAction.Permissions\"), -1) | search reason_index >= 0  | eval reason = mvindex('targetResources{}.modifiedProperties{}.newValue',reason_index) | eval permissions = mvindex('targetResources{}.modifiedProperties{}.newValue',permissions_index) | search reason = \"\\\"Risky application detected\\\"\" | rex field=permissions \"Scope: (?<Scope>[^,]+)\" | stats count min(_time) as firstTime max(_time) as lastTime by operationName, user, reason, Scope | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_user_consent_blocked_for_risky_application_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "UPDATE_KNOWN_FALSE_POSITIVES", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/protect-against-consent-phishing", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": ["Risk"], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_user_consent_blocked_for_risky_application_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD User Consent Blocked for Risky Application:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/azure_ad_user_consent_blocked/azure_ad_user_consent_blocked.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/azure_ad_user_consent_blocked/azure_ad_user_consent_blocked.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD User Consent Denied for OAuth Application", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "bb093c30-d860-4858-a56e-cd0895d5b49c", "description": "The following analytic identifies instances where a user has actively denied consent to an OAuth application seeking permissions within the Azure AD environment. This suggests that the user either recognized something suspicious about the application or chose not to grant it the requested permissions for other reasons. This detection leverages the Azure AD's audit logs, specifically focusing on events related to user consent actions. By filtering for denied consent actions associated with OAuth applications, the analytic captures instances where users have actively rejected permission requests. While user-denied consents can be routine, they can also be indicative of users spotting potentially suspicious or unfamiliar applications. By monitoring these denied consent attempts, security teams can gain insights into applications that might be perceived as risky or untrusted by users. It can also serve as a feedback loop for security awareness training, indicating that users are being cautious about granting permissions. If the detection is a true positive, it indicates that a user has actively prevented an OAuth application from gaining the permissions it requested. While this is a proactive security measure on the user's part, it's essential for security teams to review the context of the denial. Understanding why certain applications are being denied can help in refining application whitelisting policies and ensuring that no malicious applications are attempting to gain access.", "tags": {"name": "Azure AD User Consent Denied for OAuth Application", "analytic_story": ["Azure Active Directory Account Takeover"], "asset_type": "Azure AD", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ denied consent for an OAuth application.", "risk_score": 36, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad` operationName=\"Sign-in activity\" properties.status.errorCode=65004 | rename properties.* as * | stats count min(_time) as firstTime max(_time) as lastTime by operationName, user, appDisplayName, status.failureReason | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_user_consent_denied_for_oauth_application_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment through an EventHub. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the SignInLogs log category.", "known_false_positives": "Users may deny consent for legitimate applications by mistake, filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/protect-against-consent-phishing", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_user_consent_denied_for_oauth_application_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD User Consent Denied for OAuth Application:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/azure_ad_user_consent_declined/azure_ad_user_consent_declined.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/azure_ad_user_consent_declined/azure_ad_user_consent_declined.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad"}]}]}, {"name": "Azure AD User Enabled And Password Reset", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2023-12-20", "version": 2, "id": "1347b9e8-2daa-4a6f-be73-b421d3d9e268", "description": "The following analytic identifies an Azure AD user enabling a previously disabled account and resetting its password within 2 minutes. This behavior could represent an adversary who has obtained administrative access and is trying to establish a backdoor identity within an Azure AD tenant.", "tags": {"name": "Azure AD User Enabled And Password Reset", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "A user account, $user$, was enabled and its password reset within 2 minutes by $initiatedBy$", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  (operationName=\"Enable account\" OR operationName=\"Reset password (by admin)\" OR operationName=\"Update user\") | transaction user startsWith=(operationName=\"Enable account\") endsWith=(operationName=\"Reset password (by admin)\") maxspan=2m | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | stats count min(_time) as firstTime max(_time) as lastTime values(operationName) as operationName values(initiatedBy) as initiatedBy by user, result | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_user_enabled_and_password_reset_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "While not common, Administrators may enable accounts and reset their passwords for legitimate reasons. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_user_enabled_and_password_reset_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD User Enabled And Password Reset:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/azure_ad_enable_and_reset/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/azure_ad_enable_and_reset/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure AD User ImmutableId Attribute Updated", "author": "Mauricio Velazco, Gowthamaraj Rajendran, Splunk", "date": "2022-09-02", "version": 1, "id": "0c0badad-4536-4a84-a561-5ff760f3c00e", "description": "The following analytic identifies the modification of the SourceAnchor (also called ImmutableId) attribute for an Azure Active Directory user. Updating this attribute is a step required to set up the Azure Active Directory identity federation backdoor technique discovered by security researcher Nestori Syynimaa. Similar to Active Directory, Azure AD uses the concept of domains to manage directories of identities. A new Azure AD tenant will initially contain a single domain that is commonly called the `cloud-only` onmicrosoft.com domain. Organizations can also add their registered custom domains to Azure AD for email addresses to match the organizations domain name. If the organization intends to use a third-party identity provider such as ADFS for authentication, the added custom domains can be configured as federated. An adversary who has obtained privileged access to an Azure AD tenant may leverage this technique to establish persistence and be able to authenticate to Azure AD impersonating any user and bypassing the requirement to have a valid password and/or perform MFA.", "tags": {"name": "Azure AD User ImmutableId Attribute Updated", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure Active Directory", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "initiatedBy", "type": "User", "role": ["Attacker"]}], "message": "The SourceAnchor or ImmutableID attribute has been modified for user $user$ by $initiatedBy$", "risk_score": 45, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `azure_monitor_aad`  operationName=\"Update user\" properties.targetResources{}.modifiedProperties{}.displayName=SourceAnchor | rename properties.* as * | rename initiatedBy.user.userPrincipalName as initiatedBy | rename targetResources{}.modifiedProperties{}.newValue as modifiedProperties | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user values(modifiedProperties) as modifiedProperties by initiatedBy, src_ip, result, operationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_ad_user_immutableid_attribute_updated_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase(https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Active Directory events into your Splunk environment. This analytic was written to be used with the azure:monitor:aad sourcetype leveraging the AuditLog log category.", "known_false_positives": "The SourceAnchor (also called ImmutableId) Azure AD attribute has legitimate uses for directory synchronization. Investigate and filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/active-directory/hybrid/plan-connect-design-concepts", "https://www.mandiant.com/resources/remediation-and-hardening-strategies-microsoft-365-defend-against-apt29-v13", "https://o365blog.com/post/federation-vulnerability/", "https://www.inversecos.com/2021/11/how-to-detect-azure-active-directory.html", "https://www.mandiant.com/resources/blog/detecting-microsoft-365-azure-active-directory-backdoors", "https://attack.mitre.org/techniques/T1098/"], "datamodel": [], "macros": [{"name": "azure_monitor_aad", "definition": "sourcetype=azure:monitor:aad", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_ad_user_immutableid_attribute_updated_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Azure AD", "Entra ID"], "enabled_by_default": false, "test_groups": [{"name": "Azure AD User ImmutableId Attribute Updated:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/azure_ad_set_immutableid/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/azure_ad_set_immutableid/azure-audit.log", "source": "Azure AD", "sourcetype": "azure:monitor:aad", "update_timestamp": true}]}]}, {"name": "Azure Automation Account Created", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 2, "id": "860902fd-2e76-46b3-b050-ba548dab576c", "description": "The following analytic identifies the creation of a new Azure Automation account within an Azure tenant. Azure Automation is a cloud-based automation platform that allows administrators to automate Azure management tasks and orchestrate actions across external systems within Azure using PowerShell and Python. Azure Automation can also be configured to automate tasks on on premise infrastructure using a component called a Hybrid Runbook Worker. Automation accounts serve as a container to isolate Automation resources, runbooks, assets, and configurations from the resources of other accounts. They allow administrators to separate resources into logical environments or delegated responsibilities. Adversaries or red teams who have obtained privileged access to an Azure tenant may create an Azure Automation account with elevated privileges to maintain persistence in the Azure tenant. A malicious Automation Runbook can be created to create Global Administrators in Azure AD, execute code on VMs, etc.", "tags": {"name": "Azure Automation Account Created", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136", "T1136.003"], "nist": ["DE.CM"], "observable": [{"name": "object", "type": "Other", "role": ["Victim"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "A new Azure Automation account $object$ was created by $user$", "risk_score": 63, "security_domain": "audit", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_audit` operationName.localizedValue=\"Create or Update an Azure Automation account\" status.value=Succeeded | dedup object | rename claims.ipaddr as src_ip | rename caller as user | stats count min(_time) as firstTime max(_time) as lastTime values(object) as object by user, src_ip, resourceGroupName, object_path | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_automation_account_created_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Audit events into your Splunk environment. Specifically, this analytic leverages the Azure Activity log category.", "known_false_positives": "Administrators may legitimately create Azure Automation accounts. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/automation/overview", "https://docs.microsoft.com/en-us/azure/automation/automation-create-standalone-account?tabs=azureportal", "https://docs.microsoft.com/en-us/azure/automation/automation-hybrid-runbook-worker", "https://www.inversecos.com/2021/12/how-to-detect-malicious-azure.html", "https://www.netspi.com/blog/technical/cloud-penetration-testing/maintaining-azure-persistence-via-automation-accounts/", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT503/AZT503-3/", "https://attack.mitre.org/techniques/T1136/003/"], "datamodel": [], "macros": [{"name": "azure_audit", "definition": "sourcetype=mscs:azure:audit", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_automation_account_created_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": [{"name": "Azure Automation Account Created:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_automation_account/azure-activity.log", "source": "mscs:azure:audit", "sourcetype": "mscs:azure:audit", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/azure_automation_account/azure-activity.log", "source": "mscs:azure:audit", "sourcetype": "mscs:azure:audit", "update_timestamp": true}]}]}, {"name": "Azure Automation Runbook Created", "author": "Mauricio Velazco, Splunk", "date": "2023-11-07", "version": 2, "id": "178d696d-6dc6-4ee8-9d25-93fee34eaf5b", "description": "The following analytic identifies the creation of a new Azure Automation Runbook within an Azure tenant. Azure Automation is a cloud-based automation platform that allows administrators to automate Azure management tasks and orchestrate actions across external systems within Azure. Azure Automation script files called Runbooks that can be written in PowerShell or Python. Adversaries or red teams who have obtained privileged access to an Azure tenant may create an Azure Automation Runbook that runs with elevated privileges to maintain persistence in the Azure tenant. A malicious Automation Runbook can be created to create Global Administrators in Azure AD, execute code on VMs, etc.", "tags": {"name": "Azure Automation Runbook Created", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136", "T1136.003"], "nist": ["DE.CM"], "observable": [{"name": "object", "type": "Other", "role": ["Victim"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "A new Azure Automation Runbook $object$ was created by $caller$", "risk_score": 63, "security_domain": "audit", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_audit` operationName.localizedValue=\"Create or Update an Azure Automation Runbook\" object!=AzureAutomationTutorial* status.value=Succeeded | dedup object | rename claims.ipaddr as src_ip | rename caller as user | stats count min(_time) as firstTime max(_time) as lastTime values(object) as object by user, src_ip, resourceGroupName, object_path | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_automation_runbook_created_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Audit events into your Splunk environment. Specifically, this analytic leverages the Azure Activity log category.", "known_false_positives": "Administrators may legitimately create Azure Automation Runbooks. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/automation/overview", "https://docs.microsoft.com/en-us/azure/automation/automation-runbook-types", "https://docs.microsoft.com/en-us/azure/automation/manage-runbooks", "https://www.inversecos.com/2021/12/how-to-detect-malicious-azure.html", "https://www.netspi.com/blog/technical/cloud-penetration-testing/maintaining-azure-persistence-via-automation-accounts/", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT503/AZT503-3/", "https://attack.mitre.org/techniques/T1136/003/"], "datamodel": [], "macros": [{"name": "azure_audit", "definition": "sourcetype=mscs:azure:audit", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_automation_runbook_created_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": [{"name": "Azure Automation Runbook Created:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azure_automation_runbook/azure-activity.log", "source": "mscs:azure:audit", "sourcetype": "mscs:azure:audit", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azure_automation_runbook/azure-activity.log", "source": "mscs:azure:audit", "sourcetype": "mscs:azure:audit", "update_timestamp": true}]}]}, {"name": "Azure Runbook Webhook Created", "author": "Mauricio Velazco, Splunk", "date": "2023-12-20", "version": 3, "id": "e98944a9-92e4-443c-81b8-a322e33ce75a", "description": "The following analytic identifies the creation of a new Automation Runbook Webhook within an Azure tenant. Azure Automation is a cloud-based automation platform that allows administrators to automate Azure management tasks and orchestrate actions across external systems within Azure. Azure Automation script files called Runbooks that can be written in PowerShell or Python. One of the ways administrators can configure a Runbook to be executed is through HTTP Webhooks. Webhooks leverage custom unauthenticated URLs that are exposed to the Internet. An adversary who has obtained privileged access to an Azure tenant may create a Webhook to trigger the execution of an Automation Runbook with malicious code that can create users or execute code on a VM. This provides a persistent foothold on the environment.", "tags": {"name": "Azure Runbook Webhook Created", "analytic_story": ["Azure Active Directory Persistence"], "asset_type": "Azure", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "object", "type": "Other", "role": ["Victim"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "A new Azure Runbook Webhook $object$ was created by $caller$", "risk_score": 63, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `azure_audit` operationName.localizedValue=\"Create or Update an Azure Automation webhook\" status.value=Succeeded | dedup object | rename claims.ipaddr as src_ip | rename caller as user | stats count min(_time) as firstTime max(_time) as lastTime values(object) as object by user, src_ip, resourceGroupName, object_path | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `azure_runbook_webhook_created_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Microsoft Cloud Services from Splunkbase (https://splunkbase.splunk.com/app/3110/#/details). You must be ingesting Azure Audit events into your Splunk environment. Specifically, this analytic leverages the Azure Activity log category.", "known_false_positives": "Administrators may legitimately create Azure Runbook Webhooks. Filter as needed.", "check_references": false, "references": ["https://docs.microsoft.com/en-us/azure/automation/overview", "https://docs.microsoft.com/en-us/azure/automation/automation-runbook-types", "https://docs.microsoft.com/en-us/azure/automation/automation-webhooks?tabs=portal", "https://www.inversecos.com/2021/12/how-to-detect-malicious-azure.html", "https://www.netspi.com/blog/technical/cloud-penetration-testing/maintaining-azure-persistence-via-automation-accounts/", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT503/AZT503-3/", "https://attack.mitre.org/techniques/T1078/004/"], "datamodel": [], "macros": [{"name": "azure_audit", "definition": "sourcetype=mscs:azure:audit", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "azure_runbook_webhook_created_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": [{"name": "Azure Runbook Webhook Created:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azure_runbook_webhook/azure-activity.log", "source": "mscs:azure:audit", "sourcetype": "mscs:azure:audit", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/azure_runbook_webhook/azure-activity.log", "source": "mscs:azure:audit", "sourcetype": "mscs:azure:audit", "update_timestamp": true}]}]}, {"name": "Circle CI Disable Security Job", "author": "Patrick Bareiss, Splunk", "date": "2021-09-02", "version": 1, "id": "4a2fdd41-c578-4cd4-9ef7-980e352517f2", "description": "This analytic searches for a specific behavior in CircleCI pipelines such as the disabling of security jobs. The detection is made by using a Splunk query that renames certain fields and retrieves values for specified job names, workflow IDs and names, user information, commit messages, URLs, and branches. Then, the query identifies mandatory jobs for each workflow and searches for instances where they were run. The search also identifies the phase of the pipeline as \"build\" and extracts the repository name from the URL using regular expressions. The detection is important because it detects attempts to bypass security measures in CircleCI pipelines, which can potentially lead to malicious code being introduced into the pipeline, data breaches, system downtime, and reputational damage.  False positives might occur since legitimate use cases can require the disabling of security jobs. However, you can proactively monitor and identify any suspicious activity in the pipeline using this analytic and mitigate potential threats through early detection.", "tags": {"name": "Circle CI Disable Security Job", "analytic_story": ["Dev Sec Ops"], "asset_type": "CircleCI", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1554"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "disable security job $mandatory_job$ in workflow $workflow_name$ from user $user$", "risk_score": 72, "security_domain": "network", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`circleci` | rename vcs.committer_name as user vcs.subject as commit_message vcs.url as url workflows.* as *  | stats values(job_name) as job_names by workflow_id workflow_name user commit_message url branch | lookup mandatory_job_for_workflow workflow_name OUTPUTNEW job_name AS mandatory_job | search mandatory_job=* | eval mandatory_job_executed=if(like(job_names, \"%\".mandatory_job.\"%\"), 1, 0) | where mandatory_job_executed=0 | eval phase=\"build\" | rex field=url \"(?<repository>[^\\/]*\\/[^\\/]*)$\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `circle_ci_disable_security_job_filter`", "how_to_implement": "You must index CircleCI logs.", "known_false_positives": "unknown", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "circleci", "definition": "sourcetype=circleci", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "circle_ci_disable_security_job_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "mandatory_job_for_workflow", "description": "A lookup file that will be used to define the mandatory job for workflow", "filename": "mandatory_job_for_workflow.csv", "file_path": "/home/jose.costa/splunk/content/lookups/mandatory_job_for_workflow.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Circle CI Disable Security Job:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1554/circle_ci_disable_security_job/circle_ci_disable_security_job.json", "source": "circleci", "sourcetype": "circleci"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1554/circle_ci_disable_security_job/circle_ci_disable_security_job.json", "source": "circleci", "sourcetype": "circleci"}]}]}, {"name": "Circle CI Disable Security Step", "author": "Patrick Bareiss, Splunk", "date": "2021-09-01", "version": 1, "id": "72cb9de9-e98b-4ac9-80b2-5331bba6ea97", "description": "The following analytic detects the disablement of security steps in a CircleCI pipeline. Addressing instances of security step disablement in CircleCI pipelines can mitigate the risks associated with potential security vulnerabilities and unauthorized changes. A proactive approach helps protect the organization's infrastructure, data, and overall security posture. The detection is made by a Splunk query that searches for specific criteria within CircleCI logs through a combination of field renaming, joining, and statistical analysis to identify instances where security steps are disabled. It retrieves information such as job IDs, job names, commit details, and user information from the CircleCI logs.  The detection is important because it indicates potential security vulnerabilities or unauthorized changes to the pipeline caused by someone within the organization intentionally or unintentionally disabling security steps in the CircleCI pipeline.Disabling security steps can leave the pipeline and the associated infrastructure exposed to potential attacks, data breaches, or the introduction of malicious code into the pipeline. Investigate by reviewing the job name, commit details, and user information associated with the disablement of security steps. You must also examine any relevant on-disk artifacts and identify concurrent processes that might indicate the source of the attack or unauthorized change.", "tags": {"name": "Circle CI Disable Security Step", "analytic_story": ["Dev Sec Ops"], "asset_type": "CircleCI", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1554"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "disable security step $mandatory_step$ in job $job_name$ from user $user$", "risk_score": 72, "security_domain": "network", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`circleci` | rename workflows.job_id AS job_id | join job_id [ | search `circleci` | stats values(name) as step_names count by job_id job_name ] | stats count by step_names job_id job_name vcs.committer_name vcs.subject vcs.url owners{} | rename vcs.* as * , owners{} as user | lookup mandatory_step_for_job job_name OUTPUTNEW step_name AS mandatory_step | search mandatory_step=* | eval mandatory_step_executed=if(like(step_names, \"%\".mandatory_step.\"%\"), 1, 0) | where mandatory_step_executed=0 | rex field=url \"(?<repository>[^\\/]*\\/[^\\/]*)$\" | eval phase=\"build\"  | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `circle_ci_disable_security_step_filter`", "how_to_implement": "You must index CircleCI logs.", "known_false_positives": "unknown", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "circleci", "definition": "sourcetype=circleci", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "circle_ci_disable_security_step_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "mandatory_step_for_job", "description": "A lookup file that will be used to define the mandatory step for job", "filename": "mandatory_step_for_job.csv", "file_path": "/home/jose.costa/splunk/content/lookups/mandatory_step_for_job.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Circle CI Disable Security Step:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1554/circle_ci_disable_security_step/circle_ci_disable_security_step.json", "source": "circleci", "sourcetype": "circleci"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1554/circle_ci_disable_security_step/circle_ci_disable_security_step.json", "source": "circleci", "sourcetype": "circleci"}]}]}, {"name": "Cloud API Calls From Previously Unseen User Roles", "author": "David Dorsey, Splunk", "date": "2020-09-04", "version": 1, "id": "2181ad1f-1e73-4d0c-9780-e8880482a08f", "description": "The following analytic detects when a new command is run by a user, who typically does not run those commands. The detection is made by a Splunk query to search for these commands in the Change data model. Identifies commands run by users with the user_type of AssumedRole and a status of success. The query retrieves the earliest and latest timestamps of each command run and groups the results by the user and command. Then, it drops the unnecessary data model object name and creates a lookup to verify if the command was seen before. The lookup table contains information about previously seen cloud API calls for each user role, including the first time the command was seen and whether enough data is available for analysis. If the firstTimeSeenUserApiCall field is null or greater than the relative time of 24 hours ago, it indicates that the command is new and was not seen before. The final result table includes the firstTime, user, object, and command fields of the new commands. It also applies the security_content_ctime function to format the timestamps and applies a filter to remove any cloud API calls from previously unseen user roles. The detection is important because it helps to identify new commands run by different user roles. New commands can indicate potential malicious activity or unauthorized actions within the environment. Detecting and investigating these new commands can help identify and mitigate potential security threats earlier, preventing data breaches, unauthorized access, or other damaging outcomes.", "tags": {"name": "Cloud API Calls From Previously Unseen User Roles", "analytic_story": ["Suspicious Cloud User Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ of type AssumedRole attempting to execute new API calls $command$ that have not been seen before", "risk_score": 36, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where All_Changes.user_type=AssumedRole AND All_Changes.status=success by All_Changes.user, All_Changes.command All_Changes.object | `drop_dm_object_name(\"All_Changes\")` | lookup previously_seen_cloud_api_calls_per_user_role user as user, command as command OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenUserApiCall=min(firstTimeSeen) | where isnull(firstTimeSeenUserApiCall) OR firstTimeSeenUserApiCall > relative_time(now(),\"-24h@h\") | table firstTime, user, object, command |`security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `cloud_api_calls_from_previously_unseen_user_roles_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud API Calls Per User Role - Initial` to build the initial table of user roles, commands, and times. You must also enable the second baseline search `Previously Seen Cloud API Calls Per User Role - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `cloud_api_calls_from_previously_unseen_user_roles_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_api_calls_from_previously_unseen_user_roles_filter`", "known_false_positives": ".", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_api_calls_from_previously_unseen_user_roles_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_api_calls_per_user_role", "description": "A table of users, commands, and the first and last time that they have been seen", "collection": "previously_seen_cloud_api_calls_per_user_role", "fields_list": "_key, user, command, firstTimeSeen, lastTimeSeen, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_api_calls_per_user_role.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud API Calls From Previously Unseen User Roles:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Compute Instance Created By Previously Unseen User", "author": "Rico Valdez, Splunk", "date": "2021-07-13", "version": 2, "id": "37a0ec8d-827e-4d6d-8025-cedf31f3a149", "description": "This search looks for cloud compute instances created by users who have not created them before.", "tags": {"name": "Cloud Compute Instance Created By Previously Unseen User", "analytic_story": ["Cloud Cryptomining"], "asset_type": "Cloud Compute Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "dest", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is creating a new instance $dest$ for the first time", "risk_score": 18, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats `security_content_summariesonly` count earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object) as dest from datamodel=Change where All_Changes.action=created by All_Changes.user All_Changes.vendor_region | `drop_dm_object_name(\"All_Changes\")` | lookup previously_seen_cloud_compute_creations_by_user user as user OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenUser=min(firstTimeSeen) | where isnull(firstTimeSeenUser) OR firstTimeSeenUser > relative_time(now(), \"-24h@h\") | table firstTime, user, dest, count vendor_region | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_by_previously_unseen_user_filter`", "how_to_implement": "You must be ingesting the appropriate cloud-infrastructure logs Run the \"Previously Seen Cloud Compute Creations By User\" support search to create of baseline of previously seen users.", "known_false_positives": "It's possible that a user will start to create compute instances for the first time, for any number of reasons. Verify with the user launching instances that this is the intended behavior.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "security_content_summariesonly", "definition": "summariesonly=false allow_old_summaries=true fillnull_value=null", "description": "search data model's summaries only"}, {"name": "cloud_compute_instance_created_by_previously_unseen_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_compute_creations_by_user", "description": "A table of previously seen users creating cloud instances", "collection": "previously_seen_cloud_compute_creations_by_user", "fields_list": "_key, firstTimeSeen, lastTimeSeen, user, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_compute_creations_by_user.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Compute Instance Created By Previously Unseen User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Compute Instance Created In Previously Unused Region", "author": "David Dorsey, Splunk", "date": "2020-09-02", "version": 1, "id": "fa4089e2-50e3-40f7-8469-d2cc1564ca59", "description": "This search looks at cloud-infrastructure events where an instance is created in any region within the last hour and then compares it to a lookup file of previously seen regions where instances have been created.", "tags": {"name": "Cloud Compute Instance Created In Previously Unused Region", "analytic_story": ["Cloud Cryptomining"], "asset_type": "Cloud Compute Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1535"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "dest", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is creating an instance $dest$ in a new region for the first time", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime latest(_time) as lastTime values(All_Changes.object_id) as dest, count from datamodel=Change where All_Changes.action=created by All_Changes.vendor_region, All_Changes.user | `drop_dm_object_name(\"All_Changes\")` | lookup previously_seen_cloud_regions vendor_region as vendor_region OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenRegion=min(firstTimeSeen) | where isnull(firstTimeSeenRegion) OR firstTimeSeenRegion > relative_time(now(), \"-24h@h\") | table firstTime, user, dest, count , vendor_region | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_in_previously_unused_region_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Regions - Initial` to build the initial table of images observed and times. You must also enable the second baseline search `Previously Seen Cloud Regions - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_in_previously_unused_region_filter` macro.", "known_false_positives": "It's possible that a user has unknowingly started an instance in a new region. Please verify that this activity is legitimate.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_compute_instance_created_in_previously_unused_region_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_regions", "description": "A table of vendor_region values and the first and last time that they have been observed in cloud provisioning activities", "collection": "previously_seen_cloud_regions", "fields_list": "_key, firstTimeSeen, lastTimeSeen, vendor_region, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_regions.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Compute Instance Created In Previously Unused Region:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Compute Instance Created With Previously Unseen Image", "author": "David Dorsey, Splunk", "date": "2018-10-12", "version": 1, "id": "bc24922d-987c-4645-b288-f8c73ec194c4", "description": "The following analytic detects potential instances that are created in a cloud computing environment using new or unknown image IDs that have not been seen before. This detection is important because it helps to investigate and take appropriate action to prevent further damage or unauthorized access to the Cloud environment, which can include data breaches, unauthorized access to sensitive information, or the deployment of malicious payloads within the cloud environment. False positives might occur since legitimate instances can also have previously unseen image IDs. Next steps include conducting an extensive triage and investigation to determine the nature of the activity. During triage, review the details of the created instances, including the user responsible for the creation, the image ID used, and any associated metadata. Additionally, consider inspecting any relevant on-disk artifacts and analyzing concurrent processes to identify the source of the attack.", "tags": {"name": "Cloud Compute Instance Created With Previously Unseen Image", "analytic_story": ["Cloud Cryptomining"], "asset_type": "Cloud Compute Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "dest", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is creating an instance $dest$ with an image that has not been previously seen.", "risk_score": 36, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats count earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object_id) as dest from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.image_id, All_Changes.user | `drop_dm_object_name(\"All_Changes\")` | `drop_dm_object_name(\"Instance_Changes\")` | where image_id != \"unknown\" | lookup previously_seen_cloud_compute_images image_id as image_id OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenImage=min(firstTimeSeen) | where isnull(firstTimeSeenImage) OR firstTimeSeenImage > relative_time(now(), \"-24h@h\") | table firstTime, user, image_id, count, dest | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_with_previously_unseen_image_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Compute Images - Initial` to build the initial table of images observed and times. You must also enable the second baseline search `Previously Seen Cloud Compute Images - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_with_previously_unseen_image_filter` macro.", "known_false_positives": "After a new image is created, the first systems created with that image will cause this alert to fire.  Verify that the image being used was created by a legitimate user.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_compute_instance_created_with_previously_unseen_image_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_compute_images", "description": "A table of previously seen Cloud image IDs", "collection": "previously_seen_cloud_compute_images", "fields_list": "_key, firstTimeSeen, lastTimeSeen, image_id, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_compute_images.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Compute Instance Created With Previously Unseen Image:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Compute Instance Created With Previously Unseen Instance Type", "author": "David Dorsey, Splunk", "date": "2020-09-12", "version": 1, "id": "c6ddbf53-9715-49f3-bb4c-fb2e8a309cda", "description": "The following analytic detects the creation of EC2 instances with previously unseen instance types. The detection is made by using a Splunk query to identify the EC2 instances. First, the query searches for changes in the EC2 instance creation action and filters for instances with instance types that are not recognized or previously seen. Next, the query uses the Splunk tstats command to gather the necessary information from the Change data model. Then, it filters the instances with unknown instance types and reviews previously seen instance types to determine if they are new or not. The detection is important because it identifies attackers attempting to create instances with unknown or potentially compromised instance types, which can be an attempt to gain unauthorized access to sensitive data, compromise of systems, exfiltrate data, potential disruption of services, or launch other malicious activities within the environment. False positives might occur since there might be legitimate reasons for creating instances with previously unseen instance types. Therefore, you must carefully review and triage all alerts.", "tags": {"name": "Cloud Compute Instance Created With Previously Unseen Instance Type", "analytic_story": ["Cloud Cryptomining"], "asset_type": "Cloud Compute Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "dest", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is creating an instance $dest$ with an instance type $instance_type$ that has not been previously seen.", "risk_score": 30, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object_id) as dest, count from datamodel=Change where All_Changes.action=created by All_Changes.Instance_Changes.instance_type, All_Changes.user | `drop_dm_object_name(\"All_Changes\")` | `drop_dm_object_name(\"Instance_Changes\")` | where instance_type != \"unknown\" | lookup previously_seen_cloud_compute_instance_types instance_type as instance_type OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenInstanceType=min(firstTimeSeen) | where isnull(firstTimeSeenInstanceType) OR firstTimeSeenInstanceType > relative_time(now(), \"-24h@h\") | table firstTime, user, dest, count, instance_type | `security_content_ctime(firstTime)` | `cloud_compute_instance_created_with_previously_unseen_instance_type_filter`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider. You should run the baseline search `Previously Seen Cloud Compute Instance Types - Initial` to build the initial table of instance types observed and times. You must also enable the second baseline search `Previously Seen Cloud Compute Instance Types - Update` to keep this table up to date and to age out old data. You can also provide additional filtering for this search by customizing the `cloud_compute_instance_created_with_previously_unseen_instance_type_filter` macro.", "known_false_positives": "It is possible that an admin will create a new system using a new instance type that has never been used before. Verify with the creator that they intended to create the system with the new instance type.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_compute_instance_created_with_previously_unseen_instance_type_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_compute_instance_types", "description": "A place holder for a list of used cloud compute instance types", "collection": "previously_seen_cloud_compute_instance_types", "fields_list": "_key, firstTimeSeen, lastTimeSeen, instance_type, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_compute_instance_types.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Compute Instance Created With Previously Unseen Instance Type:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Instance Modified By Previously Unseen User", "author": "Rico Valdez, Splunk", "date": "2020-07-29", "version": 1, "id": "7fb15084-b14e-405a-bd61-a6de15a40722", "description": "This search looks for cloud instances being modified by users who have not previously modified them.", "tags": {"name": "Cloud Instance Modified By Previously Unseen User", "analytic_story": ["Suspicious Cloud Instance Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078.004", "T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ is modifying an instance $object_id$ for the first time.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats `security_content_summariesonly` count earliest(_time) as firstTime, latest(_time) as lastTime values(All_Changes.object_id) as object_id values(All_Changes.command) as command from datamodel=Change where All_Changes.action=modified All_Changes.change_type=EC2 All_Changes.status=success by All_Changes.user | `drop_dm_object_name(\"All_Changes\")` | lookup previously_seen_cloud_instance_modifications_by_user user as user OUTPUTNEW firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenUser=min(firstTimeSeen) | where isnull(firstTimeSeenUser) OR firstTimeSeenUser > relative_time(now(), \"-24h@h\") | table firstTime user command object_id count | `security_content_ctime(firstTime)` | `cloud_instance_modified_by_previously_unseen_user_filter`", "how_to_implement": "This search has a dependency on other searches to create and update a baseline of users observed to be associated with this activity. The search \"Previously Seen Cloud Instance Modifications By User - Update\" should be enabled for this detection to properly work.", "known_false_positives": "It's possible that a new user will start to modify EC2 instances when they haven't before for any number of reasons. Verify with the user that is modifying instances that this is the intended behavior.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "security_content_summariesonly", "definition": "summariesonly=false allow_old_summaries=true fillnull_value=null", "description": "search data model's summaries only"}, {"name": "cloud_instance_modified_by_previously_unseen_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_instance_modifications_by_user", "description": "A table of users seen making instance modifications, and the first and last time that the activity was observed", "collection": "previously_seen_cloud_instance_modifications_by_user", "fields_list": "_key, firstTimeSeen, lastTimeSeen, user, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_instance_modifications_by_user.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Instance Modified By Previously Unseen User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Provisioning Activity From Previously Unseen City", "author": "Rico Valdez, Bhavin Patel, Splunk", "date": "2020-10-09", "version": 1, "id": "e7ecc5e0-88df-48b9-91af-51104c68f02f", "description": "This search looks for cloud provisioning activities from previously unseen cities. Provisioning activities are defined broadly as any event that runs or creates something.", "tags": {"name": "Cloud Provisioning Activity From Previously Unseen City", "analytic_story": ["Suspicious Cloud Provisioning Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "object", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is starting or creating an instance $object$ for the first time in City $City$ from IP address $src$", "risk_score": 18, "security_domain": "threat", "risk_severity": "low", "manual_test": "This search needs the baseline to be run first to create a lookup", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.object, All_Changes.command | `drop_dm_object_name(\"All_Changes\")` | iplocation src | where isnotnull(City) | lookup previously_seen_cloud_provisioning_activity_sources City as City OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenCity=min(firstTimeSeen) | where isnull(firstTimeSeenCity) OR firstTimeSeenCity > relative_time(now(), `previously_unseen_cloud_provisioning_activity_window`) | table firstTime, src, City, user, object, command | `cloud_provisioning_activity_from_previously_unseen_city_filter` | `security_content_ctime(firstTime)`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_city_filter` macro.", "known_false_positives": "This is a strictly behavioral search, so we define \"false positive\" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no \"false positives\" in a traditional sense, there is definitely lots of noise.\\\n This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "previously_unseen_cloud_provisioning_activity_window", "definition": "\"-70m@m\"", "description": "Use this macro to determine how far back you should be checking for new provisioning activities"}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_provisioning_activity_from_previously_unseen_city_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_provisioning_activity_sources", "description": "A table of source IPs, geographic locations, and the first and last time that they have that done cloud provisioning activities", "collection": "previously_seen_cloud_provisioning_activity_sources", "fields_list": "_key, src, City, Country, Region, firstTimeSeen, lastTimeSeen, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_provisioning_activity_sources.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Provisioning Activity From Previously Unseen City:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Provisioning Activity From Previously Unseen Country", "author": "Rico Valdez, Bhavin Patel, Splunk", "date": "2020-10-09", "version": 1, "id": "94994255-3acf-4213-9b3f-0494df03bb31", "description": "This search looks for cloud provisioning activities from previously unseen countries. Provisioning activities are defined broadly as any event that runs or creates something.", "tags": {"name": "Cloud Provisioning Activity From Previously Unseen Country", "analytic_story": ["Suspicious Cloud Provisioning Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "object", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is starting or creating an instance $object$ for the first time in Country $Country$ from IP address $src$", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "manual_test": "This search needs the baseline to be run first to create a lookup", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.object, All_Changes.command | `drop_dm_object_name(\"All_Changes\")` | iplocation src | where isnotnull(Country) | lookup previously_seen_cloud_provisioning_activity_sources Country as Country OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenCountry=min(firstTimeSeen) | where isnull(firstTimeSeenCountry) OR firstTimeSeenCountry > relative_time(now(), \"-24h@h\") | table firstTime, src, Country, user, object, command | `cloud_provisioning_activity_from_previously_unseen_country_filter` | `security_content_ctime(firstTime)`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_country_filter` macro.", "known_false_positives": "This is a strictly behavioral search, so we define \"false positive\" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no \"false positives\" in a traditional sense, there is definitely lots of noise.\\\n This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_provisioning_activity_from_previously_unseen_country_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_provisioning_activity_sources", "description": "A table of source IPs, geographic locations, and the first and last time that they have that done cloud provisioning activities", "collection": "previously_seen_cloud_provisioning_activity_sources", "fields_list": "_key, src, City, Country, Region, firstTimeSeen, lastTimeSeen, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_provisioning_activity_sources.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Provisioning Activity From Previously Unseen Country:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Provisioning Activity From Previously Unseen IP Address", "author": "Rico Valdez, Splunk", "date": "2020-08-16", "version": 1, "id": "f86a8ec9-b042-45eb-92f4-e9ed1d781078", "description": "This search looks for cloud provisioning activities from previously unseen IP addresses. Provisioning activities are defined broadly as any event that runs or creates something.", "tags": {"name": "Cloud Provisioning Activity From Previously Unseen IP Address", "analytic_story": ["Suspicious Cloud Provisioning Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "object_id", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is starting or creating an instance $object_id$ for the first time from IP address $src$", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "manual_test": "This search needs the baseline to be run first to create a lookup", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime, latest(_time) as lastTime, values(All_Changes.object_id) as object_id from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.command | `drop_dm_object_name(\"All_Changes\")` | lookup previously_seen_cloud_provisioning_activity_sources src as src OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenSrc=min(firstTimeSeen) | where isnull(firstTimeSeenSrc) OR firstTimeSeenSrc > relative_time(now(), `previously_unseen_cloud_provisioning_activity_window`) | table firstTime, src, user, object_id, command | `cloud_provisioning_activity_from_previously_unseen_ip_address_filter` | `security_content_ctime(firstTime)`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_ip_address_filter` macro.", "known_false_positives": "This is a strictly behavioral search, so we define \"false positive\" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no \"false positives\" in a traditional sense, there is definitely lots of noise.\\\n This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "previously_unseen_cloud_provisioning_activity_window", "definition": "\"-70m@m\"", "description": "Use this macro to determine how far back you should be checking for new provisioning activities"}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_provisioning_activity_from_previously_unseen_ip_address_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_provisioning_activity_sources", "description": "A table of source IPs, geographic locations, and the first and last time that they have that done cloud provisioning activities", "collection": "previously_seen_cloud_provisioning_activity_sources", "fields_list": "_key, src, City, Country, Region, firstTimeSeen, lastTimeSeen, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_provisioning_activity_sources.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Provisioning Activity From Previously Unseen IP Address:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Provisioning Activity From Previously Unseen Region", "author": "Rico Valdez, Bhavin Patel, Splunk", "date": "2020-08-16", "version": 1, "id": "5aba1860-9617-4af9-b19d-aecac16fe4f2", "description": "This search looks for cloud provisioning activities from previously unseen regions. Provisioning activities are defined broadly as any event that runs or creates something.", "tags": {"name": "Cloud Provisioning Activity From Previously Unseen Region", "analytic_story": ["Suspicious Cloud Provisioning Activities"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "object", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ is starting or creating an instance $object$ for the first time in region $Region$ from IP address $src$", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "manual_test": "This search needs the baseline to be run first to create a lookup", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime, latest(_time) as lastTime from datamodel=Change where (All_Changes.action=started OR All_Changes.action=created) All_Changes.status=success by All_Changes.src, All_Changes.user, All_Changes.object, All_Changes.command | `drop_dm_object_name(\"All_Changes\")` | iplocation src | where isnotnull(Region) | lookup previously_seen_cloud_provisioning_activity_sources Region as Region OUTPUT firstTimeSeen, enough_data | eventstats max(enough_data) as enough_data | where enough_data=1 | eval firstTimeSeenRegion=min(firstTimeSeen) | where isnull(firstTimeSeenRegion) OR firstTimeSeenRegion > relative_time(now(), `previously_unseen_cloud_provisioning_activity_window`) | table firstTime, src, Region, user, object, command | `cloud_provisioning_activity_from_previously_unseen_region_filter` | `security_content_ctime(firstTime)`", "how_to_implement": "You must be ingesting your cloud infrastructure logs from your cloud provider.  You should run the baseline search `Previously Seen Cloud Provisioning Activity Sources - Initial` to build the initial table of source IP address, geographic locations, and times. You must also enable the second baseline search `Previously Seen Cloud Provisioning Activity Sources - Update` to keep this table up to date and to age out old data. You can adjust the time window for this search by updating the `previously_unseen_cloud_provisioning_activity_window` macro. You can also provide additional filtering for this search by customizing the `cloud_provisioning_activity_from_previously_unseen_region_filter` macro.", "known_false_positives": "This is a strictly behavioral search, so we define \"false positive\" slightly differently. Every time this fires, it will accurately reflect the first occurrence in the time period you're searching within, plus what is stored in the cache feature. But while there are really no \"false positives\" in a traditional sense, there is definitely lots of noise.\\\n This search will fire any time a new IP address is seen in the **GeoIP** database for any kind of provisioning activity. If you typically do all provisioning from tools inside of your country, there should be few false positives. If you are located in countries where the free version of **MaxMind GeoIP** that ships by default with Splunk has weak resolution (particularly small countries in less economically powerful regions), this may be much less valuable to you.", "check_references": false, "references": [], "datamodel": ["Change"], "macros": [{"name": "previously_unseen_cloud_provisioning_activity_window", "definition": "\"-70m@m\"", "description": "Use this macro to determine how far back you should be checking for new provisioning activities"}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "cloud_provisioning_activity_from_previously_unseen_region_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "previously_seen_cloud_provisioning_activity_sources", "description": "A table of source IPs, geographic locations, and the first and last time that they have that done cloud provisioning activities", "collection": "previously_seen_cloud_provisioning_activity_sources", "fields_list": "_key, src, City, Country, Region, firstTimeSeen, lastTimeSeen, enough_data", "file_path": "/home/jose.costa/splunk/content/lookups/previously_seen_cloud_provisioning_activity_sources.yml"}], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Provisioning Activity From Previously Unseen Region:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Cloud Security Groups Modifications by User", "author": "Bhavin Patel, Splunk", "date": "2024-02-21", "version": 1, "id": "cfe7cca7-2746-4bdf-b712-b01ed819b9de", "description": "The following analytic identifies users who are unsually modifying security group in your cloud enriovnment,focusing on actions such as modifications, deletions, or creations performed by users over 30-minute intervals. Analyzing patterns of modifications to security groups can help in identifying anomalous behavior that may indicate a compromised account or an insider threat.\\\nThe detection calculates the standard deviation for each host and leverages the 3-sigma statistical rule to identify an unusual number of users. To customize this analytic, users can try different combinations of the `bucket` span time and the calculation of the `upperBound` field. This logic can be used for real time security monitoring as well as threat hunting exercises.\\\nThis detection will only trigger on all user and service accounts that have created/modified/deleted a security group .\\\nThe analytics returned fields allow analysts to investigate the event further by providing fields like source ip and values of the security objects affected.", "tags": {"name": "Cloud Security Groups Modifications by User", "analytic_story": ["Suspicious Cloud User Activities"], "asset_type": "Cloud Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1578.005"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "Unsual number cloud security group modifications detected by user - $user$", "risk_score": 35, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats dc(All_Changes.object) as unique_security_groups values(All_Changes.src) as src values(All_Changes.user_type) as user_type values(All_Changes.object_category) as object_category values(All_Changes.object) as objects values(All_Changes.action) as action  values(All_Changes.user_agent) as user_agent values(All_Changes.command) as command from datamodel=Change WHERE All_Changes.object_category = \"security_group\" (All_Changes.action = modified OR All_Changes.action = deleted OR All_Changes.action = created)  by All_Changes.user  _time span=30m |  `drop_dm_object_name(\"All_Changes\")` | eventstats avg(unique_security_groups) as avg_changes , stdev(unique_security_groups) as std_changes by user | eval upperBound=(avg_changes+std_changes*3) | eval isOutlier=if(unique_security_groups > 2 and unique_security_groups >= upperBound, 1, 0) | where isOutlier=1| `cloud_security_groups_modifications_by_user_filter`", "how_to_implement": "This search requries the Cloud infrastructure logs such as AWS Cloudtrail, GCP Pubsub Message logs, Azure Audit logs to be ingested into an accelerated Change datamodel. It is also recommended that users can try different combinations of the `bucket` span time and outlier conditions to better suit with their environment.", "known_false_positives": "It is possible that legitimate user/admin may modify a number of security groups", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1578/005/"], "datamodel": ["Change"], "macros": [{"name": "cloud_security_groups_modifications_by_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Cloud Security Groups Modifications by User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1578.005/aws_authorize_security_group/aws_authorize_security_group.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1578.005/aws_authorize_security_group/aws_authorize_security_group.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail"}]}]}, {"name": "Detect AWS Console Login by New User", "author": "Rico Valdez, Splunk", "date": "2022-05-10", "version": 3, "id": "bc91a8cd-35e7-4bb2-6140-e756cc46fd71", "description": "This search looks for AWS CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour", "tags": {"name": "Detect AWS Console Login by New User", "analytic_story": ["Suspicious Cloud Authentication Activities", "AWS Identity and Access Management Account Takeover"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1552"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ is logging into the AWS console for the first time", "risk_score": 30, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user | `drop_dm_object_name(Authentication)` | join user type=outer [ | inputlookup previously_seen_users_console_logins | stats min(firstTime) as earliestseen by user] | eval userStatus=if(earliestseen >= relative_time(now(), \"-24h@h\") OR isnull(earliestseen), \"First Time Logging into AWS Console\", \"Previously Seen User\") | where userStatus=\"First Time Logging into AWS Console\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `detect_aws_console_login_by_new_user_filter`", "how_to_implement": "You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines.", "known_false_positives": "When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.", "check_references": false, "references": [], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_aws_console_login_by_new_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Detect AWS Console Login by New User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Detect AWS Console Login by User from New City", "author": "Bhavin Patel, Eric McGinnis Splunk", "date": "2022-08-25", "version": 2, "id": "121b0b11-f8ac-4ed6-a132-3800ca4fc07a", "description": "This search looks for AWS CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour", "tags": {"name": "Detect AWS Console Login by User from New City", "analytic_story": ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities", "AWS Identity and Access Management Account Takeover", "Compromised User Account"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1535"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ is logging into the AWS console from City $City$ for the first time", "risk_score": 18, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | `drop_dm_object_name(Authentication)` | rename City as justSeenCity | table firstTime lastTime user justSeenCity | join user type=outer [| inputlookup previously_seen_users_console_logins | rename City as previouslySeenCity | stats min(firstTime) AS earliestseen by user previouslySeenCity | fields earliestseen user previouslySeenCity] | eval userCity=if(firstTime >= relative_time(now(), \"-24h@h\"), \"New City\",\"Previously Seen City\") | where userCity = \"New City\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime lastTime user previouslySeenCity justSeenCity userCity | `detect_aws_console_login_by_user_from_new_city_filter`", "how_to_implement": "You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in AWS CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in AWS CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_city_filter` macro.", "known_false_positives": "When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.", "check_references": false, "references": [], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_aws_console_login_by_user_from_new_city_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Detect AWS Console Login by User from New City:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Detect AWS Console Login by User from New Country", "author": "Bhavin Patel, Eric McGinnis Splunk", "date": "2022-08-25", "version": 2, "id": "67bd3def-c41c-4bf6-837b-ae196b4257c6", "description": "This search looks for AWS CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour", "tags": {"name": "Detect AWS Console Login by User from New Country", "analytic_story": ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities", "AWS Identity and Access Management Account Takeover", "Compromised User Account"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1535"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ is logging into the AWS console from Country $Country$ for the first time", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | `drop_dm_object_name(Authentication)` | rename Country as justSeenCountry | table firstTime lastTime user justSeenCountry | join user type=outer [| inputlookup previously_seen_users_console_logins | rename Country as previouslySeenCountry | stats min(firstTime) AS earliestseen by user previouslySeenCountry | fields earliestseen user previouslySeenCountry] | eval userCountry=if(firstTime >= relative_time(now(), \"-24h@h\"), \"New Country\",\"Previously Seen Country\") | where userCountry = \"New Country\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime lastTime user previouslySeenCountry justSeenCountry userCountry | `detect_aws_console_login_by_user_from_new_country_filter`", "how_to_implement": "You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in AWS CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in AWS CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_country_filter` macro.", "known_false_positives": "When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.", "check_references": false, "references": [], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_aws_console_login_by_user_from_new_country_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Detect AWS Console Login by User from New Country:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Detect AWS Console Login by User from New Region", "author": "Bhavin Patel, Eric McGinnis Splunk", "date": "2022-08-25", "version": 2, "id": "9f31aa8e-e37c-46bc-bce1-8b3be646d026", "description": "This search looks for AWS CloudTrail events wherein a console login event by a user was recorded within the last hour, then compares the event to a lookup file of previously seen users (by ARN values) who have logged into the console. The alert is fired if the user has logged into the console for the first time within the last hour", "tags": {"name": "Detect AWS Console Login by User from New Region", "analytic_story": ["Suspicious AWS Login Activities", "Suspicious Cloud Authentication Activities", "AWS Identity and Access Management Account Takeover", "Compromised User Account"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1535"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ is logging into the AWS console from Region $Region$ for the first time", "risk_score": 36, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats earliest(_time) as firstTime latest(_time) as lastTime from datamodel=Authentication where Authentication.signature=ConsoleLogin by Authentication.user Authentication.src | iplocation Authentication.src | `drop_dm_object_name(Authentication)` | rename Region as justSeenRegion | table firstTime lastTime user justSeenRegion | join user type=outer [| inputlookup previously_seen_users_console_logins | rename Region as previouslySeenRegion | stats min(firstTime) AS earliestseen by user previouslySeenRegion | fields earliestseen user previouslySeenRegion] | eval userRegion=if(firstTime >= relative_time(now(), \"-24h@h\"), \"New Region\",\"Previously Seen Region\") | where userRegion= \"New Region\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | table firstTime lastTime user previouslySeenRegion justSeenRegion userRegion | `detect_aws_console_login_by_user_from_new_region_filter`", "how_to_implement": "You must install and configure the Splunk Add-on for AWS (version 5.1.0 or later) and Enterprise Security 6.2, which contains the required updates to the Authentication data model for cloud use cases. Run the `Previously Seen Users in AWS CloudTrail - Initial` support search only once to create a baseline of previously seen IAM users within the last 30 days. Run `Previously Seen Users in AWS CloudTrail - Update` hourly (or more frequently depending on how often you run the detection searches) to refresh the baselines. You can also provide additional filtering for this search by customizing the `detect_aws_console_login_by_user_from_new_region_filter` macro.", "known_false_positives": "When a legitimate new user logins for the first time, this activity will be detected. Check how old the account is and verify that the user activity is legitimate.", "check_references": false, "references": [], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_aws_console_login_by_user_from_new_region_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Detect AWS Console Login by User from New Region:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/abnormally_high_cloud_instances_launched/cloudtrail_behavioural_detections.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Detect GCP Storage access from a new IP", "author": "Shannon Davis, Splunk", "date": "2020-08-10", "version": 1, "id": "ccc3246a-daa1-11ea-87d0-0242ac130022", "description": "This search looks at GCP Storage bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed a GCP Storage bucket.", "tags": {"name": "Detect GCP Storage access from a new IP", "analytic_story": ["Suspicious GCP Storage Activities"], "asset_type": "GCP Storage Bucket", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1530"], "nist": ["DE.AE"], "observable": [{"name": "remote_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`google_gcp_pubsub_message` | multikv | rename sc_status_ as status | rename cs_object_ as bucket_name | rename c_ip_ as remote_ip | rename cs_uri_ as request_uri | rename cs_method_ as operation | search status=\"\\\"200\\\"\" | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip operation request_uri | table firstTime, lastTime, bucket_name, remote_ip, operation, request_uri | inputlookup append=t previously_seen_gcp_storage_access_from_remote_ip | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip operation request_uri | outputlookup previously_seen_gcp_storage_access_from_remote_ip | eval newIP=if(firstTime >= relative_time(now(),\"-70m@m\"), 1, 0) | where newIP=1 | eval first_time=strftime(firstTime,\"%m/%d/%y %H:%M:%S\") | eval last_time=strftime(lastTime,\"%m/%d/%y %H:%M:%S\") | table  first_time last_time bucket_name remote_ip operation request_uri | `detect_gcp_storage_access_from_a_new_ip_filter`", "how_to_implement": "This search relies on the Splunk Add-on for Google Cloud Platform, setting up a Cloud Pub/Sub input, along with the relevant GCP PubSub topics and logging sink to capture GCP Storage Bucket events (https://cloud.google.com/logging/docs/routing/overview). In order to capture public GCP Storage Bucket access logs, you must also enable storage bucket logging to your PubSub Topic as per https://cloud.google.com/storage/docs/access-logs.  These logs are deposited into the nominated Storage Bucket on an hourly basis and typically show up by 15 minutes past the hour.  It is recommended to configure any saved searches or correlation searches in Enterprise Security to run on an hourly basis at 30 minutes past the hour (cron definition of 30 * * * *).  A lookup table (previously_seen_gcp_storage_access_from_remote_ip.csv) stores the previously seen access requests, and is used by this search to determine any newly seen IP addresses accessing the Storage Buckets.", "known_false_positives": "GCP Storage buckets can be accessed from any IP (if the ACLs are open to allow it), as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past two hours.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "google_gcp_pubsub_message", "definition": "sourcetype=\"google:gcp:pubsub:message\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "detect_gcp_storage_access_from_a_new_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": []}, {"name": "Detect New Open GCP Storage Buckets", "author": "Shannon Davis, Splunk", "date": "2020-08-05", "version": 1, "id": "f6ea3466-d6bb-11ea-87d0-0242ac130003", "description": "This search looks for GCP PubSub events where a user has created an open/public GCP Storage bucket.", "tags": {"name": "Detect New Open GCP Storage Buckets", "analytic_story": ["Suspicious GCP Storage Activities"], "asset_type": "GCP Storage Bucket", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1530"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`google_gcp_pubsub_message` data.resource.type=gcs_bucket data.protoPayload.methodName=storage.setIamPermissions | spath output=action path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.action | spath output=user path=data.protoPayload.authenticationInfo.principalEmail | spath output=location path=data.protoPayload.resourceLocation.currentLocations{} | spath output=src path=data.protoPayload.requestMetadata.callerIp | spath output=bucketName path=data.protoPayload.resourceName | spath output=role path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.role | spath output=member path=data.protoPayload.serviceData.policyDelta.bindingDeltas{}.member | search (member=allUsers AND action=ADD) | table  _time, bucketName, src, user, location, action, role, member | search `detect_new_open_gcp_storage_buckets_filter`", "how_to_implement": "This search relies on the Splunk Add-on for Google Cloud Platform, setting up a Cloud Pub/Sub input, along with the relevant GCP PubSub topics and logging sink to capture GCP Storage Bucket events (https://cloud.google.com/logging/docs/routing/overview).", "known_false_positives": "While this search has no known false positives, it is possible that a GCP admin has legitimately created a public bucket for a specific purpose. That said, GCP strongly advises against granting full control to the \"allUsers\" group.", "check_references": false, "references": [], "datamodel": ["Email"], "macros": [{"name": "google_gcp_pubsub_message", "definition": "sourcetype=\"google:gcp:pubsub:message\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "detect_new_open_gcp_storage_buckets_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": []}, {"name": "Detect New Open S3 buckets", "author": "Bhavin Patel, Patrick Bareiss, Splunk", "date": "2021-07-19", "version": 3, "id": "2a9b80d3-6340-4345-b5ad-290bf3d0dac4", "description": "This search looks for AWS CloudTrail events where a user has created an open/public S3 bucket.", "tags": {"name": "Detect New Open S3 buckets", "analytic_story": ["Suspicious AWS S3 Activities"], "asset_type": "S3 Bucket", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1530"], "nist": ["DE.CM"], "observable": [{"name": "user_arn", "type": "User", "role": ["Attacker"]}, {"name": "bucketName", "type": "Other", "role": ["Victim"]}], "message": "User $user_arn$ has created an open/public bucket $bucketName$ with the following permissions $permission$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=s3.amazonaws.com eventName=PutBucketAcl | rex field=_raw \"(?<json_field>{.+})\" | spath input=json_field output=grantees path=requestParameters.AccessControlPolicy.AccessControlList.Grant{} | search grantees=* | mvexpand grantees | spath input=grantees output=uri path=Grantee.URI | spath input=grantees output=permission path=Permission | search uri IN (\"http://acs.amazonaws.com/groups/global/AllUsers\",\"http://acs.amazonaws.com/groups/global/AuthenticatedUsers\") | search permission IN (\"READ\",\"READ_ACP\",\"WRITE\",\"WRITE_ACP\",\"FULL_CONTROL\") | rename requestParameters.bucketName AS bucketName | stats count min(_time) as firstTime max(_time) as lastTime by user_arn userIdentity.principalId userAgent uri permission bucketName | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_new_open_s3_buckets_filter` ", "how_to_implement": "You must install the AWS App for Splunk.", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the \"All Users\" group.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_new_open_s3_buckets_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "Detect New Open S3 buckets:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1530/aws_s3_public_bucket/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1530/aws_s3_public_bucket/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Detect New Open S3 Buckets over AWS CLI", "author": "Patrick Bareiss, Splunk", "date": "2021-07-19", "version": 2, "id": "39c61d09-8b30-4154-922b-2d0a694ecc22", "description": "This search looks for AWS CloudTrail events where a user has created an open/public S3 bucket over the aws cli.", "tags": {"name": "Detect New Open S3 Buckets over AWS CLI", "analytic_story": ["Suspicious AWS S3 Activities"], "asset_type": "S3 Bucket", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1530"], "nist": ["DE.CM"], "observable": [{"name": "userIdentity.userName", "type": "User", "role": ["Attacker"]}, {"name": "bucketName", "type": "Other", "role": ["Victim"]}], "message": "User $userIdentity.userName$ has created an open/public bucket $bucketName$ using AWS CLI with the following permissions - $requestParameters.accessControlList.x-amz-grant-read$ $requestParameters.accessControlList.x-amz-grant-read-acp$ $requestParameters.accessControlList.x-amz-grant-write$ $requestParameters.accessControlList.x-amz-grant-write-acp$ $requestParameters.accessControlList.x-amz-grant-full-control$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventSource=\"s3.amazonaws.com\" (userAgent=\"[aws-cli*\" OR userAgent=aws-cli* ) eventName=PutBucketAcl OR requestParameters.accessControlList.x-amz-grant-read-acp IN (\"*AuthenticatedUsers\",\"*AllUsers\") OR requestParameters.accessControlList.x-amz-grant-write IN (\"*AuthenticatedUsers\",\"*AllUsers\") OR requestParameters.accessControlList.x-amz-grant-write-acp IN (\"*AuthenticatedUsers\",\"*AllUsers\") OR requestParameters.accessControlList.x-amz-grant-full-control IN (\"*AuthenticatedUsers\",\"*AllUsers\") | rename requestParameters.bucketName AS bucketName | fillnull | stats count min(_time) as firstTime max(_time) as lastTime by userIdentity.userName userIdentity.principalId userAgent bucketName requestParameters.accessControlList.x-amz-grant-read requestParameters.accessControlList.x-amz-grant-read-acp requestParameters.accessControlList.x-amz-grant-write requestParameters.accessControlList.x-amz-grant-write-acp requestParameters.accessControlList.x-amz-grant-full-control | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | `detect_new_open_s3_buckets_over_aws_cli_filter` ", "how_to_implement": "", "known_false_positives": "While this search has no known false positives, it is possible that an AWS admin has legitimately created a public bucket for a specific purpose. That said, AWS strongly advises against granting full control to the \"All Users\" group.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_new_open_s3_buckets_over_aws_cli_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": [{"name": "Detect New Open S3 Buckets over AWS CLI:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1530/aws_s3_public_bucket/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1530/aws_s3_public_bucket/aws_cloudtrail_events.json", "source": "aws_cloudtrail", "sourcetype": "aws:cloudtrail", "update_timestamp": true}]}]}, {"name": "Detect S3 access from a new IP", "author": "Bhavin Patel, Splunk", "date": "2018-06-28", "version": 1, "id": "e6f1bb1b-f441-492b-9126-902acda217da", "description": "This search looks at S3 bucket-access logs and detects new or previously unseen remote IP addresses that have successfully accessed an S3 bucket.", "tags": {"name": "Detect S3 access from a new IP", "analytic_story": ["Suspicious AWS S3 Activities"], "asset_type": "S3 Bucket", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1530"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_s3_accesslogs` http_status=200  [search `aws_s3_accesslogs` http_status=200 | stats earliest(_time) as firstTime latest(_time) as lastTime by bucket_name remote_ip | inputlookup append=t previously_seen_S3_access_from_remote_ip | stats min(firstTime) as firstTime, max(lastTime) as lastTime by bucket_name remote_ip | outputlookup previously_seen_S3_access_from_remote_ip| eval newIP=if(firstTime >= relative_time(now(), \"-70m@m\"), 1, 0) | where newIP=1 | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)` | table bucket_name remote_ip]| iplocation remote_ip |rename remote_ip as src_ip | table _time bucket_name src_ip City Country operation request_uri | `detect_s3_access_from_a_new_ip_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your S3 access logs' inputs. This search works best when you run the \"Previously Seen S3 Bucket Access by Remote IP\" support search once to create a history of previously seen remote IPs and bucket names.", "known_false_positives": "S3 buckets can be accessed from any IP, as long as it can make a successful connection. This will be a false postive, since the search is looking for a new IP within the past hour", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_s3_accesslogs", "definition": "sourcetype=aws:s3:accesslogs", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "detect_s3_access_from_a_new_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "Detect Spike in AWS Security Hub Alerts for EC2 Instance", "author": "Bhavin Patel, Splunk", "date": "2021-01-26", "version": 3, "id": "2a9b80d3-6340-4345-b5ad-290bf5d0d222", "description": "This search looks for a spike in number of of AWS security Hub alerts for an EC2 instance in 4 hours intervals", "tags": {"name": "Detect Spike in AWS Security Hub Alerts for EC2 Instance", "analytic_story": ["AWS Security Hub Alerts"], "asset_type": "AWS Instance", "cis20": ["CIS 10"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "dest", "type": "Endpoint", "role": ["Victim"]}], "message": "Spike in AWS security Hub alerts with title $Title$ for EC2 instance $dest$", "risk_score": 15, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_securityhub_finding` \"Resources{}.Type\"=AWSEC2Instance | bucket span=4h _time | stats count AS alerts values(Title) as Title values(Types{}) as Types values(vendor_account) as vendor_account values(vendor_region) as vendor_region values(severity) as severity by _time dest | eventstats avg(alerts) as total_alerts_avg, stdev(alerts) as total_alerts_stdev | eval threshold_value = 3 | eval isOutlier=if(alerts > total_alerts_avg+(total_alerts_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time dest alerts Title Types vendor_account vendor_region severity isOutlier total_alerts_avg | `detect_spike_in_aws_security_hub_alerts_for_ec2_instance_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.", "known_false_positives": "None", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_securityhub_finding", "definition": "sourcetype=\"aws:securityhub:finding\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "detect_spike_in_aws_security_hub_alerts_for_ec2_instance_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Detect Spike in AWS Security Hub Alerts for EC2 Instance:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/security_hub_ec2_spike/security_hub_ec2_spike.json", "source": "aws_securityhub_finding", "sourcetype": "aws:securityhub:finding"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/suspicious_behaviour/security_hub_ec2_spike/security_hub_ec2_spike.json", "source": "aws_securityhub_finding", "sourcetype": "aws:securityhub:finding"}]}]}, {"name": "Detect Spike in AWS Security Hub Alerts for User", "author": "Bhavin Patel, Splunk", "date": "2021-01-26", "version": 3, "id": "2a9b80d3-6220-4345-b5ad-290bf5d0d222", "description": "This search looks for a spike in number of of AWS security Hub alerts for an AWS IAM User in 4 hours intervals.", "tags": {"name": "Detect Spike in AWS Security Hub Alerts for User", "analytic_story": ["AWS Security Hub Alerts"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`aws_securityhub_finding` \"findings{}.Resources{}.Type\"= AwsIamUser | rename findings{}.Resources{}.Id as user | bucket span=4h _time | stats count AS alerts by _time user | eventstats avg(alerts) as total_launched_avg, stdev(alerts) as total_launched_stdev | eval threshold_value = 2 | eval isOutlier=if(alerts > total_launched_avg+(total_launched_stdev * threshold_value), 1, 0) | search isOutlier=1 | table _time user alerts |`detect_spike_in_aws_security_hub_alerts_for_user_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your Security Hub inputs. The threshold_value should be tuned to your environment and schedule these searches according to the bucket span interval.", "known_false_positives": "None", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "aws_securityhub_finding", "definition": "sourcetype=\"aws:securityhub:finding\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "detect_spike_in_aws_security_hub_alerts_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "Detect Spike in blocked Outbound Traffic from your AWS", "author": "Bhavin Patel, Splunk", "date": "2018-05-07", "version": 1, "id": "d3fffa37-492f-487b-a35d-c60fcb2acf01", "description": "This search will detect spike in blocked outbound network connections originating from within your AWS environment.  It will also update the cache file that factors in the latest data.", "tags": {"name": "Detect Spike in blocked Outbound Traffic from your AWS", "analytic_story": ["AWS Network ACL Activity", "Suspicious AWS Traffic", "Command And Control"], "asset_type": "AWS Instance", "cis20": ["CIS 13"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "dest", "type": "Hostname", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  [search  `cloudwatchlogs_vpcflow` action=blocked (src_ip=10.0.0.0/8 OR src_ip=172.16.0.0/12 OR src_ip=192.168.0.0/16) ( dest_ip!=10.0.0.0/8 AND dest_ip!=172.16.0.0/12 AND dest_ip!=192.168.0.0/16)  | stats count as numberOfBlockedConnections by src_ip | inputlookup baseline_blocked_outbound_connections append=t | fields - latestCount | stats values(*) as * by src_ip | rename numberOfBlockedConnections as latestCount | eval newAvgBlockedConnections=avgBlockedConnections + (latestCount-avgBlockedConnections)/720 | eval newStdevBlockedConnections=sqrt(((pow(stdevBlockedConnections, 2)*719 + (latestCount-newAvgBlockedConnections)*(latestCount-avgBlockedConnections))/720)) | eval avgBlockedConnections=coalesce(newAvgBlockedConnections, avgBlockedConnections), stdevBlockedConnections=coalesce(newStdevBlockedConnections, stdevBlockedConnections), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table src_ip, latestCount, numDataPoints, avgBlockedConnections, stdevBlockedConnections | outputlookup baseline_blocked_outbound_connections | eval dataPointThreshold = 5, deviationThreshold = 3 | eval isSpike=if((latestCount > avgBlockedConnections+deviationThreshold*stdevBlockedConnections) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | table src_ip] | stats values(dest_ip) as \"Blocked Destination IPs\", values(interface_id) as \"resourceId\" count as numberOfBlockedConnections, dc(dest_ip) as uniqueDestConnections by src_ip | `detect_spike_in_blocked_outbound_traffic_from_your_aws_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your VPC Flow logs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the number of data points required to meet the definition of \"spike.\" The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the \"Baseline of Blocked Outbound Connection\" support search once to create a history of previously seen blocked outbound connections.", "known_false_positives": "The false-positive rate may vary based on the values of`dataPointThreshold` and `deviationThreshold`. Additionally, false positives may result when AWS administrators roll out policies enforcing network blocks, causing sudden increases in the number of blocked outbound connections.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudwatchlogs_vpcflow", "definition": "sourcetype=aws:cloudwatchlogs:vpcflow", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "detect_spike_in_blocked_outbound_traffic_from_your_aws_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": []}, {"name": "Detect Spike in S3 Bucket deletion", "author": "Bhavin Patel, Splunk", "date": "2018-11-27", "version": 1, "id": "e733a326-59d2-446d-b8db-14a17151aa68", "description": "This search detects users creating spikes in API activity related to deletion of S3 buckets in your AWS environment. It will also update the cache file that factors in the latest data.", "tags": {"name": "Detect Spike in S3 Bucket deletion", "analytic_story": ["Suspicious AWS S3 Activities"], "asset_type": "S3 Bucket", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1530"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`cloudtrail` eventName=DeleteBucket [search `cloudtrail` eventName=DeleteBucket | spath output=arn path=userIdentity.arn | stats count as apiCalls by arn | inputlookup s3_deletion_baseline append=t | fields - latestCount | stats values(*) as * by arn | rename apiCalls as latestCount | eval newAvgApiCalls=avgApiCalls + (latestCount-avgApiCalls)/720 | eval newStdevApiCalls=sqrt(((pow(stdevApiCalls, 2)*719 + (latestCount-newAvgApiCalls)*(latestCount-avgApiCalls))/720)) | eval avgApiCalls=coalesce(newAvgApiCalls, avgApiCalls), stdevApiCalls=coalesce(newStdevApiCalls, stdevApiCalls), numDataPoints=if(isnull(latestCount), numDataPoints, numDataPoints+1) | table arn, latestCount, numDataPoints, avgApiCalls, stdevApiCalls | outputlookup s3_deletion_baseline | eval dataPointThreshold = 15, deviationThreshold = 3 | eval isSpike=if((latestCount > avgApiCalls+deviationThreshold*stdevApiCalls) AND numDataPoints > dataPointThreshold, 1, 0) | where isSpike=1 | rename arn as userIdentity.arn | table userIdentity.arn] | spath output=user userIdentity.arn | spath output=bucketName path=requestParameters.bucketName | stats values(bucketName) as bucketName, count as numberOfApiCalls, dc(eventName) as uniqueApisCalled by user | `detect_spike_in_s3_bucket_deletion_filter`", "how_to_implement": "You must install the AWS App for Splunk (version 5.1.0 or later) and Splunk Add-on for AWS (version 4.4.0 or later), then configure your AWS CloudTrail inputs. You can modify `dataPointThreshold` and `deviationThreshold` to better fit your environment. The `dataPointThreshold` variable is the minimum number of data points required to have a statistically significant amount of data to determine. The `deviationThreshold` variable is the number of standard deviations away from the mean that the value must be to be considered a spike. This search works best when you run the \"Baseline of S3 Bucket deletion activity by ARN\" support search once to create a baseline of previously seen S3 bucket-deletion activity.", "known_false_positives": "Based on the values of`dataPointThreshold` and `deviationThreshold`, the false positive rate may vary. Please modify this according the your environment.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "cloudtrail", "definition": "sourcetype=aws:cloudtrail", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "detect_spike_in_s3_bucket_deletion_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Amazon Web Services - Cloudtrail"], "enabled_by_default": false, "test_groups": []}, {"name": "GCP Authentication Failed During MFA Challenge", "author": "Bhavin Patel, Mauricio Velazco, Splunk", "date": "2024-01-04", "version": 2, "id": "345f7e1d-a3fe-4158-abd8-e630f9878323", "description": "The following analytic identifies an authentication attempt event against a Google Cloud Platform tenant that fails during the Multi Factor Authentication challenge. This behavior may represent an adversary trying to authenticate with compromised credentials for an account that has multi-factor authentication enabled. ", "tags": {"name": "GCP Authentication Failed During MFA Challenge", "analytic_story": ["GCP Account Takeover"], "asset_type": "Google Cloud Platform tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1078", "T1078.004", "T1621"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ failed to pass MFA challenge", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `gws_reports_login` event.name=login_failure `gws_login_mfa_methods` | stats count min(_time) as firstTime max(_time) as lastTime by user, src_ip, login_challenge_method | `gcp_authentication_failed_during_mfa_challenge_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Google Workspace from Splunkbase (https://splunkbase.splunk.com/app/5556) which allows Splunk administrators to collect Google Workspace event data in Splunk using Google Workspace APIs. Specifically, this analytic leverages the User log events.", "known_false_positives": "Legitimate users may miss to reply the MFA challenge within the time window or deny it by mistake.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/", "https://attack.mitre.org/techniques/T1078/004/"], "datamodel": [], "macros": [{"name": "gws_login_mfa_methods", "definition": "event.parameters{}.multiValue{} IN (\"backup_code\", \"google_authenticator\", \"google_prompt\", \"idv_any_phone\", \"idv_preregistered_phone\", \"internal_two_factor\", \"knowledge_employee_id\", \"knowledge_preregistered_email\", \"login_location\", \"knowledge_preregistered_phone\", \"offline_otp\", \"security_key\", \"security_key_otp\")", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gws_reports_login", "definition": "sourcetype=gws:reports:login", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gcp_authentication_failed_during_mfa_challenge_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GCP Authentication Failed During MFA Challenge:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/gcp_failed_mfa/gws_login.log", "source": "gws:reports:login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/gcp_failed_mfa/gws_login.log", "source": "gws:reports:login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}]}, {"name": "GCP Detect gcploit framework", "author": "Rod Soto, Splunk", "date": "2020-10-08", "version": 1, "id": "a1c5a85e-a162-410c-a5d9-99ff639e5a52", "description": "This search provides detection of GCPloit exploitation framework. This framework can be used to escalate privileges and move laterally from compromised high privilege accounts.", "tags": {"name": "GCP Detect gcploit framework", "analytic_story": ["GCP Cross Account Activity"], "asset_type": "GCP Account", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`google_gcp_pubsub_message` data.protoPayload.request.function.timeout=539s | table src src_user data.resource.labels.project_id data.protoPayload.request.function.serviceAccountEmail data.protoPayload.authorizationInfo{}.permission data.protoPayload.request.location http_user_agent | `gcp_detect_gcploit_framework_filter`", "how_to_implement": "You must install splunk GCP add-on. This search works with gcp:pubsub:message logs", "known_false_positives": "Payload.request.function.timeout value can possibly be match with other functions or requests however the source user and target request account may indicate an attempt to move laterally accross acounts or projects", "check_references": false, "references": ["https://github.com/dxa4481/gcploit", "https://www.youtube.com/watch?v=Ml09R38jpok"], "datamodel": ["Email"], "macros": [{"name": "google_gcp_pubsub_message", "definition": "sourcetype=\"google:gcp:pubsub:message\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gcp_detect_gcploit_framework_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": []}, {"name": "GCP Kubernetes cluster pod scan detection", "author": "Rod Soto, Splunk", "date": "2020-07-17", "version": 1, "id": "19b53215-4a16-405b-8087-9e6acf619842", "description": "This search provides information of unauthenticated requests via user agent, and authentication data against Kubernetes cluster's pods", "tags": {"name": "GCP Kubernetes cluster pod scan detection", "analytic_story": ["Kubernetes Scanning Activity"], "asset_type": "GCP Kubernetes cluster", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`google_gcp_pubsub_message` category=kube-audit |spath input=properties.log |search responseStatus.code=401 |table sourceIPs{} userAgent verb requestURI responseStatus.reason properties.pod | `gcp_kubernetes_cluster_pod_scan_detection_filter`", "how_to_implement": "You must install the GCP App for Splunk (version 2.0.0 or later), then configure stackdriver and set a Pub/Sub subscription to be imported to Splunk.", "known_false_positives": "Not all unauthenticated requests are malicious, but frequency, User Agent, source IPs and pods  will provide context.", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "google_gcp_pubsub_message", "definition": "sourcetype=\"google:gcp:pubsub:message\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gcp_kubernetes_cluster_pod_scan_detection_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": []}, {"name": "GCP Multi-Factor Authentication Disabled", "author": "Bhavin Patel, Mauricio Velazco, Splunk", "date": "2024-01-04", "version": 2, "id": "b9bc5513-6fc1-4821-85a3-e1d81e451c83", "description": "The following analytic identifies an attempt to disable multi-factor authentication for a GCP user. An adversary who has obtained access to an GCP tenant may disable multi-factor authentication as a way to plant a backdoor and maintain persistence using a valid account. This way the attackers can keep persistance in the environment without adding new users.", "tags": {"name": "GCP Multi-Factor Authentication Disabled", "analytic_story": ["GCP Account Takeover"], "asset_type": "GCP", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1556", "T1556.006"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "actor.email", "type": "User", "role": ["Attacker"]}], "message": "MFA disabled for User $user$ initiated by $actor.email$", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gws_reports_admin` command=UNENROLL_USER_FROM_STRONG_AUTH | stats count min(_time) as firstTime max(_time) as lastTime by user, command, actor.email, status, id.applicationName, event.name, vendor_account, action | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `gcp_multi_factor_authentication_disabled_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Google Workspace from Splunkbase (https://splunkbase.splunk.com/app/5556) which allows Splunk administrators to collect Google Workspace event data in Splunk using Google Workspace APIs. Specifically, this analytic leverages the Admin log events.", "known_false_positives": "Legitimate use case may require for users to disable MFA. Filter as needed.", "check_references": false, "references": ["https://support.google.com/cloudidentity/answer/2537800?hl=en", "https://attack.mitre.org/tactics/TA0005/", "https://attack.mitre.org/techniques/T1556/"], "datamodel": [], "macros": [{"name": "gws_reports_admin", "definition": "sourcetype=gws:reports:admin", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gcp_multi_factor_authentication_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GCP Multi-Factor Authentication Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/gcp_disable_mfa/gws_admin.log", "source": "gws:reports:admin", "sourcetype": "gws:reports:admin", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/gcp_disable_mfa/gws_admin.log", "source": "gws:reports:admin", "sourcetype": "gws:reports:admin", "update_timestamp": true}]}]}, {"name": "GCP Multiple Failed MFA Requests For User", "author": "Mauricio Velazco, Splunk", "date": "2022-10-14", "version": 1, "id": "cbb3cb84-c06f-4393-adcc-5cb6195621f1", "description": "The following analytic identifies multiple failed multi-factor authentication requests for a single user within a Google Cloud Platform tenant. Specifically, the analytic triggers when 10 or more MFA user prompts fail within 5 minutes. Google CLoud tenants can be very different depending on the organization, Security teams should test this detection and customize these arbitrary thresholds. The detected behavior may represent an adversary who has obtained legitimate credentials for a user and continuously repeats login attempts in order to bombard users with MFA push notifications, SMS messages, and phone calls potentially resulting in the user finally accepting the authentication request. Threat actors like the Lapsus team and APT29 have leveraged this technique to bypass multi-factor authentication controls as reported by Mandiant and others.", "tags": {"name": "GCP Multiple Failed MFA Requests For User", "analytic_story": ["GCP Account Takeover"], "asset_type": "Google Cloud Platform tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1621", "T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Multiple Failed MFA requests for user $user$", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`gws_reports_login` event.name=login_failure `gws_login_mfa_methods` | bucket span=5m _time | stats dc(_raw) AS mfa_prompts values(user) AS user by src_ip, login_challenge_method,  _time | where mfa_prompts >= 10 | `gcp_multiple_failed_mfa_requests_for_user_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Google Workspace from Splunkbase (https://splunkbase.splunk.com/app/5556) which allows Splunk administrators to collect Google Workspace event data in Splunk using Google Workspace APIs. We would also recommend tuning the detection by adjusting the window `span` and `mfa_prompts` threshold values according to your environment. Specifically, this analytic leverages the User log events.", "known_false_positives": "Multiple Failed MFA requests may also be a sign of authentication or application issues. Filter as needed.", "check_references": false, "references": ["https://www.mandiant.com/resources/blog/russian-targeting-gov-business", "https://arstechnica.com/information-technology/2022/03/lapsus-and-solar-winds-hackers-both-use-the-same-old-trick-to-bypass-mfa/", "https://therecord.media/russian-hackers-bypass-2fa-by-annoying-victims-with-repeated-push-notifications/", "https://attack.mitre.org/techniques/T1621/", "https://attack.mitre.org/techniques/T1078/004/"], "datamodel": [], "macros": [{"name": "gws_login_mfa_methods", "definition": "event.parameters{}.multiValue{} IN (\"backup_code\", \"google_authenticator\", \"google_prompt\", \"idv_any_phone\", \"idv_preregistered_phone\", \"internal_two_factor\", \"knowledge_employee_id\", \"knowledge_preregistered_email\", \"login_location\", \"knowledge_preregistered_phone\", \"offline_otp\", \"security_key\", \"security_key_otp\")", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gws_reports_login", "definition": "sourcetype=gws:reports:login", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gcp_multiple_failed_mfa_requests_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GCP Multiple Failed MFA Requests For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/multiple_failed_mfa_gws/gws_login.log", "source": "gws:reports:login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/multiple_failed_mfa_gws/gws_login.log", "source": "gws:reports:login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}]}, {"name": "GCP Multiple Users Failing To Authenticate From Ip", "author": "Bhavin Patel, Splunk", "date": "2022-10-12", "version": 1, "id": "da20828e-d6fb-4ee5-afb7-d0ac200923d5", "description": "The following analytic identifies one source Ip failing to authenticate into the Google Workspace user accounts with more than 20 unique valid users within 5 minutes. These user accounts may have other privileges with respect to access to other sensitive resources in the Google Cloud Platform. This behavior could represent an adversary performing a Password Spraying attack against an Google Workspace environment to obtain initial access or elevate privileges.", "tags": {"name": "GCP Multiple Users Failing To Authenticate From Ip", "analytic_story": ["GCP Account Takeover"], "asset_type": "Google Cloud Platform tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "tried_accounts", "type": "User", "role": ["Victim"]}], "message": "Multiple failed login attempts against users $tried_accounts$ seen from $src$", "risk_score": 54, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`gws_reports_login` event.type = login event.name = login_failure | bucket span=5m _time | stats count dc(user) AS unique_accounts values(user) as tried_accounts values(authentication_method) AS authentication_method earliest(_time) as firstTime latest(_time) as lastTime by _time event.name src app id.applicationName | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` |  where unique_accounts > 20 | `gcp_multiple_users_failing_to_authenticate_from_ip_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Google Workspace from Splunkbase (https://splunkbase.splunk.com/app/5556) which allows Splunk administrators to collect Google Workspace event data in Splunk using Google Workspace APIs. We would also recommend tuning the detection by adjusting the window `span` and `unique_accounts` threshold values according to your environment. Specifically, this analytic leverages the User log events.", "known_false_positives": "No known false postives for this detection. Please review this alert.", "check_references": false, "references": ["https://cloud.google.com/blog/products/identity-security/how-google-cloud-can-help-stop-credential-stuffing-attacks", "https://www.slideshare.net/dafthack/ok-google-how-do-i-red-team-gsuite", "https://attack.mitre.org/techniques/T1110/003/", "https://www.blackhillsinfosec.com/wp-content/uploads/2020/05/Breaching-the-Cloud-Perimeter-Slides.pdf"], "datamodel": [], "macros": [{"name": "gws_reports_login", "definition": "sourcetype=gws:reports:login", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gcp_multiple_users_failing_to_authenticate_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GCP Multiple Users Failing To Authenticate From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/gcp_gws_multiple_login_failure/gws_login.json", "source": "gws_login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/gcp_gws_multiple_login_failure/gws_login.json", "source": "gws_login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}]}, {"name": "GCP Successful Single-Factor Authentication", "author": "Bhavin Patel, Mauricio Velazco, Splunk", "date": "2024-01-04", "version": 2, "id": "40e17d88-87da-414e-b253-8dc1e4f9555b", "description": "The following analytic identifies a successful authentication event against Google Cloud Platform for an account without Multi-Factor Authentication enabled. This could be evidence of a missconfiguration, a policy violation or an account take over attempt that should be investigated", "tags": {"name": "GCP Successful Single-Factor Authentication", "analytic_story": ["GCP Account Takeover"], "asset_type": "Google Cloud Platform tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1078", "T1078.004"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Successful authentication for user $user$ without MFA", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gws_reports_login` event.name=login_success NOT `gws_login_mfa_methods` | stats count min(_time) as firstTime max(_time) as lastTime by user, src_ip,  login_challenge_method, app, event.name, vendor_account, action |`security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`| `gcp_successful_single_factor_authentication_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Google Workspace from Splunkbase (https://splunkbase.splunk.com/app/5556) which allows Splunk administrators to collect Google Workspace event data in Splunk using Google Workspace APIs. Specifically, this analytic leverages the User log events.", "known_false_positives": "Although not recommended, certain users may be required without multi-factor authentication. Filter as needed", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1078/004/", "https://support.google.com/a/answer/175197?hl=en", "https://www.forbes.com/sites/daveywinder/2020/07/08/new-dark-web-audit-reveals-15-billion-stolen-logins-from-100000-breaches-passwords-hackers-cybercrime/?sh=69927b2a180f"], "datamodel": [], "macros": [{"name": "gws_login_mfa_methods", "definition": "event.parameters{}.multiValue{} IN (\"backup_code\", \"google_authenticator\", \"google_prompt\", \"idv_any_phone\", \"idv_preregistered_phone\", \"internal_two_factor\", \"knowledge_employee_id\", \"knowledge_preregistered_email\", \"login_location\", \"knowledge_preregistered_phone\", \"offline_otp\", \"security_key\", \"security_key_otp\")", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gws_reports_login", "definition": "sourcetype=gws:reports:login", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gcp_successful_single_factor_authentication_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GCP Successful Single-Factor Authentication:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/gcp_single_factor_auth/gws_login.log", "source": "gws:reports:login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078.004/gcp_single_factor_auth/gws_login.log", "source": "gws:reports:login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}]}, {"name": "GCP Unusual Number of Failed Authentications From Ip", "author": "Bhavin Patel, Splunk", "date": "2022-10-13", "version": 1, "id": "bd8097ed-958a-4873-87d9-44f2b4d85705", "description": "The following analytic identifies one source IP failing to authenticate into the Google Workspace with multiple valid users. This behavior could represent an adversary performing a Password Spraying attack against a Google Workspace enviroment to obtain initial access or elevate privileges. The detection calculates the standard deviation for source IP and leverages the 3-sigma statistical rule to identify an unusual number of failed authentication attempts. To customize this analytic, users can try different combinations of the bucket span time and the calculation of the upperBound field. This logic can be used for real time security monitoring as well as threat hunting exercises.  While looking for anomalies using statistical methods like the standard deviation can have benefits, we also recommend using threshold-based detections to complement coverage. A similar analytic following the threshold model is `GCP Multiple Users Failing To Authenticate From Ip`", "tags": {"name": "GCP Unusual Number of Failed Authentications From Ip", "analytic_story": ["GCP Account Takeover"], "asset_type": "Google Cloud Platform tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "src", "type": "IP Address", "role": ["Attacker"]}, {"name": "tried_accounts", "type": "User", "role": ["Victim"]}], "message": "Unusual number of failed console login attempts against users $tried_accounts$ seen from $src$", "risk_score": 54, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`gws_reports_login` event.type = login event.name = login_failure| bucket span=5m _time | stats  dc(user_name) AS unique_accounts values(user_name) as tried_accounts values(authentication_method) AS authentication_method by _time, src | eventstats  avg(unique_accounts) as ip_avg , stdev(unique_accounts) as ip_std by _time | eval  upperBound=(ip_avg+ip_std*3) | eval  isOutlier=if(unique_accounts > 10 and unique_accounts >= upperBound, 1, 0) | where isOutlier =1| `gcp_unusual_number_of_failed_authentications_from_ip_filter`", "how_to_implement": "You must install the latest version of Splunk Add-on for Google Workspace from Splunkbase (https://splunkbase.splunk.com/app/5556) which allows Splunk administrators to collect Google Workspace event data in Splunk using Google Workspace APIs. We would also recommend tuning the detection by adjusting the window `span` and `unique_accounts` threshold values according to your environment. Specifically, this analytic leverages the User log events.", "known_false_positives": "No known false positives for this detection. Please review this alert", "check_references": false, "references": ["https://cloud.google.com/blog/products/identity-security/how-google-cloud-can-help-stop-credential-stuffing-attacks", "https://www.slideshare.net/dafthack/ok-google-how-do-i-red-team-gsuite", "https://attack.mitre.org/techniques/T1110/003/", "https://www.blackhillsinfosec.com/wp-content/uploads/2020/05/Breaching-the-Cloud-Perimeter-Slides.pdf"], "datamodel": [], "macros": [{"name": "gws_reports_login", "definition": "sourcetype=gws:reports:login", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gcp_unusual_number_of_failed_authentications_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GCP Unusual Number of Failed Authentications From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/gcp_gws_multiple_login_failure/gws_login.json", "source": "gws_login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/gcp_gws_multiple_login_failure/gws_login.json", "source": "gws_login", "sourcetype": "gws:reports:login", "update_timestamp": true}]}]}, {"name": "Gdrive suspicious file sharing", "author": "Rod Soto, Teoderick Contreras", "date": "2021-10-24", "version": 1, "id": "a7131dae-34e3-11ec-a2de-acde48001122", "description": "This search can help the detection of compromised accounts or internal users sharing potentially malicious/classified documents with users outside your organization via GSuite file sharing .", "tags": {"name": "Gdrive suspicious file sharing", "analytic_story": ["Spearphishing Attachments", "Data Exfiltration"], "asset_type": "GDrive", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1566"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_drive` name=change_user_access | rename parameters.* as * | search email = \"*@yourdomain.com\" target_user != \"*@yourdomain.com\" | stats count values(owner) as owner values(target_user) as target values(doc_type) as doc_type values(doc_title) as doc_title dc(target_user) as distinct_target by src_ip email | where distinct_target > 50 | `gdrive_suspicious_file_sharing_filter`", "how_to_implement": "Need to implement Gsuite logging targeting Google suite drive activity. In order for the search to work for your environment please update `yourdomain.com` value in the query with the domain relavant for your organization.", "known_false_positives": "This is an anomaly search, you must specify your domain in the parameters so it either filters outside domains or focus on internal domains. This search may also help investigate compromise of accounts. By looking at for example source ip addresses, document titles and abnormal number of shares and shared target users.", "check_references": false, "references": ["https://www.splunk.com/en_us/blog/security/investigating-gsuite-phishing-attacks-with-splunk.html"], "datamodel": [], "macros": [{"name": "gsuite_drive", "definition": "sourcetype=gsuite:drive:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gdrive_suspicious_file_sharing_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": []}, {"name": "GitHub Actions Disable Security Workflow", "author": "Patrick Bareiss, Splunk", "date": "2022-04-04", "version": 1, "id": "0459f1a5-c0ac-4987-82d6-65081209f854", "description": "This search detects a disabled security workflow in GitHub Actions. An attacker can disable a security workflow in GitHub actions to hide malicious code in it.", "tags": {"name": "GitHub Actions Disable Security Workflow", "analytic_story": ["Dev Sec Ops"], "asset_type": "GitHub", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1195.002", "T1195"], "nist": ["DE.AE"], "observable": [{"name": "repository", "type": "Unknown", "role": ["Victim"]}], "message": "Security Workflow is disabled in branch $branch$ for repository $repository$", "risk_score": 27, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`github` workflow_run.event=push OR workflow_run.event=pull_request | stats values(workflow_run.name) as workflow_run.name by workflow_run.head_commit.id workflow_run.event workflow_run.head_branch workflow_run.head_commit.author.email workflow_run.head_commit.author.name workflow_run.head_commit.message workflow_run.head_commit.timestamp workflow_run.head_repository.full_name workflow_run.head_repository.owner.id workflow_run.head_repository.owner.login workflow_run.head_repository.owner.type | rename workflow_run.head_commit.author.name as user, workflow_run.head_commit.author.email as user_email, workflow_run.head_repository.full_name as repository, workflow_run.head_branch as branch | search NOT workflow_run.name=*security-testing* | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `github_actions_disable_security_workflow_filter`", "how_to_implement": "You must index GitHub logs. You can follow the url in reference to onboard GitHub logs. Sometimes GitHub logs are truncated, make sure to disable it in props.conf. Replace *security-testing* with the name of your security testing workflow in GitHub Actions.", "known_false_positives": "unknown", "check_references": false, "references": ["https://www.splunk.com/en_us/blog/tips-and-tricks/getting-github-data-with-webhooks.html"], "datamodel": [], "macros": [{"name": "github", "definition": "sourcetype=aws:firehose:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "github_actions_disable_security_workflow_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "GitHub Actions Disable Security Workflow:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1195.002/github_actions_disable_security_workflow/github_actions_disable_security_workflow.log", "source": "github", "sourcetype": "aws:firehose:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1195.002/github_actions_disable_security_workflow/github_actions_disable_security_workflow.log", "source": "github", "sourcetype": "aws:firehose:json"}]}]}, {"name": "Github Commit Changes In Master", "author": "Teoderick Contreras, Splunk", "date": "2021-08-20", "version": 1, "id": "c9d2bfe2-019f-11ec-a8eb-acde48001122", "description": "This search is to detect a pushed or commit to master or main branch. This is to avoid unwanted modification to master without a review to the changes. Ideally in terms of devsecops the changes made in a branch and do a PR for review. of course in some cases admin of the project may did a changes directly to master branch", "tags": {"name": "Github Commit Changes In Master", "analytic_story": ["Dev Sec Ops"], "asset_type": "GitHub", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1199"], "nist": ["DE.AE"], "observable": [{"name": "commit.commit.author.email", "type": "User", "role": ["Attacker"]}], "message": "suspicious commit by $commit.commit.author.email$ to main branch", "risk_score": 9, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`github` branches{}.name = main OR branches{}.name = master |  stats count min(_time) as firstTime max(_time) as lastTime by commit.commit.author.email commit.author.login commit.commit.message repository.pushed_at commit.commit.committer.date repository.full_name | rename commit.author.login as user, repository.full_name as repository | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `github_commit_changes_in_master_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to github logs having the fork, commit, push metadata that can be use to monitor the changes in a github project.", "known_false_positives": "admin can do changes directly to master branch", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops"], "datamodel": [], "macros": [{"name": "github", "definition": "sourcetype=aws:firehose:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "github_commit_changes_in_master_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Github Commit Changes In Master:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1199/github_push_master/github_push_master.log", "source": "github", "sourcetype": "aws:firehose:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1199/github_push_master/github_push_master.log", "source": "github", "sourcetype": "aws:firehose:json"}]}]}, {"name": "Github Commit In Develop", "author": "Teoderick Contreras, Splunk", "date": "2021-09-01", "version": 1, "id": "f3030cb6-0b02-11ec-8f22-acde48001122", "description": "This search is to detect a pushed or commit to develop branch. This is to avoid unwanted modification to develop without a review to the changes. Ideally in terms of devsecops the changes made in a branch and do a PR for review. of course in some cases admin of the project may did a changes directly to master branch", "tags": {"name": "Github Commit In Develop", "analytic_story": ["Dev Sec Ops"], "asset_type": "GitHub", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1199"], "nist": ["DE.AE"], "observable": [{"name": "commit.commit.author.email", "type": "User", "role": ["Attacker"]}], "message": "suspicious commit by $commit.commit.author.email$ to develop branch", "risk_score": 9, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`github` branches{}.name = main OR branches{}.name = develop |  stats count min(_time) as firstTime max(_time) as lastTime  by commit.author.html_url commit.commit.author.email commit.author.login commit.commit.message repository.pushed_at commit.commit.committer.date | eval phase=\"code\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `github_commit_in_develop_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to github logs having the fork, commit, push metadata that can be use to monitor the changes in a github project.", "known_false_positives": "admin can do changes directly to develop branch", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops"], "datamodel": [], "macros": [{"name": "github", "definition": "sourcetype=aws:firehose:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "github_commit_in_develop_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "Github Commit In Develop:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1199/github_push_master/github_push_develop.json", "source": "github", "sourcetype": "aws:firehose:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1199/github_push_master/github_push_develop.json", "source": "github", "sourcetype": "aws:firehose:json"}]}]}, {"name": "GitHub Dependabot Alert", "author": "Patrick Bareiss, Splunk", "date": "2021-09-01", "version": 1, "id": "05032b04-4469-4034-9df7-05f607d75cba", "description": "The following analytic is made by first searching for logs that contain the action \"create\" and renames certain fields for easier analysis. Then, this analytic uses the \"stats\" command to calculate the first and last occurrence of the alert based on the timestamp. The fields included in the output are the action, affected package name, affected range, created date, external identifier, external reference, fixed version, severity, repository, repository URL, and user. The \"phase\" field is set to \"code\" to indicate that the alert pertains to code-related issues. The detection is important because dependabot Alerts can indicate vulnerabilities in the codebase that can be exploited by attackers. Detecting and investigating these alerts can help a SOC to proactively address security risks and prevent potential breaches or unauthorized access to sensitive information. False positives might occur since there are legitimate actions that trigger the \"create\" action or if other factors exist that can generate similar log entries. Next steps include reviewing the details of the alert, such as the affected package, severity, and fixed version to determine the appropriate response and mitigation steps.", "tags": {"name": "GitHub Dependabot Alert", "analytic_story": ["Dev Sec Ops"], "asset_type": "GitHub", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1195.001", "T1195"], "nist": ["DE.AE"], "observable": [{"name": "repository", "type": "Unknown", "role": ["Victim"]}], "message": "Vulnerabilities found in packages used by GitHub repository $repository$", "risk_score": 27, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`github` alert.id=* action=create | rename repository.full_name as repository, repository.html_url as repository_url sender.login as user | stats min(_time) as firstTime max(_time) as lastTime by action alert.affected_package_name alert.affected_range alert.created_at alert.external_identifier alert.external_reference alert.fixed_in alert.severity repository repository_url user | eval phase=\"code\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `github_dependabot_alert_filter`", "how_to_implement": "You must index GitHub logs. You can follow the url in reference to onboard GitHub logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://www.splunk.com/en_us/blog/tips-and-tricks/getting-github-data-with-webhooks.html"], "datamodel": [], "macros": [{"name": "github", "definition": "sourcetype=aws:firehose:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "github_dependabot_alert_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "GitHub Dependabot Alert:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1195.001/github_security_advisor_alert/github_security_advisor_alert.json", "source": "github", "sourcetype": "aws:firehose:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1195.001/github_security_advisor_alert/github_security_advisor_alert.json", "source": "github", "sourcetype": "aws:firehose:json"}]}]}, {"name": "GitHub Pull Request from Unknown User", "author": "Patrick Bareiss, Splunk", "date": "2021-09-01", "version": 1, "id": "9d7b9100-8878-4404-914e-ca5e551a641e", "description": "The following analytic detects pull requests from unknown users on GitHub. The detection is made by using a Splunk query to search for pull requests in the `check_suite.pull_requests` field where the `id` is not specified. Next, the analytic retrieves information such as the author's name, the repository's full name, the head reference of the pull request, and the commit message from the `check_suite.head_commit` field. The analytic also includes a step to exclude known users by using the `github_known_users` lookup table, which helps to filter out pull requests from known users and focus on the pull requests from unknown users. The detection is important because it locates potential malicious activity or unauthorized access since unknown users can introduce malicious code or gain unauthorized access to repositories leading to unauthorized code changes, data breaches, or other security incidents. Next steps include reviewing the author's name, the repository involved, the head reference of the pull request, and the commit message upon triage of a potential pull request from an unknown user. You must also analyze any relevant on-disk artifacts and investigate any concurrent processes to determine the source and intent of the pull request.\"", "tags": {"name": "GitHub Pull Request from Unknown User", "analytic_story": ["Dev Sec Ops"], "asset_type": "GitHub", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1195.001", "T1195"], "nist": ["DE.AE"], "observable": [{"name": "repository", "type": "Unknown", "role": ["Victim"]}], "message": "Vulnerabilities found in packages used by GitHub repository $repository$", "risk_score": 27, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`github` check_suite.pull_requests{}.id=* | stats count by check_suite.head_commit.author.name repository.full_name check_suite.pull_requests{}.head.ref check_suite.head_commit.message | rename check_suite.head_commit.author.name as user repository.full_name as repository check_suite.pull_requests{}.head.ref as ref_head check_suite.head_commit.message as commit_message | search NOT `github_known_users` | eval phase=\"code\" | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `github_pull_request_from_unknown_user_filter`", "how_to_implement": "You must index GitHub logs. You can follow the url in reference to onboard GitHub logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://www.splunk.com/en_us/blog/tips-and-tricks/getting-github-data-with-webhooks.html"], "datamodel": [], "macros": [{"name": "github", "definition": "sourcetype=aws:firehose:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "github_known_users", "definition": "user IN (user_names_here)", "description": "specify the user allowed to create PRs in Github projects."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "github_pull_request_from_unknown_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "enabled_by_default": false, "test_groups": [{"name": "GitHub Pull Request from Unknown User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1195.001/github_pull_request/github_pull_request.json", "source": "github", "sourcetype": "aws:firehose:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1195.001/github_pull_request/github_pull_request.json", "source": "github", "sourcetype": "aws:firehose:json"}]}]}, {"name": "Gsuite Drive Share In External Email", "author": "Teoderick Contreras, Splunk", "date": "2021-08-16", "version": 1, "id": "f6ee02d6-fea0-11eb-b2c2-acde48001122", "description": "This search is to detect suspicious google drive or google docs files shared outside or externally. This behavior might be a good hunting query to monitor exfitration of data made by an attacker or insider to a targetted machine.", "tags": {"name": "Gsuite Drive Share In External Email", "analytic_story": ["Dev Sec Ops", "Insider Threat"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1567.002", "T1567"], "nist": ["DE.AE"], "observable": [{"name": "parameters.owner", "type": "User", "role": ["Attacker"]}, {"name": "email", "type": "User", "role": ["Victim"]}], "message": "suspicious share gdrive from $parameters.owner$ to $email$ namely as $parameters.doc_title$", "risk_score": 72, "security_domain": "endpoint", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`gsuite_drive` NOT (email IN(\"\", \"null\")) | rex field=parameters.owner \"[^@]+@(?<src_domain>[^@]+)\" | rex field=email \"[^@]+@(?<dest_domain>[^@]+)\" | where src_domain = \"internal_test_email.com\" and not dest_domain = \"internal_test_email.com\" | eval phase=\"plan\" | eval severity=\"low\" | stats values(parameters.doc_title) as doc_title, values(parameters.doc_type) as doc_types, values(email) as dst_email_list, values(parameters.visibility) as visibility, values(parameters.doc_id) as doc_id, count min(_time) as firstTime max(_time) as lastTime by parameters.owner ip_address phase severity  | rename parameters.owner as user ip_address as src_ip | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `gsuite_drive_share_in_external_email_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to gsuite having the file attachment metadata like file type, file extension, source email, destination email, num of attachment and etc. In order for the search to work for your environment, please edit the query to use your company specific email domain instead of `internal_test_email.com`.", "known_false_positives": "network admin or normal user may share files to customer and external team.", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops"], "datamodel": [], "macros": [{"name": "gsuite_drive", "definition": "sourcetype=gsuite:drive:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gsuite_drive_share_in_external_email_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "Gsuite Drive Share In External Email:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1567.002/gsuite_share_drive/gdrive_share_external.log", "source": "http:gsuite", "sourcetype": "gsuite:drive:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1567.002/gsuite_share_drive/gdrive_share_external.log", "source": "http:gsuite", "sourcetype": "gsuite:drive:json"}]}]}, {"name": "GSuite Email Suspicious Attachment", "author": "Teoderick Contreras, Splunk", "date": "2021-08-16", "version": 1, "id": "6d663014-fe92-11eb-ab07-acde48001122", "description": "This search is to detect a suspicious attachment file extension in Gsuite email that may related to spear phishing attack. This file type is commonly used by malware to lure user to click on it to execute malicious code to compromised targetted machine. But this search can also catch some normal files related to this file type that maybe send by employee or network admin.", "tags": {"name": "GSuite Email Suspicious Attachment", "analytic_story": ["Dev Sec Ops"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1566.001", "T1566"], "nist": ["DE.AE"], "observable": [{"name": "source.address", "type": "User", "role": ["Attacker"]}, {"name": "destination{}.address", "type": "User", "role": ["Victim"]}], "message": "suspicious email from $source.address$ to $destination{}.address$", "risk_score": 49, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_gmail` \"attachment{}.file_extension_type\" IN (\"pl\", \"py\", \"rb\", \"sh\", \"bat\", \"exe\", \"dll\", \"cpl\", \"com\", \"js\", \"vbs\", \"ps1\", \"reg\",\"swf\", \"cmd\", \"go\") | eval phase=\"plan\" | eval severity=\"medium\" | stats count min(_time) as firstTime max(_time) as lastTime values(attachment{}.file_extension_type) as email_attachments, values(attachment{}.sha256) as attachment_sha256, values(payload_size) as payload_size by destination{}.service num_message_attachments  subject destination{}.address source.address phase severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `gsuite_email_suspicious_attachment_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to gsuite having the file attachment metadata like file type, file extension, source email, destination email, num of attachment and etc.", "known_false_positives": "network admin and normal user may send this file attachment as part of their day to day work. having a good protocol in attaching this file type to an e-mail may reduce the risk of having a spear phishing attack.", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops"], "datamodel": [], "macros": [{"name": "gsuite_gmail", "definition": "sourcetype=gsuite:gmail:bigquery", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gsuite_email_suspicious_attachment_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "GSuite Email Suspicious Attachment:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_susp_attachment_ext/gsuite_gmail_file_ext.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_susp_attachment_ext/gsuite_gmail_file_ext.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}]}, {"name": "Gsuite Email Suspicious Subject With Attachment", "author": "Teoderick Contreras, Splunk", "date": "2021-08-19", "version": 1, "id": "8ef3971e-00f2-11ec-b54f-acde48001122", "description": "This search is to detect a gsuite email contains suspicious subject having known file type used in spear phishing. This technique is a common and effective entry vector of attacker to compromise a network by luring the user to click or execute the suspicious attachment send from external email account because of the effective social engineering of subject related to delivery, bank and so on. On the other hand this detection may catch a normal email traffic related to legitimate transaction so better to check the email sender, spelling and etc. avoid click link or opening the attachment if you are not expecting this type of e-mail.", "tags": {"name": "Gsuite Email Suspicious Subject With Attachment", "analytic_story": ["Dev Sec Ops"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1566.001", "T1566"], "nist": ["DE.AE"], "observable": [{"name": "source.address", "type": "User", "role": ["Attacker"]}], "message": "suspicious email from $source.address$ to $destination{}.address$", "risk_score": 25, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_gmail` num_message_attachments > 0 subject IN (\"*dhl*\", \"* ups *\", \"*delivery*\", \"*parcel*\", \"*label*\", \"*invoice*\", \"*postal*\", \"* fedex *\", \"* usps *\", \"* express *\", \"*shipment*\", \"*Banking/Tax*\",\"*shipment*\", \"*new order*\") attachment{}.file_extension_type IN (\"doc\", \"docx\", \"xls\", \"xlsx\", \"ppt\", \"pptx\", \"pdf\", \"zip\", \"rar\", \"html\",\"htm\",\"hta\") | rex field=source.from_header_address \"[^@]+@(?<source_domain>[^@]+)\" | rex field=destination{}.address \"[^@]+@(?<dest_domain>[^@]+)\" | where not source_domain=\"internal_test_email.com\" and dest_domain=\"internal_test_email.com\" | eval phase=\"plan\" | eval severity=\"medium\" | stats count min(_time) as firstTime max(_time) as lastTime values(attachment{}.file_extension_type) as email_attachments, values(attachment{}.sha256) as attachment_sha256, values(payload_size) as payload_size by destination{}.service num_message_attachments  subject destination{}.address source.address phase severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `gsuite_email_suspicious_subject_with_attachment_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to gsuite having the file attachment metadata like file type, file extension, source email, destination email, num of attachment and etc.", "known_false_positives": "normal user or normal transaction may contain the subject and file type attachment that this detection try to search.", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops", "https://www.mandiant.com/resources/top-words-used-in-spear-phishing-attacks"], "datamodel": [], "macros": [{"name": "gsuite_gmail", "definition": "sourcetype=gsuite:gmail:bigquery", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gsuite_email_suspicious_subject_with_attachment_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "Gsuite Email Suspicious Subject With Attachment:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_susp_subj/gsuite_susp_subj_attach.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_susp_subj/gsuite_susp_subj_attach.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}]}, {"name": "Gsuite Email With Known Abuse Web Service Link", "author": "Teoderick Contreras, Splunk", "date": "2021-08-23", "version": 1, "id": "8630aa22-042b-11ec-af39-acde48001122", "description": "This analytics is to detect a gmail containing a link that are known to be abused by malware or attacker like pastebin, telegram and discord to deliver malicious payload. This event can encounter some normal email traffic within organization and external email that normally using this application and services.", "tags": {"name": "Gsuite Email With Known Abuse Web Service Link", "analytic_story": ["Dev Sec Ops"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1566.001", "T1566"], "nist": ["DE.AE"], "observable": [{"name": "source.address", "type": "User", "role": ["Attacker"]}], "message": "suspicious email from $source.address$ to $destination{}.address$", "risk_score": 25, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_gmail` \"link_domain{}\" IN (\"*pastebin.com*\", \"*discord*\", \"*telegram*\",\"t.me\") | rex field=source.from_header_address \"[^@]+@(?<source_domain>[^@]+)\" | rex field=destination{}.address \"[^@]+@(?<dest_domain>[^@]+)\" | where not source_domain=\"internal_test_email.com\" and dest_domain=\"internal_test_email.com\" | eval phase=\"plan\" | eval severity=\"low\" |stats values(link_domain{}) as link_domains min(_time) as firstTime max(_time) as lastTime count by is_spam source.address source.from_header_address subject destination{}.address phase severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `gsuite_email_with_known_abuse_web_service_link_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to gsuite having the file attachment metadata like file type, file extension, source email, destination email, num of attachment and etc.", "known_false_positives": "normal email contains this link that are known application within the organization or network can be catched by this detection.", "check_references": false, "references": ["https://news.sophos.com/en-us/2021/07/22/malware-increasingly-targets-discord-for-abuse/"], "datamodel": [], "macros": [{"name": "gsuite_gmail", "definition": "sourcetype=gsuite:gmail:bigquery", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gsuite_email_with_known_abuse_web_service_link_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "Gsuite Email With Known Abuse Web Service Link:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_susp_url/gsuite_susp_url.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_susp_url/gsuite_susp_url.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}]}, {"name": "Gsuite Outbound Email With Attachment To External Domain", "author": "Teoderick Contreras, Stanislav Miskovic, Splunk", "date": "2024-03-25", "version": 2, "id": "dc4dc3a8-ff54-11eb-8bf7-acde48001122", "description": "This search is to detect a suspicious outbound e-mail from internal email to external email domain. This can be a good hunting query to monitor insider or outbound email traffic for not common domain e-mail. The idea is to parse the domain of destination email check if there is a minimum outbound traffic < 20 with attachment.", "tags": {"name": "Gsuite Outbound Email With Attachment To External Domain", "analytic_story": ["Dev Sec Ops", "Insider Threat"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1048.003", "T1048"], "nist": ["DE.AE"], "observable": [{"name": "src_domain_list", "type": "Email Address", "role": ["Victim"]}, {"name": "dest_domain", "type": "IP Address", "role": ["Attacker"]}], "message": "Suspicious email from $src_domain_list$ to $dest_domain$", "risk_score": 9, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_gmail` num_message_attachments > 0 | rex field=source.from_header_address \"[^@]+@(?<source_domain>[^@]+)\" | rex field=destination{}.address \"[^@]+@(?<dest_domain>[^@]+)\" | where source_domain=\"internal_test_email.com\" and not dest_domain=\"internal_test_email.com\" | eval phase=\"plan\" | eval severity=\"low\" | stats values(subject) as subject, values(source.from_header_address) as src_domain_list, count as numEvents, dc(source.from_header_address) as numSrcAddresses, min(_time) as firstTime max(_time) as lastTime by dest_domain phase severity | where numSrcAddresses < 20 |sort - numSrcAddresses | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `gsuite_outbound_email_with_attachment_to_external_domain_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to gsuite having the file attachment metadata like file type, file extension, source email, destination email, num of attachment and etc.", "known_false_positives": "network admin and normal user may send this file attachment as part of their day to day work. having a good protocol in attaching this file type to an e-mail may reduce the risk of having a spear phishing attack.", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops"], "datamodel": [], "macros": [{"name": "gsuite_gmail", "definition": "sourcetype=gsuite:gmail:bigquery", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gsuite_outbound_email_with_attachment_to_external_domain_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "Gsuite Outbound Email With Attachment To External Domain:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_outbound_email_to_external/gsuite_external_domain.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gsuite_outbound_email_to_external/gsuite_external_domain.log", "source": "http:gsuite", "sourcetype": "gsuite:gmail:bigquery"}]}]}, {"name": "Gsuite suspicious calendar invite", "author": "Rod Soto, Teoderick Contreras", "date": "2021-10-24", "version": 1, "id": "03cdd68a-34fb-11ec-9bd3-acde48001122", "description": "This search can help the detection of compromised accounts or internal users sending suspcious calendar invites via GSuite calendar. These invites may contain malicious links or attachments.", "tags": {"name": "Gsuite suspicious calendar invite", "analytic_story": ["Spearphishing Attachments"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1566"], "nist": ["DE.AE"], "observable": [{"name": "email", "type": "Email Address", "role": ["Attacker"]}], "message": "Gsuite suspicious calendar invite sent by $email$", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_calendar` |bin span=5m _time |rename parameters.* as * |search target_calendar_id!=null email=\"*yourdomain.com\"| stats  count values(target_calendar_id) values(event_title) values(event_guest) by email _time | where count >100| `gsuite_suspicious_calendar_invite_filter`", "how_to_implement": "In order to successfully implement this search, you need to be ingesting logs related to gsuite (gsuite:calendar:json) having the file sharing metadata like file type, source owner, destination target user, description, etc. This search can also be made more specific by selecting specific emails, subdomains timeframe, organizational units, targeted user, etc. In order for the search to work for your environment please update `yourdomain.com` value in the query with the domain relavant for your organization.", "known_false_positives": "This search will also produce normal activity statistics. Fields such as email, ip address, name, parameters.organizer_calendar_id, parameters.target_calendar_id and parameters.event_title may give away phishing intent.For more specific results use email parameter.", "check_references": false, "references": ["https://www.techrepublic.com/article/how-to-avoid-the-dreaded-google-calendar-malicious-invite-issue/", "https://gcn.com/cybersecurity/2012/09/the-20-most-common-words-in-phishing-attacks/280956/"], "datamodel": [], "macros": [{"name": "gsuite_calendar", "definition": "sourcetype=gsuite:calendar:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "gsuite_suspicious_calendar_invite_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": []}, {"name": "Gsuite Suspicious Shared File Name", "author": "Teoderick Contreras, Splunk", "date": "2021-08-23", "version": 1, "id": "07eed200-03f5-11ec-98fb-acde48001122", "description": "This search is to detect a shared file in google drive with suspicious file name that are commonly used by spear phishing campaign. This technique is very popular to lure the user by running a malicious document or click a malicious link within the shared file that will redirected to malicious website. This detection can also catch some normal email communication between organization and its external customer.", "tags": {"name": "Gsuite Suspicious Shared File Name", "analytic_story": ["Dev Sec Ops"], "asset_type": "GSuite", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1566.001", "T1566"], "nist": ["DE.AE"], "observable": [{"name": "parameters.owner", "type": "User", "role": ["Attacker"]}, {"name": "email", "type": "User", "role": ["Victim"]}], "message": "suspicious share gdrive from $parameters.owner$ to $email$ namely as $parameters.doc_title$", "risk_score": 21, "security_domain": "endpoint", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`gsuite_drive` parameters.owner_is_team_drive=false \"parameters.doc_title\" IN (\"*dhl*\", \"* ups *\", \"*delivery*\", \"*parcel*\", \"*label*\", \"*invoice*\", \"*postal*\", \"*fedex*\", \"* usps *\", \"* express *\", \"*shipment*\", \"*Banking/Tax*\",\"*shipment*\", \"*new order*\") parameters.doc_type IN (\"document\",\"pdf\", \"msexcel\", \"msword\", \"spreadsheet\", \"presentation\") | rex field=parameters.owner \"[^@]+@(?<source_domain>[^@]+)\" | rex field=parameters.target_user \"[^@]+@(?<dest_domain>[^@]+)\" | where not source_domain=\"internal_test_email.com\" and dest_domain=\"internal_test_email.com\" | eval phase=\"plan\" | eval severity=\"low\" | stats count min(_time) as firstTime max(_time) as lastTime by email parameters.owner parameters.target_user parameters.doc_title parameters.doc_type phase severity | rename parameters.target_user AS user | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `gsuite_suspicious_shared_file_name_filter`", "how_to_implement": "To successfully implement this search, you need to be ingesting logs related to gsuite having the file attachment metadata like file type, file extension, source email, destination email, num of attachment and etc. In order for the search to work for your environment, please edit the query to use your company specific email domain instead of `internal_test_email.com`.", "known_false_positives": "normal user or normal transaction may contain the subject and file type attachment that this detection try to search", "check_references": false, "references": ["https://www.redhat.com/en/topics/devops/what-is-devsecops", "https://www.mandiant.com/resources/top-words-used-in-spear-phishing-attacks"], "datamodel": [], "macros": [{"name": "gsuite_drive", "definition": "sourcetype=gsuite:drive:json", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "gsuite_suspicious_shared_file_name_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Google Workspace", "Google Cloud Platform"], "enabled_by_default": false, "test_groups": [{"name": "Gsuite Suspicious Shared File Name:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gdrive_susp_file_share/gdrive_susp_attach.log", "source": "http:gsuite", "sourcetype": "gsuite:drive:json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1566.001/gdrive_susp_file_share/gdrive_susp_attach.log", "source": "http:gsuite", "sourcetype": "gsuite:drive:json"}]}]}, {"name": "High Number of Login Failures from a single source", "author": "Bhavin Patel, Mauricio Velazco, Splunk", "date": "2020-12-16", "version": 2, "id": "7f398cfb-918d-41f4-8db8-2e2474e02222", "description": "This analytic detects multiple failed login attempts in Office365 Azure Active Directory from a single source IP address. Specifically, it identifies scenarios where there are more than 10 unsuccessful login attempts within a short time frame. The detection leverages Office365 management activity logs, specifically the AzureActiveDirectoryStsLogon records from the AzureActiveDirectory workload. It aggregates these logs in 5-minute intervals to count the number of failed login attempts and associates them with the originating source IP address. Multiple failed login attempts from a single source can be indicative of brute-force attacks, password spraying, or other malicious authentication attempts. Identifying and responding to these patterns promptly can prevent unauthorized access and potential breaches. If this detection represents a true positive, an attacker might be attempting to gain unauthorized access to an Office365 account. Successful compromise could lead to unauthorized access to sensitive data, potential lateral movement within the organization, or further malicious activities using the compromised account.", "tags": {"name": "High Number of Login Failures from a single source", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110.001", "T1110"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Ip address $src_ip$ failed to authenticate more than 10 times in a 5 minute", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=UserLoginFailed record_type=AzureActiveDirectoryStsLogon | bucket span=5m _time | stats dc(_raw) AS failed_attempts values(user) as user values(LogonError) as LogonError values(signature) as signature values(UserAgent) as UserAgent by _time, src_ip | where failed_attempts > 10 | `high_number_of_login_failures_from_a_single_source_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events. Adjust the threshold value to suit the specific environment, as environments with naturally higher login failures might generate false positives at a lower threshold.", "known_false_positives": "An Ip address with more than 10 failed authentication attempts in the span of 5 minutes may also be triggered by a broken application.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/001/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://docs.microsoft.com/azure/active-directory/reports-monitoring/reference-sign-ins-error-codes"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "high_number_of_login_failures_from_a_single_source_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "High Number of Login Failures from a single source:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/o365_high_number_authentications_for_user/o365_high_number_authentications_for_user.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/o365_high_number_authentications_for_user/o365_high_number_authentications_for_user.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "Kubernetes Abuse of Secret by Unusual Location", "author": "Patrick Bareiss, Splunk", "date": "2023-12-06", "version": 1, "id": "40a064c1-4ec1-4381-9e35-61192ba8ef82", "description": "The following analytic detects unauthorized access or misuse of Kubernetes Secrets from unusual locations. It identifies anomalies in access patterns by segmenting and analyzing the source of requests by country. Kubernetes Secrets, which store sensitive information like passwords, OAuth tokens, and SSH keys, are critical assets, and their misuse can lead to significant security breaches. This behavior is worth identifying for a SOC as it could indicate an attacker attempting to exfiltrate or misuse these secrets. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Abuse of Secret by Unusual Location", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1552.007"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Access of Kubernetes secret $objectRef.name$ from unusual location $Country$ by $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=secrets verb=get | iplocation sourceIPs{} | fillnull | search NOT `kube_allowed_loactions` | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb City Country | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_abuse_of_secret_by_unusual_location_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_allowed_loactions", "definition": "Country=\"United States\"", "description": "Define your locations which are allowed to connect to your kubernetes cluster."}, {"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_abuse_of_secret_by_unusual_location_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Abuse of Secret by Unusual Location:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Abuse of Secret by Unusual User Agent", "author": "Patrick Bareiss, Splunk", "date": "2023-12-06", "version": 1, "id": "096ab390-05ca-462c-884e-343acd5b9240", "description": "The following analytic detects unauthorized access or misuse of Kubernetes Secrets by unusual user agents. It identifies anomalies in access patterns by segmenting and analyzing the source of requests by user agent. Kubernetes Secrets, which store sensitive information like passwords, OAuth tokens, and SSH keys, are critical assets, and their misuse can lead to significant security breaches. This behavior is worth identifying for a SOC as it could indicate an attacker attempting to exfiltrate or misuse these secrets. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Abuse of Secret by Unusual User Agent", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1552.007"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Access of Kubernetes secret $objectRef.name$ from unusual user agent $userAgent$ by $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=secrets verb=get | search NOT `kube_allowed_user_agents` | fillnull | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_abuse_of_secret_by_unusual_user_agent_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_allowed_user_agents", "definition": "userAgent=Helm/3.13.2", "description": "Define your user agents which are allowed to connect to your kubernetes cluster."}, {"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_abuse_of_secret_by_unusual_user_agent_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Abuse of Secret by Unusual User Agent:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Abuse of Secret by Unusual User Group", "author": "Patrick Bareiss, Splunk", "date": "2023-12-06", "version": 1, "id": "b6f45bbc-4ea9-4068-b3bc-0477f6997ae2", "description": "The following analytic detects unauthorized access or misuse of Kubernetes Secrets by unusual user groups. It identifies anomalies in access patterns by segmenting and analyzing the source of requests by user group. Kubernetes Secrets, which store sensitive information like passwords, OAuth tokens, and SSH keys, are critical assets, and their misuse can lead to significant security breaches. This behavior is worth identifying for a SOC as it could indicate an attacker attempting to exfiltrate or misuse these secrets. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Abuse of Secret by Unusual User Group", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1552.007"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Access of Kubernetes secret $objectRef.name$ from unusual user group $user.groups{}$ by user name $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=secrets verb=get | search NOT `kube_allowed_user_groups` | fillnull | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_abuse_of_secret_by_unusual_user_group_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_allowed_user_groups", "definition": "user.groups{} IN (admin)", "description": "Define your user groups which are allowed to connect to your kubernetes cluster."}, {"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_abuse_of_secret_by_unusual_user_group_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Abuse of Secret by Unusual User Group:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Abuse of Secret by Unusual User Name", "author": "Patrick Bareiss, Splunk", "date": "2023-12-06", "version": 1, "id": "df6e9cae-5257-4a34-8f3a-df49fa0f5c46", "description": "The following analytic detects unauthorized access or misuse of Kubernetes Secrets by unusual user names. It identifies anomalies in access patterns by segmenting and analyzing the source of requests by user name. Kubernetes Secrets, which store sensitive information like passwords, OAuth tokens, and SSH keys, are critical assets, and their misuse can lead to significant security breaches. This behavior is worth identifying for a SOC as it could indicate an attacker attempting to exfiltrate or misuse these secrets. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Abuse of Secret by Unusual User Name", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1552.007"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Access of Kubernetes secret $objectRef.name$ from unusual user name $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=secrets verb=get | search NOT `kube_allowed_user_names` | fillnull | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_abuse_of_secret_by_unusual_user_name_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_allowed_user_names", "definition": "user.username=admin", "description": "Define your user names which are allowed to connect to your kubernetes cluster."}, {"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_abuse_of_secret_by_unusual_user_name_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Abuse of Secret by Unusual User Name:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1552.007/kube_audit_get_secret/kube_audit_get_secret.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Access Scanning", "author": "Patrick Bareiss, Splunk", "date": "2023-12-07", "version": 1, "id": "2f4abe6d-5991-464d-8216-f90f42999764", "description": "The following analytic detects potential scanning activities within a Kubernetes environment. It identifies unauthorized access attempts, probing of public APIs, or attempts to exploit known vulnerabilities. The analytic detects this behavior by monitoring Kubernetes audit logs for patterns indicative of scanning, such as repeated failed access attempts or unusual API requests. This behavior is worth identifying for a SOC as it could indicate an attackers preliminary step in an attack, aiming to gather information about the system to find potential vulnerabilities. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Access Scanning", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1046"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes scanning from ip $src_ip$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` \"user.groups{}\"=\"system:unauthenticated\" \"responseStatus.code\"=403 | iplocation sourceIPs{} | stats count values(userAgent) as userAgent values(user.username) as user.username values(user.groups{}) as user.groups{} values(verb) as verb values(requestURI) as requestURI values(responseStatus.code) as responseStatus.code values(responseStatus.message) as responseStatus.message values(responseStatus.reason) as responseStatus.reason values(responseStatus.status) as responseStatus.status by sourceIPs{} Country City | where count > 5 | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_access_scanning_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_access_scanning_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Access Scanning:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1046/kubernetes_scanning/kubernetes_scanning.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1046/kubernetes_scanning/kubernetes_scanning.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Anomalous Inbound Network Activity from Process", "author": "Matthew Moore, Splunk", "date": "2024-01-10", "version": 1, "id": "10442d8b-0701-4c25-911d-d67b906e713c", "description": "This detection detects inbound network traffic volume anomalies from processes running within containerised workloads. Anomalies are provided with context identifying the Kubernetes cluster, the workload name, and the type of anomaly.This detection leverages Network performance Monitoring metrics harvested using an OTEL collector, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection compares the tcp.bytes, tcp.new_sockets, tcp.packets, udp.bytes, udp.packets metrics for destination (receiving) workload process pairs over the last 1 hour, with the average of those metrics for those pairs over the last 30 days in order to detect any anonymously high inbound network activity. Anomalies in inbound network traffic may suggest that the container is receiving unexpected or unauthorized data, potentially indicative of a breach, a vulnerability exploitation attempt, an attempt to overload the service, or propagation of malware. Successful compromise of a containerised application resulting in the ability to upload data, can result in installation of command and control software or other malware, data integrity damage, container escape, and further compromise of the environment. Additionally this kind of activity may result in resource contention, performance degradation and disruption to the normal operation of the environment.", "tags": {"name": "Kubernetes Anomalous Inbound Network Activity from Process", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Anomalous Inbound Network Activity from Process in kubernetes cluster $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(tcp.*) as tcp.* avg(udp.*) as udp.* where `kubernetes_metrics` AND earliest=-1h by k8s.cluster.name dest.workload.name dest.process.name  span=10s | eval key='dest.workload.name' + \":\" + 'dest.process.name' | join type=left key [ mstats avg(tcp.*) as avg_tcp.* avg(udp.*) as avg_udp.* stdev(tcp.*) as stdev_tcp.* avg(udp.*) as stdev_udp.* where `kubernetes_metrics` AND earliest=-30d latest=-1h by dest.workload.name dest.process.name | eval key='dest.workload.name' + \":\" + 'dest.process.name' ] | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 3 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | fillnull | eval anomalies = split(replace(anomalies, \",\\s$$$$\", \"\") ,\", \") | where anomalies!=\"\" | stats count(anomalies) as count values(anomalies) as anomalies by k8s.cluster.name dest.workload.name dest.process.name | where count > 5 | rename k8s.cluster.name as host | `kubernetes_anomalous_inbound_network_activity_from_process_filter` ", "how_to_implement": "To gather NPM metrics the Open Telemetry to the Kubernetes Cluster and enable Network Performance Monitoring according to instructions found in Splunk Docs https://docs.splunk.com/observability/en/infrastructure/network-explorer/network-explorer-setup.html#network-explorer-setup In order to access those metrics from within Splunk Enterprise and ES, the Splunk Infrastructure Monitoring add-on must be installed and configured on a Splunk Search Head.  Once installed, first configure the add-on with your O11y Cloud Org ID and Access Token. Lastly set up the add-on to ingest metrics from O11y cloud using the following settings, and any other settings left at default:\\\n* Name sim_npm_metrics_to_metrics_index \\\n* Org ID <Your O11y Cloud Org Id> \\\n* Signal Flow Program data('tcp.packets').publish(label='A'); data('tcp.bytes').publish(label='B'); data('tcp.new_sockets').publish(label='C'); data('udp.packets').publish(label='D'); data('udp.bytes').publish(label='E') \\\n* Metric Resolution 10000", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_anomalous_inbound_network_activity_from_process_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Anomalous Inbound Outbound Network IO", "author": "Matthew Moore, Splunk", "date": "2023-12-19", "version": 1, "id": "4f3b0c97-657e-4547-a89a-9a50c656e3cd", "description": "This analytic identifies high Inbound or Outbound Network IO anomalies in a Kubernetes container. It uses process metrics from an OTEL collector and Kubelet Stats Receiver, and data from Splunk Observability cloud via the Splunk Infrastructure Monitoring Add-on. A lookup table containing average and standard deviation for network IO is used to evaluate anomalies for each container. An event is generated if the anomaly persists over a 1 hour period. These anomalies may indicate security threats such as data exfiltration, command and control communication, service disruptions, or unauthorized data transfers. They can compromise the confidentiality, availability, and integrity of applications and data, necessitating rapid detection and response. Anomalous network utilization may suggest a compromised container, potentially leading to data breaches, service outages, financial losses, and reputational damage.", "tags": {"name": "Kubernetes Anomalous Inbound Outbound Network IO", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Anomalous Inbound Outbound Network IO from container on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(k8s.pod.network.io) as io where `kubernetes_metrics` by k8s.cluster.name k8s.pod.name k8s.node.name direction span=10s | eval service = replace('k8s.pod.name', \"-\\w{5}$$|-[abcdef0-9]{8,10}-\\w{5}$$\", \"\") | stats avg(eval(if(direction=\"transmit\", io,null()))) as outbound_network_io avg(eval(if(direction=\"receive\", io,null()))) as inbound_network_io by k8s.cluster.name k8s.node.name k8s.pod.name service _time | eval key = 'k8s.cluster.name' + \":\" + 'service' | lookup k8s_container_network_io_baseline key | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 4 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | eval anomalies = replace(anomalies, \",\\s$$\", \"\") | where anomalies!=\"\" | stats count values(anomalies) as anomalies by k8s.cluster.name k8s.node.name k8s.pod.name service | rename service as k8s.service | where count > 5 | rename k8s.node.name as host | `kubernetes_anomalous_inbound_outbound_network_traffic_io_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_anomalous_inbound_outbound_network_io_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "k8s_container_network_io_baseline", "description": "A place holder for a list of used Kuberntes Container Network IO", "collection": "k8s_container_network_io_baseline", "fields_list": "key, avg_outbound_network_io, avg_inbound_network_io, stdev_outbound_network_io, stdev_inbound_network_io, count, last_seen", "file_path": "/home/jose.costa/splunk/content/lookups/k8s_container_network_io_baseline.yml"}], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Anomalous Inbound to Outbound Network IO Ratio", "author": "Matthew Moore, Splunk", "date": "2023-12-19", "version": 1, "id": "9d8f6e3f-39df-46d8-a9d4-96173edc501f", "description": "This analytic identifies changes in network communication behavior in a Kubernetes container by examining inbound to outbound network IO ratios. It uses process metrics from an OTEL collector and Kubelet Stats Receiver, and data from Splunk Observability cloud via the Splunk Infrastructure Monitoring Add-on. A lookup table containing average and standard deviation for network IO is used to evaluate anomalies for each container. An event is generated if the anomaly persists over a 1 hour period. These anomalies may indicate security threats such as data exfiltration, command and control communication, or compromised container behavior. They can compromise the confidentiality, availability, and integrity of applications and data, necessitating rapid detection and response. Anomalous network utilization may suggest a compromised container, potentially leading to data breaches, service outages, and unauthorized access within the Kubernetes cluster.", "tags": {"name": "Kubernetes Anomalous Inbound to Outbound Network IO Ratio", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Anomalous Inbound to Outbound Network IO Ratio from Container on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(k8s.pod.network.io) as io where `kubernetes_metrics` by k8s.cluster.name k8s.pod.name k8s.node.name direction span=10s | eval service = replace('k8s.pod.name', \"-\\w{5}$|-[abcdef0-9]{8,10}-\\w{5}$\", \"\") | eval key = 'k8s.cluster.name' + \":\" + 'service' | stats avg(eval(if(direction=\"transmit\", io,null()))) as outbound_network_io avg(eval(if(direction=\"receive\", io,null()))) as inbound_network_io by key service k8s.cluster.name k8s.pod.name k8s.node.name _time | eval inbound:outbound = inbound_network_io/outbound_network_io | eval outbound:inbound = outbound_network_io/inbound_network_io | fields - *network_io | lookup k8s_container_network_io_ratio_baseline key | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 4 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> ratio higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | eval anomalies = replace(anomalies, \",\\s$\", \"\") | where anomalies!=\"\" | stats count values(anomalies) as anomalies by k8s.cluster.name k8s.node.name k8s.pod.name service | rename service as k8s.service | where count > 5 | rename k8s.node.name as host | `kubernetes_anomalous_inbound_to_outbound_network_io_ratio_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_anomalous_inbound_to_outbound_network_io_ratio_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "k8s_container_network_io_ratio_baseline", "description": "A place holder for a list of used Kuberntes Container Network IO Ratio", "collection": "k8s_container_network_io_ratio_baseline", "fields_list": "key, avg_outbound_network_io, avg_inbound_network_io, stdev_outbound_network_io, stdev_inbound_network_io, count, last_seen", "file_path": "/home/jose.costa/splunk/content/lookups/k8s_container_network_io_ratio_baseline.yml"}], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Anomalous Outbound Network Activity from Process", "author": "Matthew Moore, Splunk", "date": "2024-01-10", "version": 1, "id": "dd6afee6-e0a3-4028-a089-f47dd2842c22", "description": "This detection detects outbound network traffic volume anomalies from processes running within containerised workloads. Anomalies are provided with context identifying the Kubernetes cluster, the workload name, and the type of anomaly. This detection leverages Network performance Monitoring metrics harvested using an OTEL collector, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection compares the tcp.bytes, tcp.new_sockets, tcp.packets, udp.bytes, udp.packets metrics for source (transmitting) workload process pairs over the last 1 hout, with the average of those metrics for those pairs over the last 30 days in order to detect any anonymously high outbound network activity. Anonymously high outbound network traffic from a process running in a container is a potential indication of data exfiltration, or an indication that the process has been modified. Anomalously high outbound network activity from a process running within a container suggests the potential compromise, which may lead to unauthorized data exfiltration, communication with malicious entities, or the propagation of malware to external systems. The compromised container could also serve as a pivot point for further attacks within the containerized environment.", "tags": {"name": "Kubernetes Anomalous Outbound Network Activity from Process", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Anomalous Outbound Network Activity from Process in kubernetes cluster $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(tcp.*) as tcp.* avg(udp.*) as udp.* where `kubernetes_metrics` AND earliest=-1h by k8s.cluster.name source.workload.name source.process.name  span=10s | eval key='source.workload.name' + \":\" + 'source.process.name' | join type=left key [ mstats avg(tcp.*) as avg_tcp.* avg(udp.*) as avg_udp.* stdev(tcp.*) as stdev_tcp.* avg(udp.*) as stdev_udp.* where `kubernetes_metrics` AND earliest=-30d latest=-1h by source.workload.name source.process.name | eval key='source.workload.name' + \":\" + 'source.process.name' ] | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 3 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | fillnull | eval anomalies = split(replace(anomalies, \",\\s$$$$\", \"\") ,\", \") | where anomalies!=\"\" | stats count(anomalies) as count values(anomalies) as anomalies by k8s.cluster.name source.workload.name source.process.name | where count > 5 | rename k8s.cluster.name as host | `kubernetes_anomalous_outbound_network_activity_from_process_filter` ", "how_to_implement": "To gather NPM metrics the Open Telemetry to the Kubernetes Cluster and enable Network Performance Monitoring according to instructions found in Splunk Docs https://docs.splunk.com/observability/en/infrastructure/network-explorer/network-explorer-setup.html#network-explorer-setup In order to access those metrics from within Splunk Enterprise and ES, the Splunk Infrastructure Monitoring add-on must be installed and configured on a Splunk Search Head.  Once installed, first configure the add-on with your O11y Cloud Org ID and Access Token. Lastly set up the add-on to ingest metrics from O11y cloud using the following settings, and any other settings left at default:\\\n* Name sim_npm_metrics_to_metrics_index \\\n* Org ID <Your O11y Cloud Org Id> \\\n* Signal Flow Program data('tcp.packets').publish(label='A'); data('tcp.bytes').publish(label='B'); data('tcp.new_sockets').publish(label='C'); data('udp.packets').publish(label='D'); data('udp.bytes').publish(label='E') \\\n* Metric Resolution 10000", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_anomalous_outbound_network_activity_from_process_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Anomalous Traffic on Network Edge", "author": "Matthew Moore, Splunk", "date": "2024-01-10", "version": 1, "id": "886c7e51-2ea1-425d-8705-faaca5a64cc6", "description": "This detection detects network traffic volume anomalies between workloads in a microservices hosted application, or between a workload and the outside world if the workload is shown as (unknown). This detection leverages Network performance Monitoring metrics harvested using an OTEL collector, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on (https://splunkbase.splunk.com/app/5247). This detection compares the tcp.bytes, tcp.new_sockets, tcp.packets, udp.bytes, udp.packets metrics between workloads over the last 1 hour, with the average of those metrics over the last 30 days in order to detect any anonymously high inbound or outbound network activity. Unexpected spikes in network traffic may signify unauthorized data transfers, or abnormal behavior within the microservices ecosystem. Such activity might signify data exfiltration, unauthorized lateral movement, within the microservices environment. If a bad actor is responsible for this traffic they could compromise additional services or extract sensitive data, potentially leading to data breaches.", "tags": {"name": "Kubernetes Anomalous Traffic on Network Edge", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Anomalous Traffic on Network Edge in kubernetes cluster $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(tcp.*) as tcp.* avg(udp.*) as udp.* where `kubernetes_metrics` AND earliest=-1h by k8s.cluster.name source.workload.name dest.workload.name span=10s | eval key='source.workload.name' + \":\" + 'dest.workload.name' | join type=left key [ mstats avg(tcp.*) as avg_tcp.* avg(udp.*) as avg_udp.* stdev(tcp.*) as stdev_tcp.* avg(udp.*) as stdev_udp.* where `kubernetes_metrics` AND earliest=-30d latest=-1h by source.workload.name dest.workload.name | eval key='source.workload.name' + \":\" + 'dest.workload.name' ] | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 3 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | fillnull | eval anomalies = split(replace(anomalies, \",\\s$$$$\", \"\") ,\", \") | where anomalies!=\"\" | stats count(anomalies) as count values(anomalies) as anomalies by k8s.cluster.name source.workload.name dest.workload.name | rename service as k8s.service | where count > 5 | rename k8s.cluster.name as host | `kubernetes_anomalous_traffic_on_network_edge_filter` ", "how_to_implement": "To gather NPM metrics the Open Telemetry to the Kubernetes Cluster and enable Network Performance Monitoring according to instructions found in Splunk Docs https://docs.splunk.com/observability/en/infrastructure/network-explorer/network-explorer-setup.html#network-explorer-setup In order to access those metrics from within Splunk Enterprise and ES, the Splunk Infrastructure Monitoring add-on must be installed and configured on a Splunk Search Head.  Once installed, first configure the add-on with your O11y Cloud Org ID and Access Token. Lastly set up the add-on to ingest metrics from O11y cloud using the following settings, and any other settings left at default:\\\n* Name sim_npm_metrics_to_metrics_index \\\n* Org ID <Your O11y Cloud Org Id> \\\n* Signal Flow Program data('tcp.packets').publish(label='A'); data('tcp.bytes').publish(label='B'); data('tcp.new_sockets').publish(label='C'); data('udp.packets').publish(label='D'); data('udp.bytes').publish(label='E') \\\n* Metric Resolution 10000", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_anomalous_traffic_on_network_edge_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes AWS detect suspicious kubectl calls", "author": "Rod Soto, Patrick Bareiss, Splunk", "date": "2023-12-19", "version": 2, "id": "042a3d32-8318-4763-9679-09db2644a8f2", "description": "The following analytic detects anonymous and unauthenticated requests to a Kubernetes cluster. It identifies this behavior by monitoring for API calls from users who have not provided any token or password in their request. This is a significant behavior to identify for a SOC as it indicates a severe misconfiguration that allows unfettered access to a cluster with no traceability to a user or service. The impact of such an attack could be substantial, potentially granting an attacker access to sensitive data or control over the cluster. This detection rule is crucial for maintaining the security and integrity of your Kubernetes infrastructure.", "tags": {"name": "Kubernetes AWS detect suspicious kubectl calls", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 10"], "kill_chain_phases": [], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` user.username=\"system:anonymous\" user.groups{} IN (\"system:unauthenticated\") | fillnull | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user |`kubernetes_aws_detect_suspicious_kubectl_calls_filter`", "how_to_implement": "You must install splunk AWS add on and Splunk App for AWS. This search works with cloudwatch logs.", "known_false_positives": "Kubectl calls are not malicious by nature. However source IP, verb and Object can reveal potential malicious activity, specially anonymous suspicious IPs and sensitive objects such as configmaps or secrets", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_aws_detect_suspicious_kubectl_calls_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Create or Update Privileged Pod", "author": "Patrick Bareiss, Splunk", "date": "2023-12-14", "version": 1, "id": "3c6bd734-334d-4818-ae7c-5234313fc5da", "description": "The following analytic detects the creation of privileged pods in Kubernetes. It identifies this behavior by monitoring Kubernetes Audit logs for the creation of pods with root privileges. This behavior is worth identifying for a SOC as it could potentially allow an attacker to escalate privileges, exploit the kernel, and gain full access to the host's namespace and devices. The impact of such an attack could be severe, leading to unauthorized access to sensitive information, data breaches, and service disruptions.", "tags": {"name": "Kubernetes Create or Update Privileged Pod", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes privileged pod created by user $user$.", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=pods verb=create OR verb=update requestObject.metadata.annotations.kubectl.kubernetes.io/last-applied-configuration=*\\\"privileged\\\":true* | fillnull | stats count values(user.groups{}) as user_groups by kind objectRef.name objectRef.namespace objectRef.resource requestObject.kind responseStatus.code sourceIPs{} stage user.username userAgent verb requestObject.metadata.annotations.kubectl.kubernetes.io/last-applied-configuration | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_create_or_update_privileged_pod_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_create_or_update_privileged_pod_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Create or Update Privileged Pod:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_privileged_pod/kubernetes_privileged_pod.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_privileged_pod/kubernetes_privileged_pod.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Cron Job Creation", "author": "Patrick Bareiss, Splunk", "date": "2023-12-14", "version": 1, "id": "5984dbe8-572f-47d7-9251-3dff6c3f0c0d", "description": "The following analytic detects the creation of a Kubernetes cron job, a task scheduled to run automatically at specified intervals. It identifies this behavior by monitoring Kubernetes Audit logs for creation of a cron job. This behavior is worth identifying for a SOC as it could potentially allow an attacker to execute malicious tasks repeatedly and automatically, posing a significant threat to the integrity and security of the Kubernetes infrastructure. The impact of such an attack could be severe, leading to persistent attacks, service disruptions, or unauthorized access to sensitive information.", "tags": {"name": "Kubernetes Cron Job Creation", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1053.007"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes cron job creation from user $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` verb=create \"objectRef.resource\"=cronjobs | fillnull | stats count values(user.groups{}) as user_groups by kind objectRef.name objectRef.namespace objectRef.resource requestObject.kind requestObject.spec.schedule requestObject.spec.jobTemplate.spec.template.spec.containers{}.image responseStatus.code sourceIPs{} stage user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_cron_job_creation_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_cron_job_creation_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Cron Job Creation:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1053.007/kubernetes_audit_cron_job_creation/kubernetes_audit_cron_job_creation.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1053.007/kubernetes_audit_cron_job_creation/kubernetes_audit_cron_job_creation.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes DaemonSet Deployed", "author": "Patrick Bareiss, Splunk", "date": "2023-12-14", "version": 1, "id": "bf39c3a3-b191-4d42-8738-9d9797bd0c3a", "description": "The following analytic detects the creation of a DaemonSet in a Kubernetes cluster. A DaemonSet ensures the presence of a specific pod on every node in the cluster, making it an ideal avenue for persistent access. This behavior is identified by monitoring Kubernetes Audit logs for the creation of a DaemonSet. The identified behavior is worth noting for a SOC as it could potentially allow an attacker to maintain persistent access to the Kubernetes infrastructure. The impact of such an attack could be severe, leading to persistent attacks, service disruptions, or unauthorized access to sensitive information.", "tags": {"name": "Kubernetes DaemonSet Deployed", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "DaemonSet deployed to Kubernetes by user $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` \"objectRef.resource\"=daemonsets verb=create | fillnull | stats count values(user.groups{}) as user_groups by kind objectRef.name objectRef.namespace objectRef.resource requestObject.kind responseStatus.code sourceIPs{} stage user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_daemonset_deployed_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_daemonset_deployed_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes DaemonSet Deployed:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_audit_daemonset_created/kubernetes_audit_daemonset_created.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_audit_daemonset_created/kubernetes_audit_daemonset_created.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Falco Shell Spawned", "author": "Patrick Bareiss, Splunk", "date": "2023-12-13", "version": 1, "id": "d2feef92-d54a-4a19-8306-b47c6ceba5b2", "description": "The following analytic detects instances where a shell is spawned within a Kubernetes container, a behavior often indicative of an attacker gaining unauthorized access. Leveraging Falco, a cloud-native runtime security tool, this analytic monitors system calls within the Kubernetes environment, flagging when a shell is spawned in a container. This behavior is worth identifying for a SOC as it could potentially allow an attacker to execute arbitrary commands, manipulate container processes, or escalate privileges, posing a significant threat to the integrity and security of the Kubernetes infrastructure. The impact of such an attack could be severe, leading to data breaches, service disruptions, or unauthorized access to sensitive information.", "tags": {"name": "Kubernetes Falco Shell Spawned", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "A shell is spawned in the container $container_name$ by user $user$.", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_container_falco` \"A shell was spawned in a container\" |  fillnull | stats count by container_image container_image_tag container_name parent proc_exepath process user | `kubernetes_falco_shell_spawned_filter` ", "how_to_implement": "The detection is based on data that originates from Falco, a cloud native runtime security tool. Falco is designed to detect anomalous activity in your applications and is a crucial component of this detection rule. To implement this detection rule, you need to install and configure Falco in your Kubernetes environment. Once Falco is set up, it will monitor the system calls in your Kubernetes infrastructure and generate logs for any suspicious activity. These logs are then ingested by Splunk for analysis. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_container_falco", "definition": "sourcetype=\"kube:container:falco\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_falco_shell_spawned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Falco Shell Spawned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_falco_shell_spawned/kubernetes_falco_shell_spawned.log", "source": "kubernetes", "sourcetype": "kube:container:falco"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_falco_shell_spawned/kubernetes_falco_shell_spawned.log", "source": "kubernetes", "sourcetype": "kube:container:falco"}]}]}, {"name": "Kubernetes newly seen TCP edge", "author": "Matthew Moore, Splunk", "date": "2024-01-10", "version": 1, "id": "13f081d6-7052-428a-bbb0-892c79ca7c65", "description": "This analytic detects TCP communication between a newly seen source and destination workload pair. This is done to identify changes in network behavior between workloads in a kubernetes cluster. This detection leverages Network performance Monitoring metrics harvested using an OTEL collector, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection compares network activity between workloads over the last 1 hour, with those over the last 30 days in order to detect newly seen inter workload communication. Newly seen network connections in a microservices based app indicate a change in behavior which could indicate potential security threats or anomalies. Distributed applications typically have common established network connection topologies, and new connections are often either an indication of a change in the application or an active threat. Unauthorized connections may enable the attacker to infiltrate the applications ecosystem, potentially leading to data breaches, manipulation of sensitive information, or disruption of critical services. Bad actors may exploit these connections to gain access, escalate privileges, move laterally within the microservices, or introduce malicious code or payloads, putting the applications integrity, availability, and confidentiality at risk.", "tags": {"name": "Kubernetes newly seen TCP edge", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes newly seen TCP edge in kubernetes cluster $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats count(tcp.packets) as tcp.packets_count where `kubernetes_metrics` AND earliest=-1h by k8s.cluster.name source.workload.name dest.workload.name | eval current=\"True\" | append [ mstats count(tcp.packets) as tcp.packets_count where `kubernetes_metrics` AND earliest=-30d latest=-1h by source.workload.name dest.workload.name | eval current=\"false\" ] | eventstats values(current) as current by source.workload.name dest.workload.name | search current=\"true\" current!=\"false\" | rename k8s.cluster.name as host | `kubernetes_newly_seen_tcp_edge_filter` ", "how_to_implement": "To gather NPM metrics the Open Telemetry to the Kubernetes Cluster and enable Network Performance Monitoring according to instructions found in Splunk Docs https://docs.splunk.com/observability/en/infrastructure/network-explorer/network-explorer-setup.html#network-explorer-setup In order to access those metrics from within Splunk Enterprise and ES, the Splunk Infrastructure Monitoring add-on must be installed and configured on a Splunk Search Head.  Once installed, first configure the add-on with your O11y Cloud Org ID and Access Token. Lastly set up the add-on to ingest metrics from O11y cloud using the following settings, and any other settings left at default:\\\n* Name sim_npm_metrics_to_metrics_index \\\n* Org ID <Your O11y Cloud Org Id> \\\n* Signal Flow Program data('tcp.packets').publish(label='A'); data('tcp.bytes').publish(label='B'); data('tcp.new_sockets').publish(label='C'); data('udp.packets').publish(label='D'); data('udp.bytes').publish(label='E') \\\n* Metric Resolution 10000", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_newly_seen_tcp_edge_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes newly seen UDP edge", "author": "Matthew Moore, Splunk", "date": "2024-01-10", "version": 1, "id": "49b7daca-4e3c-4899-ba15-9a175e056fa9", "description": "This analytic detects UDP communication between a newly seen source and destination workload pair. This is done to identify changes in network behavior between workloads in a kubernetes cluster. This detection leverages Network performance Monitoring metrics harvested using an OTEL collector, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection compares network activity between workloads over the last 1 hour, with those over the last 30 days in order to detect newly seen inter workload communication. Newly seen network connections in a microservices based app indicate a change in behavior which could indicate potential security threats or anomalies. Distributed applications typically have common established network connection topologies, and new connections are often either an indication of a change in the application or an active threat. Unauthorized connections may enable the attacker to infiltrate the applications ecosystem, potentially leading to data breaches, manipulation of sensitive information, or disruption of critical services. Bad actors may exploit these connections to gain access, escalate privileges, move laterally within the microservices, or introduce malicious code or payloads, putting the applications integrity, availability, and confidentiality at risk.", "tags": {"name": "Kubernetes newly seen UDP edge", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes newly seen UDP edge in kubernetes cluster $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats count(udp.packets) as udp.packets_count where `kubernetes_metrics` AND earliest=-1h by k8s.cluster.name source.workload.name dest.workload.name | eval current=\"True\" | append [ mstats count(udp.packets) as udp.packets_count where `kubernetes_metrics` AND earliest=-30d latest=-1h by source.workload.name dest.workload.name | eval current=\"false\" ] | eventstats values(current) as current by source.workload.name dest.workload.name | search current=\"true\" current!=\"false\" | rename k8s.cluster.name as host | `kubernetes_newly_seen_udp_edge_filter` ", "how_to_implement": "To gather NPM metrics the Open Telemetry to the Kubernetes Cluster and enable Network Performance Monitoring according to instructions found in Splunk Docs https://docs.splunk.com/observability/en/infrastructure/network-explorer/network-explorer-setup.html#network-explorer-setup In order to access those metrics from within Splunk Enterprise and ES, the Splunk Infrastructure Monitoring add-on must be installed and configured on a Splunk Search Head.  Once installed, first configure the add-on with your O11y Cloud Org ID and Access Token. Lastly set up the add-on to ingest metrics from O11y cloud using the following settings, and any other settings left at default:\\\n* Name sim_npm_metrics_to_metrics_index \\\n* Org ID <Your O11y Cloud Org Id> \\\n* Signal Flow Program data('tcp.packets').publish(label='A'); data('tcp.bytes').publish(label='B'); data('tcp.new_sockets').publish(label='C'); data('udp.packets').publish(label='D'); data('udp.bytes').publish(label='E') \\\n* Metric Resolution 10000", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_newly_seen_udp_edge_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Nginx Ingress LFI", "author": "Patrick Bareiss, Splunk", "date": "2024-03-19", "version": 2, "id": "0f83244b-425b-4528-83db-7a88c5f66e48", "description": "This search uses the Kubernetes logs from a nginx ingress controller to detect local file inclusion attacks.", "tags": {"name": "Kubernetes Nginx Ingress LFI", "analytic_story": ["Dev Sec Ops"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1212"], "nist": ["DE.CM"], "observable": [{"name": "host", "type": "Hostname", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Local File Inclusion Attack detected on $host$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kubernetes_container_controller` | rex field=_raw \"^(?<remote_addr>\\S+)\\s+-\\s+-\\s+\\[(?<time_local>[^\\]]*)\\]\\s\\\"(?<request>[^\\\"]*)\\\"\\s(?<status>\\S*)\\s(?<body_bytes_sent>\\S*)\\s\\\"(?<http_referer>[^\\\"]*)\\\"\\s\\\"(?<http_user_agent>[^\\\"]*)\\\"\\s(?<request_length>\\S*)\\s(?<request_time>\\S*)\\s\\[(?<proxy_upstream_name>[^\\]]*)\\]\\s\\[(?<proxy_alternative_upstream_name>[^\\]]*)\\]\\s(?<upstream_addr>\\S*)\\s(?<upstream_response_length>\\S*)\\s(?<upstream_response_time>\\S*)\\s(?<upstream_status>\\S*)\\s(?<req_id>\\S*)\" | lookup local_file_inclusion_paths local_file_inclusion_paths AS request OUTPUT lfi_path | search lfi_path=yes | rename remote_addr AS src_ip, upstream_status as status, proxy_upstream_name as proxy | rex field=request \"^(?<http_method>\\S+)\\s(?<url>\\S+)\\s\" | eval phase=\"operate\" | eval severity=\"high\" | stats count min(_time) as firstTime max(_time) as lastTime by src_ip, status, url, http_method, host, http_user_agent, proxy, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `kubernetes_nginx_ingress_lfi_filter`", "how_to_implement": "You must ingest Kubernetes logs through Splunk Connect for Kubernetes.", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/splunk/splunk-connect-for-kubernetes", "https://www.offensive-security.com/metasploit-unleashed/file-inclusion-vulnerabilities/"], "datamodel": [], "macros": [{"name": "kubernetes_container_controller", "definition": "sourcetype=kube:container:controller", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "kubernetes_nginx_ingress_lfi_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "local_file_inclusion_paths", "description": "A list of interesting files in a local file inclusion attack", "filename": "local_file_inclusion_paths.csv", "default_match": "false", "match_type": "WILDCARD(local_file_inclusion_paths)", "min_matches": 1, "case_sensitive_match": "false", "file_path": "/home/jose.costa/splunk/content/lookups/local_file_inclusion_paths.yml"}], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Nginx Ingress LFI:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1212/kubernetes_nginx_lfi_attack/kubernetes_nginx_lfi_attack.log", "source": "kubernetes", "sourcetype": "kube:container:controller"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1212/kubernetes_nginx_lfi_attack/kubernetes_nginx_lfi_attack.log", "source": "kubernetes", "sourcetype": "kube:container:controller"}]}]}, {"name": "Kubernetes Nginx Ingress RFI", "author": "Patrick Bareiss, Splunk", "date": "2024-03-19", "version": 3, "id": "fc5531ae-62fd-4de6-9c36-b4afdae8ca95", "description": "This search uses the Kubernetes logs from a nginx ingress controller to detect remote file inclusion attacks.", "tags": {"name": "Kubernetes Nginx Ingress RFI", "analytic_story": ["Dev Sec Ops"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1212"], "nist": ["DE.CM"], "observable": [{"name": "host", "type": "Hostname", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Remote File Inclusion Attack detected on $host$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kubernetes_container_controller` | rex field=_raw \"^(?<remote_addr>\\S+)\\s+-\\s+-\\s+\\[(?<time_local>[^\\]]*)\\]\\s\\\"(?<request>[^\\\"]*)\\\"\\s(?<status>\\S*)\\s(?<body_bytes_sent>\\S*)\\s\\\"(?<http_referer>[^\\\"]*)\\\"\\s\\\"(?<http_user_agent>[^\\\"]*)\\\"\\s(?<request_length>\\S*)\\s(?<request_time>\\S*)\\s\\[(?<proxy_upstream_name>[^\\]]*)\\]\\s\\[(?<proxy_alternative_upstream_name>[^\\]]*)\\]\\s(?<upstream_addr>\\S*)\\s(?<upstream_response_length>\\S*)\\s(?<upstream_response_time>\\S*)\\s(?<upstream_status>\\S*)\\s(?<req_id>\\S*)\" | rex field=request \"^(?<http_method>\\S+)?\\s(?<url>\\S+)\\s\" | rex field=url \"(?<dest_ip>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\" | search dest_ip=* | rename remote_addr AS src_ip, upstream_status as status, proxy_upstream_name as proxy | eval phase=\"operate\" | eval severity=\"medium\" | stats count min(_time) as firstTime max(_time) as lastTime by src_ip, dest_ip status, url, http_method, host, http_user_agent, proxy, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `kubernetes_nginx_ingress_rfi_filter`", "how_to_implement": "You must ingest Kubernetes logs through Splunk Connect for Kubernetes.", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/splunk/splunk-connect-for-kubernetes", "https://www.invicti.com/blog/web-security/remote-file-inclusion-vulnerability/"], "datamodel": [], "macros": [{"name": "kubernetes_container_controller", "definition": "sourcetype=kube:container:controller", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "kubernetes_nginx_ingress_rfi_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Nginx Ingress RFI:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1212/kuberntest_nginx_rfi_attack/kubernetes_nginx_rfi_attack.log", "source": "kubernetes", "sourcetype": "kube:container:controller"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1212/kuberntest_nginx_rfi_attack/kubernetes_nginx_rfi_attack.log", "source": "kubernetes", "sourcetype": "kube:container:controller"}]}]}, {"name": "Kubernetes Node Port Creation", "author": "Patrick Bareiss, Splunk", "date": "2023-12-13", "version": 1, "id": "d7fc865e-b8a1-4029-a960-cf4403b821b6", "description": "The following analytic detects the creation of a Kubernetes node port service, an action that exposes a service to the external network. It identifies this behavior by monitoring Kubernetes Audit logs for creation of a Node Port service. This behavior is worth identifying for a SOC as it could potentially allow an attacker to access internal services, posing a significant threat to the integrity and security of the Kubernetes infrastructure. The impact of such an attack could be severe, leading to data breaches, service disruptions, or unauthorized access to sensitive information.", "tags": {"name": "Kubernetes Node Port Creation", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes node port creation from user $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` \"objectRef.resource\"=services verb=create requestObject.spec.type=NodePort | fillnull | stats count values(user.groups{}) as user_groups by kind objectRef.name objectRef.namespace objectRef.resource requestObject.kind requestObject.spec.type responseStatus.code sourceIPs{} stage user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_node_port_creation_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_node_port_creation_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Node Port Creation:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kube_audit_create_node_port_service/kube_audit_create_node_port_service.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kube_audit_create_node_port_service/kube_audit_create_node_port_service.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Pod Created in Default Namespace", "author": "Patrick Bareiss, Splunk", "date": "2023-12-19", "version": 1, "id": "3d6b1a81-367b-42d5-a925-6ef90b6b9f1e", "description": "The following analytic detects the creation of pods in the default, kube-system, or kube-public namespaces. It identifies this behavior by monitoring Kubernetes audit logs for pod creation events in these namespaces. This behavior is worth identifying for a SOC as it may indicate an attacker attempting to hide their presence or evade defenses. Only administrators should typically create pods in the kube-system namespace, and the default and kube-public namespaces should not be used in production. The impact of the attack could be significant, as it may indicate a successful cluster breach and ongoing malicious activity.", "tags": {"name": "Kubernetes Pod Created in Default Namespace", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes Pod Created in Default Namespace by $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=pods verb=create objectRef.namespace IN (\"default\", \"kube-system\", \"kube-public\") | fillnull | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_pod_created_in_default_namespace_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_pod_created_in_default_namespace_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Pod Created in Default Namespace:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_privileged_pod/kubernetes_privileged_pod.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_privileged_pod/kubernetes_privileged_pod.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Pod With Host Network Attachment", "author": "Patrick Bareiss, Splunk", "date": "2023-12-14", "version": 1, "id": "cce357cf-43a4-494a-814b-67cea90fe990", "description": "The following analytic detects the creation of a pod with host network attachment in Kubernetes. It identifies this behavior by monitoring Kubernetes Audit logs for the creation or update of pods with host network configuration. This behavior is worth identifying for a SOC as it could potentially allow an attacker to listen to all network traffic on the node and other compute on the network namespace, capturing secrets passed in arguments or connections to escalate their privileges. The impact of such an attack could be severe, leading to unauthorized access to sensitive information, data breaches, and service disruptions.", "tags": {"name": "Kubernetes Pod With Host Network Attachment", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes pod with host network attachment from user $user$.", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` objectRef.resource=pods verb=create OR verb=update requestObject.metadata.annotations.kubectl.kubernetes.io/last-applied-configuration=*\\\"hostNetwork\\\":true* | fillnull | stats count values(user.groups{}) as user_groups by kind objectRef.name objectRef.namespace objectRef.resource requestObject.kind responseStatus.code sourceIPs{} stage user.username userAgent verb requestObject.metadata.annotations.kubectl.kubernetes.io/last-applied-configuration | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_pod_with_host_network_attachment_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_pod_with_host_network_attachment_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Pod With Host Network Attachment:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_privileged_pod/kubernetes_privileged_pod.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_privileged_pod/kubernetes_privileged_pod.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Previously Unseen Container Image Name", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "fea515a4-b1d8-4cd6-80d6-e0d71397b891", "description": "The following analytic identifies containerised workloads that have been created using a previously unseen image. This detection leverages process metrics harvested using an OTEL collector and kubernetes cluster receiver, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection uses the k8s.container.ready metric to compare the container image names seen in the last 1 hour with those seen in the 30 days prior to those 1 hour, and alerts if a new container image is detected. When a container in a Kubernetes cluster created using a previously unseen image it raises potential security risks and unknown variables. Unfamiliar container images could contain vulnerabilities, malware, or misconfigurations that pose threats to the cluster's integrity and the applications it hosts. The absence of prior knowledge about the image makes it difficult to assess its trustworthiness, track its lineage, or verify its compliance with security policies. The potential security impact of a container created using a compromised image is significant. Compromised containers can potentially introduce malware, backdoors, or other malicious code into the containerized application, leading to data breaches, service disruptions, and unauthorized access within the Kubernetes cluster. A compromised image can serve as a foothold for lateral movement and privilege escalation, potentially compromising other containers, pods, or nodes in the cluster. Additionally, it may enable the actor to exfiltrate sensitive data, manipulate configurations, or execute arbitrary code, posing risks to the confidentiality, availability, and integrity of applications and data hosted within the cluster", "tags": {"name": "Kubernetes Previously Unseen Container Image Name", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Previously Unseen Container Image Name on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats  count(k8s.container.ready) as k8s.container.ready_count where `kubernetes_metrics` AND earliest=-24h by host.name k8s.cluster.name k8s.node.name container.image.name | eval current=\"True\" | append [mstats  count(k8s.container.ready) as k8s.container.ready_count where `kubernetes_metrics` AND earliest=-30d latest=-1h  by host.name k8s.cluster.name k8s.node.name container.image.name | eval current=\"false\" ] | stats values(current) as current by host.name k8s.cluster.name k8s.node.name container.image.name | search current=\"true\" AND current!=\"false\" | rename host.name as host | `kubernetes_previously_unseen_container_image_name_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_previously_unseen_container_image_name_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Previously Unseen Process", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "c8119b2f-d7f7-40be-940a-1c582870e8e2", "description": "This analytic detects newly seen process within the Kubernetes scope on a master or worker node. This detection leverages process metrics harvested using an OTEL collector and hostmetrics receiever, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection compares the processes seen for each node over the previous 1 hour with those over the previous 30 days up until the previous 1 hour. The specific metric used by this detection is process.memory.utilization. Newly seen processes on a Kubernetes worker node are concerning as they may represent security risks and anomalies that could be related to unauthorized activity. New processes may be introduced  in an attempt to compromise the node or gain control of the Kubernetes cluster. By detecting these processes, they can be investigated, and correlated with other anomalous activity for that host. Newly seen processes may be part of an attacker's strategy to compromise the node, gain unauthorized access, and subsequently extend their control to the entire Kubernetes cluster. These processes could facilitate activities such as data exfiltration, privilege escalation, denial-of-service attacks, or the introduction of malware and backdoors, putting sensitive data, applications, and the entire infrastructure at risk. The consequences may include data breaches, service disruptions, financial losses, and reputational damage, underscoring the need to identify anomalous process and associate them with any concurrent risk activity.", "tags": {"name": "Kubernetes Previously Unseen Process", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Previously Unseen Process on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats  count(process.memory.utilization) as process.memory.utilization_count where `kubernetes_metrics` AND earliest=-1h by host.name k8s.cluster.name k8s.node.name process.executable.name | eval current=\"True\" | append [mstats  count(process.memory.utilization) as process.memory.utilization_count where `kubernetes_metrics` AND earliest=-30d latest=-1h by host.name k8s.cluster.name k8s.node.name process.executable.name ] | stats count values(current) as current by host.name k8s.cluster.name k8s.node.name process.executable.name | where count=1 and current=\"True\" | rename host.name as host | `kubernetes_previously_unseen_process_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_previously_unseen_process_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Process Running From New Path", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "454076fb-0e9e-4adf-b93a-da132621c5e6", "description": "This analytic detects processes running within the same scope as Kubernetes that have been run from a newly seen path. This detection leverages process metrics harvested using an OTEL collector and hostmetrics receiever, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection compares the processes seen for each node over the previous 1 hour with those over the previous 30 days up until the previous 1 hour, and alerts if the path for that process was not seen over the previous 30 days. The specific metric used by this detection is process.memory.utilization. Processes running from a newly seen path can signify potential security risks and anomalies. A process executing from an unfamiliar file path may indicate unauthorized changes to the file system, a compromised node, or the introduction of malicious software. If the presence of a process running from a newly seen file path on a Kubernetes node indicates malicious activity, the security implications could be severe. It suggests that an attacker has potentially compromised the node, allowing them to execute unauthorized processes and potentially gain control over critical resources. This could lead to further exploitation, data exfiltration, privilege escalation, or the introduction of malware and backdoors within the Kubernetes cluster.", "tags": {"name": "Kubernetes Process Running From New Path", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Process Running From New Path on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats count(process.memory.utilization) as process.memory.utilization_count where `kubernetes_metrics` AND earliest=-1h by host.name k8s.cluster.name k8s.node.name process.pid process.executable.path process.executable.name | eval current=\"True\" | append [ mstats count(process.memory.utilization) as process.memory.utilization_count where `kubernetes_metrics` AND earliest=-30d latest=-1h by host.name k8s.cluster.name k8s.node.name process.pid process.executable.path process.executable.name ] | stats count values(current) as current by host.name k8s.cluster.name k8s.node.name process.pid process.executable.name process.executable.path | where count=1 and current=\"True\" | rename host.name as host | `kubernetes_process_running_from_new_path_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_process_running_from_new_path_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Process with Anomalous Resource Utilisation", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "25ca9594-7a0d-4a95-a5e5-3228d7398ec8", "description": "This analytic identifies high resource utilization anomalies in Kubernetes processes. It uses process metrics from an OTEL collector and hostmetrics receiver, fetched from Splunk Observability cloud via the Splunk Infrastructure Monitoring Add-on. The detection uses a lookup table with average and standard deviation values for various process metrics to identify anomalies. High resource utilization can indicate security threats or operational issues, such as cryptojacking, unauthorized data exfiltration, or compromised containers. These anomalies can disrupt services, exhaust resources, increase costs, and allow attackers to evade detection or maintain access.", "tags": {"name": "Kubernetes Process with Anomalous Resource Utilisation", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Process with Anomalous Resource Utilisation on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(process.*) as process.* where `kubernetes_metrics` by host.name k8s.cluster.name k8s.node.name process.executable.name span=10s | eval key = 'k8s.cluster.name' + \":\" + 'host.name' + \":\" + 'process.executable.name' | lookup k8s_process_resource_baseline key | fillnull | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 4 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | eval anomalies = replace(anomalies, \",\\s$\", \"\") | where anomalies!=\"\" | stats count values(anomalies) as anomalies by host.name k8s.cluster.name k8s.node.name process.executable.name | sort - count | where count > 5 | rename host.name as host | `kubernetes_process_with_anomalous_resource_utilisation_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_process_with_anomalous_resource_utilisation_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "k8s_process_resource_baseline", "description": "A place holder for a list of used Kuberntes Process Resource", "collection": "k8s_process_resource_baseline", "fields_list": "host.name, k8s.cluster.name, k8s.node.name, process.executable.name, avg_process.cpu.time, avg_process.cpu.utilization, avg_process.disk.io, avg_process.disk.operations, avg_process.memory.usage, avg_process.memory.utilization, avg_process.memory.virtual, avg_process.threads, stdev_process.cpu.time, stdev_process.cpu.utilization, stdev_process.disk.io, stdev_process.disk.operations, stdev_process.memory.usage, stdev_process.memory.utilization, stdev_process.memory.virtual, stdev_process.threads, key", "file_path": "/home/jose.costa/splunk/content/lookups/k8s_process_resource_baseline.yml"}], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Process with Resource Ratio Anomalies", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "0d42b295-0f1f-4183-b75e-377975f47c65", "description": "This analytic detects anomalously changes in the ratio between specific process resources on a Kubernetes node, based on the past behavior for each process running in the Kubernetes scope on that node. This detection leverages process metrics harvested using an OTEL collector and hostmetrics receiver, and is pulled from Splunk Observability cloud using the Splunk Infrastructure Monitoring Add-on. (https://splunkbase.splunk.com/app/5247). This detection also leverages a lookup table that contains average and standard deviation for the cpu:disk operations, cpu:mem, cpu:thread count, disk operations:thread count, and mem:disk operations ratios. This is used to indicate an anomalous change in resource ratios that indicate the workload has changed behavior irrespective of load. Changes in the relationship between utilization of different resources can indicate a change in behavior of the monitored process, which can indicate a potentially compromised application. Deviations in resource ratios, such as memory-to-CPU or CPU-to-disk utilization, may signify compromised processes, malicious activity, or misconfigurations that could pose risks. A change in process behavior could signify a potential security breach within the Kubernetes environment, where an attacker may have compromised a process either on the node or running within a container.", "tags": {"name": "Kubernetes Process with Resource Ratio Anomalies", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Process with Resource Ratio Anomalies on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(process.*) as process.* where `kubernetes_metrics` by host.name k8s.cluster.name k8s.node.name process.executable.name span=10s | eval cpu:mem = 'process.cpu.utilization'/'process.memory.utilization' | eval cpu:disk = 'process.cpu.utilization'/'process.disk.operations' | eval mem:disk = 'process.memory.utilization'/'process.disk.operations' | eval cpu:threads = 'process.cpu.utilization'/'process.threads' | eval disk:threads = 'process.disk.operations'/'process.threads' | eval key = 'k8s.cluster.name' + \":\" + 'host.name' + \":\" + 'process.executable.name' | lookup k8s_process_resource_ratio_baseline key | fillnull | eval anomalies = \"\" | foreach stdev_* [ eval anomalies =if( '<<MATCHSTR>>' > ('avg_<<MATCHSTR>>' + 4 * 'stdev_<<MATCHSTR>>'), anomalies + \"<<MATCHSTR>> ratio higher than average by \" + tostring(round(('<<MATCHSTR>>' - 'avg_<<MATCHSTR>>')/'stdev_<<MATCHSTR>>' ,2)) + \" Standard Deviations. <<MATCHSTR>>=\" + tostring('<<MATCHSTR>>') + \" avg_<<MATCHSTR>>=\" + tostring('avg_<<MATCHSTR>>') + \" 'stdev_<<MATCHSTR>>'=\" + tostring('stdev_<<MATCHSTR>>') + \", \" , anomalies) ] | eval anomalies = replace(anomalies, \",\\s$\", \"\") | where anomalies!=\"\" | stats count values(anomalies) as anomalies by host.name k8s.cluster.name k8s.node.name process.executable.name | where count > 5 | rename host.name as host | `kubernetes_process_with_resource_ratio_anomalies_filter`", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_process_with_resource_ratio_anomalies_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [{"name": "k8s_process_resource_ratio_baseline", "description": "A place holder for a list of used Kuberntes Process Ratios", "collection": "k8s_process_resource_ratio_baseline", "fields_list": "key, avg_cpu:mem, stdev_cpu:mem, avg_cpu:disk, stdev_cpu:disk, avg_mem:disk, stdev_mem:disk, avg_cpu:threads, stdev_cpu:threads, avg_disk:threads, avg_disk:threads, count, last_seen", "file_path": "/home/jose.costa/splunk/content/lookups/k8s_process_resource_ratio_baseline.yml"}], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Scanner Image Pulling", "author": "Patrick Bareiss, Splunk", "date": "2021-08-24", "version": 1, "id": "4890cd6b-0112-4974-a272-c5c153aee551", "description": "This search uses the Kubernetes logs from Splunk Connect from Kubernetes to detect Kubernetes Security Scanner.", "tags": {"name": "Kubernetes Scanner Image Pulling", "analytic_story": ["Dev Sec Ops"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.CM"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes Scanner image pulled on host $host$", "risk_score": 81, "security_domain": "network", "risk_severity": "high", "mitre_attack_enrichments": []}, "search": "`kube_objects_events` object.message IN (\"Pulling image *kube-hunter*\", \"Pulling image *kube-bench*\", \"Pulling image *kube-recon*\", \"Pulling image *kube-recon*\") | rename object.* AS * | rename involvedObject.* AS * | rename source.host AS host | eval phase=\"operate\" | eval severity=\"high\" | stats min(_time) as firstTime max(_time) as lastTime count by host, name, namespace, kind, reason, message, phase, severity | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `kubernetes_scanner_image_pulling_filter`", "how_to_implement": "You must ingest Kubernetes logs through Splunk Connect for Kubernetes.", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/splunk/splunk-connect-for-kubernetes"], "datamodel": [], "macros": [{"name": "kube_objects_events", "definition": "sourcetype=kube:objects:events", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "kubernetes_scanner_image_pulling_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Scanner Image Pulling:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1526/kubernetes_kube_hunter/kubernetes_kube_hunter.json", "source": "kubernetes", "sourcetype": "kube:objects:events"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1526/kubernetes_kube_hunter/kubernetes_kube_hunter.json", "source": "kubernetes", "sourcetype": "kube:objects:events"}]}]}, {"name": "Kubernetes Scanning by Unauthenticated IP Address", "author": "Patrick Bareiss, Splunk", "date": "2023-12-07", "version": 1, "id": "f9cadf4e-df22-4f4e-a08f-9d3344c2165d", "description": "This detection rule is designed to identify potential scanning activities within a Kubernetes environment. Scanning is a common preliminary step in an attack, where the attacker tries to gather information about the system to find potential vulnerabilities. In the context of Kubernetes, scanning could involve activities like unauthorized access attempts, probing public APIs, or trying to exploit known vulnerabilities. This rule triggers an alert when such suspicious activities are detected, helping to ensure the security of your Kubernetes infrastructure.", "tags": {"name": "Kubernetes Scanning by Unauthenticated IP Address", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1046"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Kubernetes scanning from ip $src_ip$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` \"user.groups{}\"=\"system:unauthenticated\" \"responseStatus.code\"=403 | iplocation sourceIPs{} | stats count values(userAgent) as userAgent values(user.username) as user.username values(user.groups{}) as user.groups{} values(verb) as verb values(requestURI) as requestURI values(responseStatus.code) as responseStatus.code values(responseStatus.message) as responseStatus.message values(responseStatus.reason) as responseStatus.reason values(responseStatus.status) as responseStatus.status by sourceIPs{} Country City | where count > 5 | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_scanning_by_unauthenticated_ip_address_filter` ", "how_to_implement": "You must ingest Kubernetes audit logs.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_scanning_by_unauthenticated_ip_address_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Scanning by Unauthenticated IP Address:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1046/kubernetes_scanning/kubernetes_scanning.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1046/kubernetes_scanning/kubernetes_scanning.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Shell Running on Worker Node", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "efebf0c4-dcf4-496f-85a2-5ab7ad8fa876", "description": "This analytic identifies shell activity within the Kubernetes privilege scope on a worker node, returning a list of shell processes regardless of CPU resource consumption. It uses process metrics from an OTEL collector hostmetrics receiver, pulled from Splunk Observability cloud via the Splunk Infrastructure Monitoring Add-on. Metrics used are process.cpu.utilization and process.memory.utilization. Shell processes can indicate unauthorized or suspicious activity, posing a security threat. Shell access to worker nodes can provide attackers an entry point to compromise the node and the entire Kubernetes cluster. Monitoring and detecting shell processes is crucial for anomaly identification, security policy enforcement, and breach mitigation. Unauthorized shell processes on a Kubernetes worker node can severely compromise the cluster's security and integrity. Such access can lead to data theft, service disruption, privilege escalation, lateral movement, and further attacks within the cluster. It may also enable attackers to manipulate configurations, deploy malicious containers, and execute arbitrary code, posing a severe risk to the confidentiality, availability, and integrity of applications and sensitive data.", "tags": {"name": "Kubernetes Shell Running on Worker Node", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes shell running on worker node on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(process.cpu.utilization) as process.cpu.utilization avg(process.memory.utilization) as process.memory.utilization where `kubernetes_metrics` AND process.executable.name IN (\"sh\",\"bash\",\"csh\", \"tcsh\") by host.name k8s.cluster.name k8s.node.name process.pid process.executable.name span=10s | search process.cpu.utilization>0 OR process.memory.utilization>0 | stats avg(process.cpu.utilization) as process.cpu.utilization avg(process.memory.utilization) as process.memory.utilization by host.name k8s.cluster.name k8s.node.name process.pid process.executable.name | rename host.name as host | `kubernetes_shell_running_on_worker_node_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart/tree/main"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_shell_running_on_worker_node_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Shell Running on Worker Node with CPU Activity", "author": "Matthew Moore, Splunk", "date": "2023-12-18", "version": 1, "id": "cc1448e3-cc7a-4518-bc9f-2fa48f61a22b", "description": "This analytic identifies shell activity within the Kubernetes privilege scope on a worker node. It returns shell processes only if they're consuming CPU resources. The detection uses process metrics from an OTEL collector hostmetrics receiver, pulled from Splunk Observability cloud via the Splunk Infrastructure Monitoring Add-on. The metrics used are process.cpu.utilization and process.memory.utilization. Shell processes can indicate unauthorized activity, posing a security threat. Attackers could compromise the node and the entire Kubernetes cluster via shell access to worker nodes. Monitoring shell processes is crucial for anomaly detection, policy enforcement, and breach mitigation. Unauthorized shell processes on a Kubernetes worker node could severely impact the cluster's security and integrity. Attackers could gain full control over the host's resources and file system, compromising all hosted workloads and data. This access could lead to data theft, service disruption, privilege escalation, lateral movement, and further attacks within the cluster. Attackers could also manipulate configurations, deploy malicious containers, and execute arbitrary code, severely risking the confidentiality, availability, and integrity of applications and sensitive data. A rapid and comprehensive incident response is required to mitigate and recover from such a breach.", "tags": {"name": "Kubernetes Shell Running on Worker Node with CPU Activity", "analytic_story": ["Abnormal Kubernetes Behavior using Splunk Infrastructure Monitoring"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "host", "type": "Hostname", "role": ["Attacker"]}], "message": "Kubernetes shell with cpu activity running on worker node on host $host$", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| mstats avg(process.cpu.utilization) as process.cpu.utilization avg(process.memory.utilization) as process.memory.utilization where `kubernetes_metrics` AND process.executable.name IN (\"sh\",\"bash\",\"csh\", \"tcsh\") by host.name k8s.cluster.name k8s.node.name process.pid process.executable.name span=10s | search process.cpu.utilization>0 | stats avg(process.cpu.utilization) as process.cpu.utilization avg(process.memory.utilization) as process.memory.utilization by host.name k8s.cluster.name k8s.node.name process.pid process.executable.name | rename host.name as host | `kubernetes_shell_running_on_worker_node_with_cpu_activity_filter` ", "how_to_implement": "To implement this detection, follow these steps: \\\n* Deploy the OpenTelemetry Collector (OTEL) to your Kubernetes cluster.\\\n* Enable the hostmetrics/process receiver in the OTEL configuration.\\\n* Ensure that the process metrics, specifically Process.cpu.utilization and process.memory.utilization, are enabled.\\\n* Install the Splunk Infrastructure Monitoring (SIM) add-on. (ref: https://splunkbase.splunk.com/app/5247)\\\n* Configure the SIM add-on with your Observability Cloud Organization ID and Access Token.\\\n* Set up the SIM modular input to ingest Process Metrics. Name this input \"sim_process_metrics_to_metrics_index\".\\\n* In the SIM configuration, set the Organization ID to your Observability Cloud Organization ID.\\\n* Set the Signal Flow Program to the following: data('process.threads').publish(label='A'); data('process.cpu.utilization').publish(label='B'); data('process.cpu.time').publish(label='C'); data('process.disk.io').publish(label='D'); data('process.memory.usage').publish(label='E'); data('process.memory.virtual').publish(label='F'); data('process.memory.utilization').publish(label='G'); data('process.cpu.utilization').publish(label='H'); data('process.disk.operations').publish(label='I'); data('process.handles').publish(label='J'); data('process.threads').publish(label='K')\\\n* Set the Metric Resolution to 10000.\\\n* Leave all other settings at their default values.\\\n* Run the Search Baseline Of Kubernetes Container Network IO Ratio ", "known_false_positives": "unknown", "check_references": false, "references": ["https://github.com/signalfx/splunk-otel-collector-chart/tree/main"], "datamodel": [], "macros": [{"name": "kubernetes_metrics", "definition": "index=kubernetes_metrics", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_shell_running_on_worker_node_with_cpu_activity_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": []}, {"name": "Kubernetes Suspicious Image Pulling", "author": "Patrick Bareiss, Splunk", "date": "2023-12-07", "version": 1, "id": "4d3a17b3-0a6d-4ae0-9421-46623a69c122", "description": "The following analytic detects instances of suspicious image pulling in Kubernetes. It identifies this behavior by monitoring Kubernetes audit logs for image pull requests that do not match a predefined list of allowed images. This behavior is worth identifying for a SOC as it could indicate an attacker attempting to deploy malicious software or infiltrate the system. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Suspicious Image Pulling", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1526"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Suspicious image $objectRef.name$ pulled in Kubernetes from ip $src_ip$ by user $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` requestObject.message=\"Pulling image*\" | search NOT `kube_allowed_images` | fillnull | stats count by objectRef.name objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_suspicious_image_pulling_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_allowed_images", "definition": "objectRef.name IN (*splunk*, *falco*)", "description": "Define your images which are allowed to connect to your kubernetes cluster."}, {"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_suspicious_image_pulling_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Suspicious Image Pulling:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1526/kubernetes_audit_pull_image/kubernetes_audit_pull_image.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1526/kubernetes_audit_pull_image/kubernetes_audit_pull_image.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "Kubernetes Unauthorized Access", "author": "Patrick Bareiss, Splunk", "date": "2023-12-07", "version": 1, "id": "9b5f1832-e8b9-453f-93df-07a3d6a72a45", "description": "The following analytic detects unauthorized access to Kubernetes by monitoring Kubernetes audit logs. It identifies anomalies in access patterns by segmenting and analyzing the source of requests. Unauthorized access is worth identifying for a SOC as it could indicate an attacker attempting to infiltrate the system. The impact of such an attack could be severe, potentially leading to unauthorized access to sensitive systems or data.", "tags": {"name": "Kubernetes Unauthorized Access", "analytic_story": ["Kubernetes Security"], "asset_type": "Kubernetes", "cis20": ["CIS 13"], "kill_chain_phases": [], "mitre_attack_id": ["T1204"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Unauthorized access to Kubernetes from user $user$", "risk_score": 49, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`kube_audit` verb=create responseStatus.reason=Forbidden | fillnull | stats count by objectRef.namespace objectRef.resource requestReceivedTimestamp requestURI responseStatus.code responseStatus.message sourceIPs{} stage user.groups{} user.uid user.username userAgent verb | rename sourceIPs{} as src_ip, user.username as user | `kubernetes_unauthorized_access_filter` ", "how_to_implement": "The detection is based on data that originates from Kubernetes Audit logs. Ensure that audit logging is enabled in your Kubernetes cluster. Kubernetes audit logs provide a record of the requests made to the Kubernetes API server, which is crucial for monitoring and detecting suspicious activities. Configure the audit policy in Kubernetes to determine what kind of activities are logged. This is done by creating an Audit Policy and providing it to the API server. Use the Splunk OpenTelemetry Collector for Kubernetes to collect the logs. This doc will describe how to collect the audit log file https://github.com/signalfx/splunk-otel-collector-chart/blob/main/docs/migration-from-sck.md.", "known_false_positives": "unknown", "check_references": false, "references": ["https://kubernetes.io/docs/tasks/debug/debug-cluster/audit/"], "datamodel": [], "macros": [{"name": "kube_audit", "definition": "source=\"kubernetes\"", "description": "customer specific splunk configurations(eg- index, source, sourcetype) for Kubernetes audit data. Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "kubernetes_unauthorized_access_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Kubernetes"], "enabled_by_default": false, "test_groups": [{"name": "Kubernetes Unauthorized Access:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_unauthorized_access/kubernetes_unauthorized_access.json", "source": "kubernetes", "sourcetype": "_json"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1204/kubernetes_unauthorized_access/kubernetes_unauthorized_access.json", "source": "kubernetes", "sourcetype": "_json"}]}]}, {"name": "O365 Add App Role Assignment Grant User", "author": "Rod Soto, Splunk", "date": "2023-07-11", "version": 2, "id": "b2c81cc6-6040-11eb-ae93-0242ac130002", "description": "This search is designed to detect the creation of a new Federation setting by alerting on a specific event associated with its creation. By monitoring for this event, the search can identify any instances where a Federation setting is being created within the system. This can help in detecting and monitoring any unauthorized or suspicious changes to the Federation settings, providing an additional layer of security for your environment.", "tags": {"name": "O365 Add App Role Assignment Grant User", "analytic_story": ["Office 365 Persistence Mechanisms", "Cloud Federated Credential Abuse"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003", "T1136"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "dest", "type": "Endpoint", "role": ["Victim"]}], "message": "User $user$ has created a new federation setting $modified_properties_name$ on $dest$", "risk_score": 18, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Add app role assignment grant to user.\" | stats count min(_time) as firstTime max(_time) as lastTime values(Actor{}.ID) as Actor.ID values(Actor{}.Type) as Actor.Type values(ModifiedProperties{}.Name) as modified_properties_name by user dest ResultStatus Operation | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_add_app_role_assignment_grant_user_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "The creation of a new Federation is not necessarily malicious, however this events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a different cloud provider.", "check_references": false, "references": ["https://www.fireeye.com/content/dam/fireeye-www/blog/pdfs/wp-m-unc2452-2021-000343-01.pdf", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_add_app_role_assignment_grant_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Add App Role Assignment Grant User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_new_federation/o365_new_federation.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_new_federation/o365_new_federation.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Added Service Principal", "author": "Rod Soto, Splunk", "date": "2023-08-02", "version": 3, "id": "1668812a-6047-11eb-ae93-0242ac130002", "description": "The following analytic detects addition of new service principal accounts added to O365 tenants. Attackers can abuse service principals in Office 365 (now known as Microsoft 365) to gain unauthorized access and perform malicious actions within an organization's environment. Service principals are essentially non-human accounts used by applications, services, or scripts to access resources and interact with APIs on behalf of the organization.", "tags": {"name": "O365 Added Service Principal", "analytic_story": ["Office 365 Persistence Mechanisms", "Cloud Federated Credential Abuse", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003", "T1136"], "nist": ["DE.CM"], "observable": [{"name": "src_user", "type": "User", "role": ["Victim"]}], "message": "User $src_user$ has created new service principal $new_value$ in AzureActiveDirectory", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"*Add service principal*\" OR (Operation = \"*principal*\" AND action = \"created\") | stats count values(ModifiedProperties{}.NewValue) as new_value by src_user src_user_type action Operation authentication_service Workload | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_added_service_principal_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "The creation of a new Federation is not necessarily malicious, however these events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a different cloud provider.", "check_references": false, "references": ["https://www.fireeye.com/content/dam/fireeye-www/blog/pdfs/wp-m-unc2452-2021-000343-01.pdf", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://www.splunk.com/en_us/blog/security/a-golden-saml-journey-solarwinds-continued.html", "https://blog.sygnia.co/detection-and-hunting-of-golden-saml-attack?hsLang=en"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_added_service_principal_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Added Service Principal:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_added_service_principal/o365_add_service_principal.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_added_service_principal/o365_add_service_principal.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Admin Consent Bypassed by Service Principal", "author": "Mauricio Velazco, Splunk", "date": "2024-02-09", "version": 1, "id": "8a1b22eb-50ce-4e26-a691-97ff52349569", "description": "This detection targets situations where a service principal in Office 365 Azure Active Directory assigns app roles without the standard admin consent, a potential security breach. Using o365_management_activity logs, it examines the 'Add app role assignment to service principal' operation, focusing on service principals and extracting details like role ID and description. This is critical for SOCs to detect potential bypassing of crucial administrative controls, which could lead to unauthorized access or privilege escalation. A true positive implies a service principal might be misusing automated processes to assign sensitive permissions.", "tags": {"name": "O365 Admin Consent Bypassed by Service Principal", "analytic_story": ["Office 365 Persistence Mechanisms"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1003.002"], "nist": ["DE.CM"], "observable": [{"name": "src_user", "type": "User", "role": ["Attacker"]}], "message": "Service principal $src_user$ bypassed the admin consent process and granted permissions to $dest_user$", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Add app role assignment to service principal.\" | eval len=mvcount('Actor{}.ID') | eval userType = mvindex('Actor{}.ID',len-1) | eval roleId = mvindex('ModifiedProperties{}.NewValue', 0) | eval roleValue = mvindex('ModifiedProperties{}.NewValue', 1) | eval roleDescription = mvindex('ModifiedProperties{}.NewValue', 2) | eval dest_user = mvindex('Target{}.ID', 0) | search userType = \"ServicePrincipal\" | eval src_user = user | stats count earliest(_time) as firstTime latest(_time) as lastTime by src_user dest_user roleId roleValue roleDescription | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)`  | `o365_admin_consent_bypassed_by_service_principal_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Service Principals are sometimes configured to legitimately bypass the consent process for purposes of automation. Filter as needed.", "check_references": false, "references": ["REFERENCE"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_admin_consent_bypassed_by_service_principal_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Admin Consent Bypassed by Service Principal:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_bypass_admin_consent/o365_bypass_admin_consent.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_bypass_admin_consent/o365_bypass_admin_consent.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Advanced Audit Disabled", "author": "Mauricio Velazco, Michael Haag, Splunk", "date": "2023-09-19", "version": 1, "id": "49862dd4-9cb2-4c48-a542-8c8a588d9361", "description": "The following analytic identifies instances where the O365 advanced audit is disabled for a specific user within the Office 365 tenant. It leverages O365 audit logs, specifically events related to audit license changes or modifications within the AzureActiveDirectory workloads. The O365 advanced audit provides granular logging and insights into user and administrator activities, making it a crucial tool for security monitoring and incident response. Disabling this audit for a user can blind security teams to potential malicious or unauthorized activities related to that user's mailbox or account. Attackers may disable these audits to obscure their actions and reduce the chances of detection. If an attacker successfully disables the O365 advanced audit for a user, they can operate within that user's mailbox or account with reduced risk of detection. This can lead to unauthorized data access, data exfiltration, account compromise, or other malicious activities without leaving a detailed audit trail.", "tags": {"name": "O365 Advanced Audit Disabled", "analytic_story": ["Office 365 Persistence Mechanisms"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562", "T1562.008"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Advanced auditing for user $object$ was disabled by $user$", "risk_score": 32, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=\"Change user license.\"  | eval property_name = mvindex ('ExtendedProperties{}.Name', 1) | search property_name = \"extendedAuditEventCategory\" | eval additionalDetails = mvindex('ExtendedProperties{}.Value',0) | eval split_value=split(additionalDetails, \"NewValue\") | eval possible_plan=mvindex(split_value, 1)  | rex field=\"possible_plan\" \"DisabledPlans=\\[(?P<DisabledPlans>[^\\]]+)\\]\" | search DisabledPlans IN (\"*M365_ADVANCED_AUDITING*\") | stats min(_time) as firstTime max(_time) as lastTime by Operation user object DisabledPlans | `security_content_ctime(firstTime)`  | `security_content_ctime(lastTime)` | `o365_advanced_audit_disabled_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Administrators might temporarily disable the advanced audit for troubleshooting, performance reasons, or other administrative tasks. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/008/", "https://www.mandiant.com/sites/default/files/2022-08/remediation-hardening-strategies-for-m365-defend-against-apt29-white-paper.pdf", "https://www.csoonline.com/article/570381/microsoft-365-advanced-audit-what-you-need-to-know.html"], "datamodel": ["Change"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_advanced_audit_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Advanced Audit Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/o365_advanced_audit_disabled/o365_advanced_audit_disabled.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.008/o365_advanced_audit_disabled/o365_advanced_audit_disabled.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Application Registration Owner Added", "author": "Mauricio Velazco, Splunk", "date": "2023-09-07", "version": 1, "id": "c068d53f-6aaa-4558-8011-3734df878266", "description": "The following analytic identifies instances where a new owner is assigned to an application registration within an Azure AD and Office 365 tenant. It leverages O365 audit logs, specifically events related to changes in owner assignments within the AzureActiveDirectory workload for application registrations. Assigning a new owner to an application registration can grant significant control over the application's configuration, permissions, and behavior. An unauthorized or inadvertent change in ownership can lead to misuse of the application, potentially affecting data access, user permissions, or the application's interactions within the tenant. Monitoring for such changes ensures that only legitimate and authorized personnel have control over application registrations. If an attacker successfully assigns themselves or a compromised account as an owner to an application registration, they can modify the application's settings, permissions, and behavior. This can lead to unauthorized data access, escalation of privileges, or the introduction of malicious behavior within the application's operations", "tags": {"name": "O365 Application Registration Owner Added", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Application registration $app_displayName$ was assigned a new owner $object$", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "atomic_guid": [], "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Add owner to application.\" | eval app_id=mvindex('ModifiedProperties{}.NewValue', 0) | eval app_displayName=mvindex('ModifiedProperties{}.NewValue', 1) | stats max(_time) as lastTime values(ModifiedProperties{}.NewValue) by Operation, user, app_displayName, object | `security_content_ctime(lastTime)` | `o365_application_registration_owner_added_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Application owners may be added for legitimate reasons, filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/overview-assign-app-owners"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_application_registration_owner_added_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Application Registration Owner Added:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/o365_add_app_registration_owner/o365_add_app_registration_owner.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098/o365_add_app_registration_owner/o365_add_app_registration_owner.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 ApplicationImpersonation Role Assigned", "author": "Mauricio Velazco, Splunk", "date": "2023-10-17", "version": 1, "id": "49cdce75-f814-4d56-a7a4-c64ec3a481f2", "description": "The following analytic identifies the assignment of the ApplicationImpersonation role in Office 365, either to a user or an application. This analytic leverages the Office 365 Management Activity API, specifically monitoring for events related to role assignments and changes within the Azure Active Directory audit logs. The ApplicationImpersonation role allows a security principal to impersonate any user within the organization and perform actions on their behalf, such as accessing or modifying their mailbox. This role, if misused or granted inappropriately, can pose a significant security risk. Monitoring the assignment of this role is crucial as it can be an indicator of potential malicious activity or misconfigurations. If an attacker successfully assigns the ApplicationImpersonation role to a malicious user or application, they can gain the ability to impersonate any user within the organization. This can lead to unauthorized access to sensitive information, manipulation of mailbox data, and other malicious actions. The attacker can effectively masquerade as a legitimate user, making their actions harder to detect and potentially causing significant harm to the organization.", "tags": {"name": "O365 ApplicationImpersonation Role Assigned", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "$user$ granted the ApplicationImpersonation role to $target_user$", "risk_score": 56, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=Exchange Operation=\"New-ManagementRoleAssignment\"  Role=ApplicationImpersonation |  rename User as target_user | stats  max(_time) as lastTime by Operation, user, object, ObjectId, Role, target_user | `security_content_ctime(lastTime)` | `o365_applicationimpersonation_role_assigned_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "While infrequent, the ApplicationImpersonation role may be granted for leigimate reasons, filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/002/", "https://www.mandiant.com/resources/blog/remediation-and-hardening-strategies-for-microsoft-365-to-defend-against-unc2452", "https://www.mandiant.com/media/17656"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_applicationimpersonation_role_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 ApplicationImpersonation Role Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.002/application_impersonation_role_assigned/application_impersonation_role_assigned.log", "source": "O365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.002/application_impersonation_role_assigned/application_impersonation_role_assigned.log", "source": "O365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Block User Consent For Risky Apps Disabled", "author": "Mauricio Velazco, Splunk", "date": "2023-10-26", "version": 1, "id": "12a23592-e3da-4344-8545-205d3290647c", "description": "This analytic detects when the \"risk-based step-up consent\" security setting in Microsoft 365 is disabled. This setting, when enabled, prevents regular users from granting consent to potentially malicious OAuth applications, requiring an administrative \"step-up\" for consent instead. Disabling this feature could expose the organization to OAuth phishing threats.The detection operates by monitoring Azure Active Directory logs for events where the \"Update authorization policy\" operation is performed. It specifically looks for changes to the \"AllowUserConsentForRiskyApps\" setting, identifying instances where this setting is switched to \"true,\" effectively disabling the risk-based step-up consent. Monitoring for changes to critical security settings like the \"risk-based step-up consent\" is vital for maintaining the integrity of an organization's security posture. Disabling this feature can make the environment more susceptible to OAuth phishing attacks, where attackers trick users into granting permissions to malicious applications. Identifying when this setting is disabled can help blue teams to quickly respond, investigate, and potentially uncover targeted phishing campaigns against their users. If an attacker successfully disables the \"risk-based step-up consent\" and subsequently launches an OAuth phishing campaign, they could gain unauthorized access to user data and other sensitive information within the M365 environment. This could lead to data breaches, unauthorized access to emails, and potentially further compromise within the organization.", "tags": {"name": "O365 Block User Consent For Risky Apps Disabled", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "O365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Risk-based step-up consent security setting was disabled by $user$", "risk_score": 30, "security_domain": "audit", "risk_severity": "low", "atomic_guid": [], "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Update authorization policy.\" | eval index_number = if(mvfind('ModifiedProperties{}.Name', \"AllowUserConsentForRiskyApps\") >= 0, mvfind('ModifiedProperties{}.Name', \"AllowUserConsentForRiskyApps\"), -1) | search index_number >= 0  | eval AllowUserConsentForRiskyApps = mvindex('ModifiedProperties{}.NewValue',index_number) | where AllowUserConsentForRiskyApps like \"%true%\" | stats count min(_time) as firstTime max(_time) as lastTime by user, Operation, AllowUserConsentForRiskyApps, user_agent | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_block_user_consent_for_risky_apps_disabled_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Legitimate changes to the 'risk-based step-up consent' setting by administrators, perhaps as part of a policy update or security assessment, may trigger this alert, necessitating verification of the change's intent and authorization.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1562/", "https://goodworkaround.com/2020/10/19/a-look-behind-the-azure-ad-permission-classifications-preview/", "https://learn.microsoft.com/en-us/entra/identity/enterprise-apps/configure-risk-based-step-up-consent", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth"], "datamodel": ["Risk"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_block_user_consent_for_risky_apps_disabled_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Block User Consent For Risky Apps Disabled:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562/o365_disable_blockconsent_for_riskapps/o365_disable_blockconsent_for_riskapps.log", "source": "O365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562/o365_disable_blockconsent_for_riskapps/o365_disable_blockconsent_for_riskapps.log", "source": "O365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Bypass MFA via Trusted IP", "author": "Bhavin Patel, Mauricio Velazco, Splunk", "date": "2022-02-03", "version": 3, "id": "c783dd98-c703-4252-9e8a-f19d9f66949e", "description": "This analytic identifies instances where new IP addresses are added to the trusted IPs list in Office 365, potentially allowing users from these IPs to bypass Multi-Factor Authentication (MFA) during login. The detection leverages O365 audit logs, specifically focusing on events related to the modification of trusted IP settings. By monitoring these logs, the analytic captures and alerts on any addition of new trusted IPs. Adding trusted IPs to bypass MFA is a significant security concern. While there might be legitimate reasons to add trusted IPs, such as for a new office location, there's also a risk of attackers or malicious insiders using this to facilitate unauthorized access. Monitoring for changes to the trusted IP list helps ensure that any attempt to bypass MFA is legitimate and authorized. If the detection is a true positive, it suggests that users logging in from the newly added trusted IP can bypass MFA, potentially weakening the security posture of the organization. This could lead to unauthorized access, especially if the IP was added maliciously. Immediate investigation is required to validate the legitimacy of the IP addition and to assess potential security implications.", "tags": {"name": "O365 Bypass MFA via Trusted IP", "analytic_story": ["Office 365 Persistence Mechanisms"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1562.007", "T1562"], "nist": ["DE.CM"], "observable": [{"name": "ip_addresses_new_added", "type": "IP Address", "role": ["Attacker"]}, {"name": "user_id", "type": "User", "role": ["Attacker"]}], "message": "User $user_id$ has added new IP addresses $ip_addresses_new_added$ to a list of trusted IPs to bypass MFA", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=\"Set Company Information.\" ModifiedProperties{}.Name=StrongAuthenticationPolicy | rex max_match=100 field=ModifiedProperties{}.NewValue \"(?<ip_addresses_new_added>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\/\\d{1,2})\" | rex max_match=100 field=ModifiedProperties{}.OldValue \"(?<ip_addresses_old>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\/\\d{1,2})\" | eval ip_addresses_old=if(isnotnull(ip_addresses_old),ip_addresses_old,\"0\") | mvexpand ip_addresses_new_added | where isnull(mvfind(ip_addresses_old,ip_addresses_new_added)) |stats count min(_time) as firstTime max(_time) as lastTime values(ip_addresses_old) as ip_addresses_old by user ip_addresses_new_added Operation Workload vendor_account status user_id action | `security_content_ctime(firstTime)`| `security_content_ctime(lastTime)`| `o365_bypass_mfa_via_trusted_ip_filter`", "how_to_implement": "You must install Splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "Unless it is a special case, it is uncommon to continually update Trusted IPs to MFA configuration.", "check_references": false, "references": ["https://i.blackhat.com/USA-20/Thursday/us-20-Bienstock-My-Cloud-Is-APTs-Cloud-Investigating-And-Defending-Office-365.pdf", "https://attack.mitre.org/techniques/T1562/007/", "https://learn.microsoft.com/en-us/azure/active-directory/authentication/howto-mfa-mfasettings"], "datamodel": ["Authentication"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_bypass_mfa_via_trusted_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Bypass MFA via Trusted IP:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.007/o365_bypass_mfa_via_trusted_ip/o365_bypass_mfa_via_trusted_ip.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1562.007/o365_bypass_mfa_via_trusted_ip/o365_bypass_mfa_via_trusted_ip.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Concurrent Sessions From Different Ips", "author": "Mauricio Velazco, Splunk", "date": "2023-12-04", "version": 1, "id": "58e034de-1f87-4812-9dc3-a4f68c7db930", "description": "The following analytic identies scenarios where the same user session is accessed from multiple IP addresses. This situation typically arises in an adversary-in-the-middle (AiTM) phishing attack, where attackers compromise user sessions. The detection method involves analyzing Azure Active Directory logs for 'UserLoggedIn' operations. It focuses on identifying sessions where the number of associated IP addresses exceeds one for the same SessionId. This pattern suggests potential unauthorized concurrent access, which is atypical under normal usage scenarios. If a true positive is identified, it implies that an adversary has gained unauthorized access to a user's Office 365 account. The ramifications of this can be significant, including data theft, account takeover, and launching of internal phishing campaigns.", "tags": {"name": "O365 Concurrent Sessions From Different Ips", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "O365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1185"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "ips", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ has logged in with the same session id from more than one unique IP address", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=AzureActiveDirectory  Operation=UserLoggedIn | stats min(_time) as firstTime max(_time) as lastTime values(src_ip) as ips values(user_agent) as user_agents by Operation, user, SessionId | where mvcount(ips) > 1 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_concurrent_sessions_from_different_ips_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "Unknown", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1185/", "https://breakdev.org/evilginx-2-next-generation-of-phishing-2fa-tokens/", "https://github.com/kgretzky/evilginx2"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_concurrent_sessions_from_different_ips_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Concurrent Sessions From Different Ips:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1185/o365_concurrent_sessions_from_different_ips/o365_concurrent_sessions_from_different_ips.log", "source": "o365", "sourcetype": "o365:management:activity", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1185/o365_concurrent_sessions_from_different_ips/o365_concurrent_sessions_from_different_ips.log", "source": "o365", "sourcetype": "o365:management:activity", "update_timestamp": true}]}]}, {"name": "O365 Disable MFA", "author": "Rod Soto, Splunk", "date": "2022-02-03", "version": 2, "id": "c783dd98-c703-4252-9e8a-f19d9f5c949e", "description": "This analytic identifies instances where Multi-Factor Authentication (MFA) is disabled for a user within the Office 365 environment. Disabling MFA removes a critical security layer, making accounts more vulnerable to unauthorized access. The detection leverages O365 audit logs, specifically focusing on events related to MFA settings. By monitoring these logs, the analytic captures and alerts on any actions that result in the deactivation or disabling of MFA for a user. MFA is a cornerstone of modern security practices, providing an additional layer of protection beyond just a password. Disabling MFA, especially without a valid reason, poses a significant security risk. Attackers, after gaining initial access to an account, might disable MFA to ensure easier re-entry and persistence. Monitoring for such changes is crucial to detect potential security breaches and to ensure that security best practices are consistently applied. If the detection is a true positive, it indicates that a user's account is now at increased risk of unauthorized access, as the added security layer of MFA has been removed. This could be a sign of an attacker trying to maintain persistence or an insider threat. Immediate investigation is required to validate the reason for disabling MFA, potentially re-enable it, and assess any other suspicious activities related to the affected account.", "tags": {"name": "O365 Disable MFA", "analytic_story": ["Office 365 Persistence Mechanisms"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1556"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $src_user$ has executed an operation $action$ for user $user$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=\"Disable Strong Authentication.\" | stats count earliest(_time) as firstTime latest(_time) as lastTime by UserType Operation UserId ResultStatus object | rename UserType AS user_type, Operation AS action, UserId AS src_user, object AS user, ResultStatus AS result | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_disable_mfa_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "Unless it is a special case, it is uncommon to disable MFA or Strong Authentication", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1556/"], "datamodel": ["Authentication"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_disable_mfa_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Disable MFA:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/o365_disable_mfa/o365_disable_mfa.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/o365_disable_mfa/o365_disable_mfa.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Excessive Authentication Failures Alert", "author": "Rod Soto, Splunk", "date": "2022-02-18", "version": 2, "id": "d441364c-349c-453b-b55f-12eccab67cf9", "description": "This search detects when an excessive number of authentication failures occur this search also includes attempts against MFA prompt codes", "tags": {"name": "O365 Excessive Authentication Failures Alert", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ has caused excessive number of authentication failures from $src_ip$ using UserAgent $UserAgent$.", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory UserAuthenticationMethod=* status=failure | stats count earliest(_time) AS firstTime latest(_time) AS lastTime values(UserAuthenticationMethod) AS UserAuthenticationMethod values(UserAgent) AS UserAgent values(status) AS status values(src_ip) AS src_ip by user | where count > 10 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_excessive_authentication_failures_alert_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "The threshold for alert is above 10 attempts and this should reduce the number of false positives.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/"], "datamodel": ["Authentication"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_excessive_authentication_failures_alert_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Excessive Authentication Failures Alert:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110/o365_brute_force_login/o365_brute_force_login.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110/o365_brute_force_login/o365_brute_force_login.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Excessive SSO logon errors", "author": "Rod Soto, Splunk", "date": "2023-08-02", "version": 3, "id": "8158ccc4-6038-11eb-ae93-0242ac130002", "description": "The following analytic detects accounts with high number of Single Sign ON (SSO) logon errors. Excessive logon errors may indicate attempts to bruteforce of password or single sign on token hijack or reuse.", "tags": {"name": "O365 Excessive SSO logon errors", "analytic_story": ["Office 365 Account Takeover", "Cloud Federated Credential Abuse"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1556"], "nist": ["DE.AE"], "observable": [{"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}, {"name": "user", "type": "User", "role": ["Victim"]}], "message": "Excessive number of SSO logon errors from $src_ip$ using UserAgent $user_agent$.", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory LogonError=*Sso* Operation=UserLoginFailed | stats count min(_time) as firstTime max(_time) as lastTime values(user) as user by  src_ip signature user_agent authentication_service action| where count >= 5 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_excessive_sso_logon_errors_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "Logon errors may not be malicious in nature however it may indicate attempts to reuse a token or password obtained via credential access attack.", "check_references": false, "references": ["https://stealthbits.com/blog/bypassing-mfa-with-pass-the-cookie/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_excessive_sso_logon_errors_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Excessive SSO logon errors:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/o365_sso_logon_errors/o365_sso_logon_errors2.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1556/o365_sso_logon_errors/o365_sso_logon_errors2.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 File Permissioned Application Consent Granted by User", "author": "Mauricio Velazco, Splunk", "date": "2023-10-18", "version": 1, "id": "6c382336-22b8-4023-9b80-1689e799f21f", "description": "This analytic identifies instances where a user in the Office 365 environment grants consent to an application that requests file permissions, specifically targeting OneDrive or SharePoint. Such permissions mean the application could potentially access, modify, or delete files stored within these services. The detection process leverages O365 audit logs, particularly focusing on events related to OAuth application consents. By examining these logs, the analytic is designed to capture and alert on any actions where users grant consent to applications requesting file-related permissions for OneDrive or SharePoint. The sensitivity of file permissions, especially in platforms as widely utilized as OneDrive and SharePoint, cannot be overstated. While many legitimate applications might require such permissions to operate, there's an inherent risk with malicious or overly permissive applications. Attackers could craft or exploit applications to gain file permissions, aiming to access, exfiltrate, or manipulate sensitive data housed in OneDrive or SharePoint. It's crucial for security operations centers to monitor these consents to ensure that only trustworthy applications gain access and that users aren't inadvertently granting permissions to potentially harmful applications. If this detection flags a true positive, it indicates that an application has been granted permissions that could allow it to interact with OneDrive or SharePoint files in potentially malicious ways. Such actions could lead to data breaches, data loss, or unauthorized data manipulation. Immediate investigation would be required to validate the application's legitimacy, understand the nature of its requested permissions, and assess the potential risks associated with the access it's been granted.", "tags": {"name": "O365 File Permissioned Application Consent Granted by User", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ consented an OAuth application that requests file-related permissions.", "risk_score": 40, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Consent to application.\" ResultStatus=Success | eval admin_consent =mvindex('ModifiedProperties{}.NewValue', 0) | search admin_consent=False | eval permissions =mvindex('ModifiedProperties{}.NewValue', 4) | rex field=permissions \"Scope: (?<Scope>[^,]+)\" | makemv delim=\" \" Scope | search Scope IN (\"Files.Read\", \"Files.Read.All\", \"Files.ReadWrite\", \"Files.ReadWrite.All\", \"Files.ReadWrite.AppFolder\") | stats max(_time) as lastTime values(Scope) by Operation, user, object, ObjectId | `security_content_ctime(lastTime)` | `o365_file_permissioned_application_consent_granted_by_user_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "OAuth applications that require file permissions may be legitimate, investigate and filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_file_permissioned_application_consent_granted_by_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 File Permissioned Application Consent Granted by User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_file_permissions/o365_user_consent_file_permissions.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_file_permissions/o365_user_consent_file_permissions.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 FullAccessAsApp Permission Assigned", "author": "Mauricio Velazco, Splunk", "date": "2024-01-29", "version": 1, "id": "01a510b3-a6ac-4d50-8812-7e8a3cde3d79", "description": "The following analytic triggers on the assignment of the 'full_access_as_app' permission to an application registration in Office 365, specifically within Exchange Online. The 'full_access_as_app' permission, identified by its GUID 'dc890d15-9560-4a4c-9b7f-a736ec74ec40', allows an application extensive control over Office 365 operations, including access to all mailboxes and the ability to send mail as any user. The analytic focuses on the ResourceAppId '00000002-0000-0ff1-ce00-000000000000', pinpointing permissions granted to the Office 365 Exchange Online resource. By analyzing Office 365 management activity logs and filtering Azure Active Directory workload events, the query detects when this specific permission is assigned. Monitoring this assignment is vital due to the broad access it provides, which can lead to unauthorized data access or exfiltration if misused. A true positive detection requires immediate attention to prevent potential security risks like account compromise or data loss.", "tags": {"name": "O365 FullAccessAsApp Permission Assigned", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098.002", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ assigned the full_access_as_app permission to the app registration $object$", "risk_score": 48, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Update application.\" | eval newvalue = mvindex('ModifiedProperties{}.NewValue',0) | spath input=newvalue  | search \"{}.ResourceAppId\"=\"00000002-0000-0ff1-ce00-000000000000\"  \"{}.RequiredAppPermissions{}.EntitlementId\"=\"dc890d15-9560-4a4c-9b7f-a736ec74ec40\" | eval Permissions = '{}.RequiredAppPermissions{}.EntitlementId' | stats count earliest(_time) as firstTime latest(_time) as lastTime values(Permissions) by user, object, user_agent, Operation | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_fullaccessasapp_permission_assigned_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "The full_access_as_app API permission may be assigned to legitimate applications. Filter as needed.", "check_references": false, "references": ["https://msrc.microsoft.com/blog/2024/01/microsoft-actions-following-attack-by-nation-state-actor-midnight-blizzard/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/", "https://attack.mitre.org/techniques/T1098/002/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_fullaccessasapp_permission_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 FullAccessAsApp Permission Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.002/o365_full_access_as_app_permission_assigned/o365_full_access_as_app_permission_assigned.log", "source": "o365:management:activity", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.002/o365_full_access_as_app_permission_assigned/o365_full_access_as_app_permission_assigned.log", "source": "o365:management:activity", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 High Number Of Failed Authentications for User", "author": "Mauricio Velazco, Splunk", "date": "2023-10-10", "version": 1, "id": "31641378-2fa9-42b1-948e-25e281cb98f7", "description": "The following analytic identifies an O365 account that has experienced more than 20 failed authentication events within a span of 5 minutes. This could be indicative of an attacker attempting to brute force or guess the password for that particular user account. It leverages the O365 Unified Audit Logs, specifically the \"UserLoginFailed\" events. By monitoring the frequency and volume of these events for individual users, the analytic can flag accounts that exceed the set threshold of failed attempts within the defined timeframe. Multiple failed login attempts in a short period can be a strong indicator of malicious activity. While there could be benign reasons, such as a user forgetting their password, the rapid succession of failed attempts is often a sign of an attacker trying to gain unauthorized access. By detecting and alerting on this behavior, the SOC can quickly investigate and take appropriate action, potentially stopping an attack in its early stages. Given that environments differ across organizations, security teams should consider customizing the threshold of this detection to better suit their specific needs and risk profile. If an attacker successfully guesses or brute-forces a user's password after numerous attempts, they can gain unauthorized access to the O365 environment. This unauthorized access could allow them to view sensitive emails, documents, and other data.", "tags": {"name": "O365 High Number Of Failed Authentications for User", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "O365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1110", "T1110.001"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ failed to authenticate more than 10 times in the span of 5 minutes.", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Operation=UserLoginFailed  record_type=AzureActiveDirectoryStsLogon Workload=AzureActiveDirectory | bucket span=5m _time | stats  dc(_raw) AS failed_attempts  values(src_ip) as src_ip by user, _time | where failed_attempts > 10 | `o365_high_number_of_failed_authentications_for_user_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Although unusual, users who have lost their passwords may trigger this detection. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/", "https://attack.mitre.org/techniques/T1110/001/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "o365_high_number_of_failed_authentications_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 High Number Of Failed Authentications for User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/o365_high_number_authentications_for_user/o365_high_number_authentications_for_user.log", "source": "o365:management:activity", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.001/o365_high_number_authentications_for_user/o365_high_number_authentications_for_user.log", "source": "o365:management:activity", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 High Privilege Role Granted", "author": "Mauricio Velazco, Splunk", "date": "2023-10-20", "version": 1, "id": "e78a1037-4548-4072-bb1b-ad99ae416426", "description": "This analytic detects when high-privilege roles, specifically \"Exchange Administrator\", \"SharePoint Administrator\", or \"Global Administrator\", are granted within Office 365. By monitoring O365 audit logs for events where these administrative roles are assigned to any user or service account, the analytic provides insight into critical role changes. The assignment of these roles is of paramount importance to Security Operations Centers (SOCs) as they grant extensive permissions, allowing for broad access and control over critical organizational resources and data. An unexpected or unauthorized role assignment could indicate potential malicious activity, insider threats, or misconfigurations. If an attacker or unauthorized individual is granted one of these roles, the potential impact includes gaining significant control over O365 resources, accessing, modifying, or deleting critical data, making configuration changes, and potentially compromising the overall security and functionality of the O365 environment.", "tags": {"name": "O365 High Privilege Role Granted", "analytic_story": ["Office 365 Persistence Mechanisms"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "$user$ granted high privilege roles to $ObjectId$", "risk_score": 48, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=\"Add member to role.\" Workload=AzureActiveDirectory | eval role_id = mvindex('ModifiedProperties{}.NewValue',2) | eval role_name = mvindex('ModifiedProperties{}.NewValue',1) | where role_id IN (\"29232cdf-9323-42fd-ade2-1d097af3e4de\", \"f28a1f50-f6e7-4571-818b-6a12f2af6b6c\", \"62e90394-69f5-4237-9190-012177145e10\")  | stats earliest(_time) as firstTime latest(_time) as lastTime by user Operation ObjectId role_name | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_high_privilege_role_granted_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Privilege roles may be assigned for legitimate purposes, filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/003/", "https://learn.microsoft.com/en-us/azure/active-directory/roles/permissions-reference", "https://learn.microsoft.com/en-us/microsoft-365/admin/add-users/about-exchange-online-admin-role?view=o365-worldwide", "https://learn.microsoft.com/en-us/sharepoint/sharepoint-admin-role"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_high_privilege_role_granted_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 High Privilege Role Granted:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_high_priv_role_assigned/o365_high_priv_role_assigned.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_high_priv_role_assigned/o365_high_priv_role_assigned.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Mail Permissioned Application Consent Granted by User", "author": "Mauricio Velazco, Splunk", "date": "2023-10-12", "version": 1, "id": "fddad083-cdf5-419d-83c6-baa85e329595", "description": "The following analytic identifies instances where a user grants consent to an application that requests mail related permissions within the Office 365 environment. This could involve permissions to read, send, or manage mail settings. It leverages the O365 audit logs, specifically events related to application permissions and user consent actions. By filtering for mail-related permissions and user-granted consents, the analytic pinpoints potential security concerns. While many legitimate applications request mail permissions for valid reasons, malicious actors can exploit these permissions for data exfiltration, spear phishing, or other malicious activities. By monitoring for user-granted mail permissions, security teams can identify and review potentially risky consents, ensuring that only trusted applications have access to sensitive email data. If the detection is a true positive, it indicates that an application now has access to the users mail data as permitted. In the hands of a malicious actor, this could lead to unauthorized data access, email forwarding, or even the sending of malicious emails from the compromised account. Its crucial to validate the legitimacy of the application and the context of the consent to prevent potential data breaches or further malicious activities.", "tags": {"name": "O365 Mail Permissioned Application Consent Granted by User", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ consented an OAuth application that requests mail-related permissions.", "risk_score": 40, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Consent to application.\" ResultStatus=Success | eval admin_consent =mvindex('ModifiedProperties{}.NewValue', 0) | search admin_consent=False | eval permissions =mvindex('ModifiedProperties{}.NewValue', 4) | rex field=permissions \"Scope: (?<Scope>[^,]+)\" | makemv delim=\" \" Scope | search Scope IN (\"Mail.Read\", \"Mail.ReadBasic\", \"Mail.ReadWrite\", \"Mail.Read.Shared\", \"Mail.ReadWrite.Shared\", \"Mail.Send\", \"Mail.Send.Shared\") | stats max(_time) as lastTime values(Scope) by Operation, user, object, ObjectId | `security_content_ctime(lastTime)` | `o365_mail_permissioned_application_consent_granted_by_user_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "OAuth applications that require mail permissions may be legitimate, investigate and filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/protect-against-consent-phishing", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_mail_permissioned_application_consent_granted_by_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Mail Permissioned Application Consent Granted by User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_mail_permissions/o365_user_consent_mail_permissions.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_mail_permissions/o365_user_consent_mail_permissions.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Mailbox Inbox Folder Shared with All Users", "author": "Mauricio Velazco, Splunk", "date": "2023-09-07", "version": 1, "id": "21421896-a692-4594-9888-5faeb8a53106", "description": "The following analytic identifies instances where the inbox folder of a mailbox in Office 365 is shared with all users within the tenant. Sharing the inbox folder with all users is an unusual and risky configuration. Attackers have been known to exploit this setting to surreptitiously read a target user's emails from another account. Such unauthorized access can lead to data breaches, leakage of confidential information, or further compromise based on the information gathered from the emails. Monitoring for this configuration change ensures that inadvertent or malicious sharing is promptly identified and addressed. If an attacker successfully configures the inbox to be shared with all users, they can access and read all emails in the affected mailbox from any account within the tenant. This can lead to data exfiltration, spear-phishing attacks based on the information in the emails, or further malicious activities using sensitive information gathered from the mailbox.", "tags": {"name": "O365 Mailbox Inbox Folder Shared with All Users", "analytic_story": ["Office 365 Collection Techniques"], "asset_type": "Office 365 Tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114", "T1114.002"], "nist": ["DE.CM"], "observable": [{"name": "MailboxOwnerUPN", "type": "User", "role": ["Victim"]}], "message": "Inbox folder for the $MailboxOwnerUPN$ mailbox was shared with all users.", "risk_score": 56, "security_domain": "access", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Operation=ModifyFolderPermissions Workload=Exchange object=Inbox Item.ParentFolder.MemberUpn=Everyone Item.ParentFolder.MemberRights!=None | stats max(_time) as lastTime by Operation, UserId, object, MailboxOwnerUPN, Item.ParentFolder.MemberUpn, Item.ParentFolder.MemberRights | `security_content_ctime(lastTime)` | `o365_mailbox_inbox_folder_shared_with_all_users_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Administrators might temporarily share a mailbox with all users for legitimate reasons, such as troubleshooting, migrations, or other administrative tasks. Some organizations use shared mailboxes for teams or departments where multiple users need access to the same mailbox. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1114/002/", "https://www.mandiant.com/sites/default/files/2022-08/remediation-hardening-strategies-for-m365-defend-against-apt29-white-paper.pdf", "https://www.blackhillsinfosec.com/abusing-exchange-mailbox-permissions-mailsniper/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_mailbox_inbox_folder_shared_with_all_users_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Mailbox Inbox Folder Shared with All Users:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_inbox_shared_with_all_users/o365_inbox_shared_with_all_users.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_inbox_shared_with_all_users/o365_inbox_shared_with_all_users.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Mailbox Read Access Granted to Application", "author": "Mauricio Velazco, Splunk", "date": "2023-09-01", "version": 1, "id": "27ab61c5-f08a-438a-b4d3-325e666490b3", "description": "The following analytic identifies instances where the Mail.Read Graph API permissions are granted to an application registration within an Office 365 tenant. It leverages O365 audit logs, specifically events related to changes in application permissions within the AzureActiveDirectory workload. The Mail.Read permission allows applications to access and read all emails within a user's mailbox. Emails often contain sensitive or confidential information, and unauthorized access can lead to data breaches or leakage. Monitoring the assignment of this permission ensures that only legitimate applications have such access and that any inadvertent or malicious assignments are promptly identified. If an attacker successfully grants this permission to a malicious or compromised application, they can read all emails in the affected mailboxes. This can lead to data exfiltration, spear-phishing attacks, or further compromise based on the information gathered from the emails.", "tags": {"name": "O365 Mailbox Read Access Granted to Application", "analytic_story": ["Office 365 Collection Techniques"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.002", "T1114", "T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "Application registration $object$ was grandes mailbox read access by $user$", "risk_score": 45, "security_domain": "access", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=\"Update application.\" | eval json_data=mvindex('ModifiedProperties{}.NewValue', 0) | eval json_data=replace(json_data, \"^\\[\\s*\", \"\") | eval json_data=replace(json_data, \"\\s*\\]$\", \"\") | spath input=json_data path=RequiredAppPermissions{}.EntitlementId output=EntitlementIds | eval match_found=mvfind(EntitlementIds, \"810c84a8-4a9e-49e6-bf7d-12d183f40d01\") | where isnotnull(match_found) | stats max(_time) as lastTime values(EntitlementIds) as EntitlementIds by Operation, user, object | `security_content_ctime(lastTime)` | `o365_mailbox_read_access_granted_to_application_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "There are legitimate scenarios in wich an Application registrations requires Mailbox read access. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/003/", "https://attack.mitre.org/techniques/T1114/002/", "https://www.mandiant.com/sites/default/files/2022-08/remediation-hardening-strategies-for-m365-defend-against-apt29-white-paper.pdf", "https://www.cisa.gov/sites/default/files/publications/Supply_Chain_Compromise_Detecting_APT_Activity_from_known_TTPs.pdf", "https://learn.microsoft.com/en-us/graph/permissions-reference", "https://graphpermissions.merill.net/permission/Mail.Read"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_mailbox_read_access_granted_to_application_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Mailbox Read Access Granted to Application:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_grant_mail_read/o365_grant_mail_read.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_grant_mail_read/o365_grant_mail_read.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multi-Source Failed Authentications Spike", "author": "Mauricio Velazco, Splunk", "date": "2023-11-09", "version": 1, "id": "ea4e2c41-dbfb-4f5f-a7b6-9ac1b7f104aa", "description": "This analytic detects potential distributed password spraying attacks within an Office 365 environment. It identifies a significant increase in failed authentication attempts characterized by diverse user-and-IP address combinations, originating from multiple source IP addresses, and utilizing various user agents. These patterns may indicate an adversary's attempt to circumvent security controls by employing a spectrum of IP addresses to test commonly used passwords against a wide range of user accounts. The detection examines UserLoginFailed events from O365 Management Activity logs, with a particular focus on events with ErrorNumber 50126, which indicates a failed authentication due to incorrect credentials. By aggregating data over a five-minute interval, the analytic calculates the distinct counts of user-and-IP combinations and unique users and source IPs. It then applies a set of thresholds to these metrics to identify abnormal activities that could suggest a coordinated attack. The predefined thresholds within the analytic (such as unique IPs, unique users, etc.) serve as initial benchmarks and should be tailored to align with the organization's typical user behavior and risk tolerance. Early detection of such distributed activities is crucial for security operations centers (SOCs) to intercept unauthorized access attempts, avert account takeovers, and reduce the risk of subsequent malevolent actions within the organization's systems. A true positive alert from this analytic would indicate an ongoing distributed password spraying campaign targeting the organization's Office 365 tenant. If such an attack is successful, it could lead to unauthorized access, especially to accounts with administrative privileges, resulting in data breaches, privilege escalation, persistent threats, and lateral movement within the organization's digital environment.", "tags": {"name": "O365 Multi-Source Failed Authentications Spike", "analytic_story": ["Office 365 Account Takeover", "NOBELIUM Group"], "asset_type": "O365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "An anomalous multi source authentication spike ocurred at $_time$", "risk_score": 42, "security_domain": "identity", "risk_severity": "low", "atomic_guid": [], "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=AzureActiveDirectory Operation=UserLoginFailed ErrorNumber=50126 | bucket span=5m _time | eval uniqueIPUserCombo = src_ip . \"-\" . user | stats dc(uniqueIPUserCombo) as uniqueIpUserCombinations, dc(user) as uniqueUsers, dc(src_ip) as uniqueIPs, values(user) as user, values(src_ip) as ips, values(user_agent) as user_agents by _time | where uniqueIpUserCombinations > 20 AND uniqueUsers > 20 AND uniqueIPs > 20 | `o365_multi_source_failed_authentications_spike_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events. The thresholds set within the analytic (such as unique IPs, unique users, etc.) are initial guidelines and should be customized based on the organization's user behavior and risk profile. Security teams are encouraged to adjust these thresholds to optimize the balance between detecting genuine threats and minimizing false positives, ensuring the detection is tailored to their specific environment.", "known_false_positives": "This detection may yield false positives in scenarios where legitimate bulk sign-in activities occur, such as during company-wide system updates or when users are accessing resources from varying locations in a short time frame, such as in the case of VPNs or cloud services that rotate IP addresses. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://docs.microsoft.com/azure/active-directory/reports-monitoring/reference-sign-ins-error-codes"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "o365_multi_source_failed_authentications_spike_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multi-Source Failed Authentications Spike:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/o365_distributed_spray/o365_distributed_spray.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/o365_distributed_spray/o365_distributed_spray.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multiple AppIDs and UserAgents Authentication Spike", "author": "Mauricio Velazco, Splunk", "date": "2023-10-24", "version": 1, "id": "66adc486-224d-45c1-8e4d-9e7eeaba988f", "description": "This analytic is crafted to identify unusual and potentially malicious authentication activity within an O365 environment. It triggers when a single user account is involved in more than 8 authentication attempts, using 3 or more unique application IDs and more than 5 unique user agents within a short timeframe. This pattern is atypical for regular user behavior and may indicate an adversary's attempt to probe the environment, testing for multi-factor authentication requirements across different applications and platforms. The detection is based on analysis of O365 audit logs, specifically focusing on authentication events. It employs statistical thresholds to highlight instances where the volume of authentication attempts and the diversity of application IDs and user agents associated with a single user account exceed normal parameters. Identifying this behavior is crucial as it provides an early indication of potential account compromise. Adversaries, once in possession of user credentials, often conduct reconnaissance to understand the security controls in place, including multi-factor authentication configurations. Tools like Invoke-MFASweep are commonly used for this purpose, automating the process of testing different user agents and application IDs to bypass MFA. By detecting these initial probing attempts, security teams can swiftly respond, potentially stopping an attack in its early stages and preventing further unauthorized access. This proactive stance is vital for maintaining the integrity of the organization's security posture. If validated as a true positive, this detection points to a compromised account, signaling that an attacker is actively attempting to navigate security controls to maintain access and potentially escalate privileges. This could lead to further exploitation, lateral movement within the network, and eventual data exfiltration. Recognizing and responding to this early stage of an attack is vital for preventing substantial harm and safeguarding sensitive organizational data and systems.", "tags": {"name": "O365 Multiple AppIDs and UserAgents Authentication Spike", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1078"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "$user$ authenticated in a short period of time with more than 5 different user agents across 3 or more unique application ids.", "risk_score": 48, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=AzureActiveDirectory (Operation=UserLoggedIn OR Operation=UserLoginFailed) | bucket span=5m _time | stats  dc(_raw) as failed_attempts dc(ApplicationId) as unique_app_ids dc(UserAgent) as unique_user_agents values(ApplicationId) values(OS) by _time user src_ip | where failed_attempts > 5 and unique_user_agents > 5 and unique_app_ids > 2 | `o365_multiple_appids_and_useragents_authentication_spike_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Rapid authentication from the same user using more than 5 different user agents and 3 application IDs is highly unlikely under normal circumstances. However, there are potential scenarios that could lead to false positives.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1078/", "https://www.blackhillsinfosec.com/exploiting-mfa-inconsistencies-on-microsoft-services/", "https://github.com/dafthack/MFASweep", "https://www.youtube.com/watch?v=SK1zgqaAZ2E"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "o365_multiple_appids_and_useragents_authentication_spike_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multiple AppIDs and UserAgents Authentication Spike:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/o365_multiple_appids_and_useragents_auth/o365_multiple_appids_and_useragents_auth.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1078/o365_multiple_appids_and_useragents_auth/o365_multiple_appids_and_useragents_auth.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multiple Failed MFA Requests For User", "author": "Mauricio Velazco, Splunk", "date": "2023-10-19", "version": 1, "id": "fd22124e-dbac-4744-a8ce-be10d8ec3e26", "description": "This analytic identifies potential \"MFA fatigue\" attacks targeting Office 365 users. Specifically, it detects scenarios where a user experiences more than nine Multi-Factor Authentication (MFA) prompts within a 10-minute timeframe. Attackers may exploit MFA fatigue by repeatedly triggering MFA requests, hoping that the user, out of frustration or oversight, will approve a malicious authentication attempt. The detection leverages O365 management activity logs, focusing on Azure Active Directory events. It looks for the UserLoginFailed operation combined with a Success ResultStatus and an ErrorNumber of 500121, which indicates MFA prompts. By monitoring these specific events and conditions, the analytic captures and alerts on potential MFA fatigue scenarios. With MFA being a cornerstone of modern cybersecurity defenses, attackers are constantly seeking ways to bypass or exploit it. MFA fatigue is one such tactic, where attackers rely on user frustration or confusion caused by frequent MFA prompts. Detecting potential MFA fatigue scenarios allows security teams to proactively investigate and ensure that users aren't inadvertently granting access to malicious actors. If this detection flags a true positive, it suggests a potential attempt by an attacker to exploit MFA mechanisms to gain unauthorized access to an O365 account. Successful exploitation could lead to data breaches, unauthorized data access, or further compromise within the O365 environment. Immediate investigation and response would be crucial to safeguard the affected account and assess the full scope of the potential breach.", "tags": {"name": "O365 Multiple Failed MFA Requests For User", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1621"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "Multiple failed MFA requestes for $user$", "risk_score": 48, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=AzureActiveDirectory Operation=UserLoginFailed ResultStatus=Success  ErrorNumber=500121 | bucket span=10m _time | stats  dc(_raw) as mfa_prompts values(LogonError) as LogonError values(signature) as signature by user, _time | where  mfa_prompts  > 9 | `o365_multiple_failed_mfa_requests_for_user_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Multiple Failed MFA requests may also be a sign of authentication or application issues. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1621/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "o365_multiple_failed_mfa_requests_for_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multiple Failed MFA Requests For User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/o365_multiple_failed_mfa_requests/o365_multiple_failed_mfa_requests.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1621/o365_multiple_failed_mfa_requests/o365_multiple_failed_mfa_requests.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multiple Mailboxes Accessed via API", "author": "Mauricio Velazco, Splunk", "date": "2024-02-01", "version": 1, "id": "7cd853e9-d370-412f-965d-a2bcff2a2908", "description": "The following analytic is designed to trigger when a high number of Office 365 Exchange mailboxes are accessed via API (Microsoft Graph API or Exchange Web Services) in a short time, hinting at possible unauthorized mass email access. It tracks 'MailItemsAccessed' operations in Exchange, using AppId and regex to identify API interactions. Crucial for SOC teams, this analytic focuses on spotting abnormal access patterns, often signaling data exfiltration or account compromise. Security teams should tailor the threshold — set here to flag over five unique mailboxes accessed within 10 minutes — to align with their environment's norms, ensuring effective detection of potential security incidents while maintaining operational efficiency.", "tags": {"name": "O365 Multiple Mailboxes Accessed via API", "analytic_story": ["Office 365 Collection Techniques", "NOBELIUM Group"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "An Oauth application identified with id $ClientAppId$ accessed multiple mailboxes in a short period of time via an API.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=Exchange Operation=MailItemsAccessed AppId=* ClientAppId=* | bucket span=10m _time | eval matchRegex=if(match(ClientInfoString, \"^Client=WebServices;ExchangeWebServices\"), 1, 0) | search (AppId=\"00000003-0000-0000-c000-000000000000\" OR matchRegex=1) | stats values(ClientIPAddress) as src_ip dc(user) as unique_mailboxes values(user) as user by _time ClientAppId ClientInfoString | where unique_mailboxes > 5 | `o365_multiple_mailboxes_accessed_via_api_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Legitimate applications may access multiple mailboxes via an API. You can filter by the ClientAppId or the CLientIpAddress fields.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1114/002/", "https://learn.microsoft.com/en-us/troubleshoot/azure/active-directory/verify-first-party-apps-sign-in", "https://learn.microsoft.com/en-us/graph/permissions-reference", "https://attack.mitre.org/techniques/T1114/002/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/", "https://learn.microsoft.com/en-us/exchange/client-developer/exchange-web-services/ews-applications-and-the-exchange-architecture"], "datamodel": ["Web"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "o365_multiple_mailboxes_accessed_via_api_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multiple Mailboxes Accessed via API:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_multiple_mailboxes_accessed_via_api/o365_multiple_mailboxes_accessed_via_api.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_multiple_mailboxes_accessed_via_api/o365_multiple_mailboxes_accessed_via_api.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multiple Service Principals Created by SP", "author": "Mauricio Velazco, Splunk", "date": "2024-02-07", "version": 1, "id": "ef4c3f20-d1ad-4ad1-a3f4-d5f391c005fe", "description": "This detection aims to identify instances where a single service principal creates more than three unique OAuth applications within a 10-minute timeframe, using O365 logs from the Unified Audit Log. The focus is on tracking the 'Add service principal' operation within the Office 365 Azure Active Directory environment. The query effectively buckets events in 10-minute intervals, specifically scrutinizing the actions of service principals. By quantifying the number of distinct OAuth applications each service principal establishes, the analytic provides critical insights for SOC teams into potentially anomalous or malicious activities. These activities could include a compromised or malicious service principal being used to create multiple service principals, which might be indicative of an attempt to expand control or access within the network. Security teams are advised to adapt the threshold of three applications to align with their typical operational baseline", "tags": {"name": "O365 Multiple Service Principals Created by SP", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003"], "nist": ["DE.AE"], "observable": [{"name": "src_user", "type": "User", "role": ["Attacker"]}], "message": "Multiple OAuth applications were created by $src_user$ in a short period of time", "risk_score": 42, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Add service principal.\"  | bucket span=10m _time | eval len=mvcount('Actor{}.ID') | eval userType = mvindex('Actor{}.ID',len-1) | search userType = \"ServicePrincipal\" | eval displayName = object | stats count earliest(_time) as firstTime latest(_time) as lastTime values(displayName) as displayName dc(displayName) as unique_apps by src_user | where unique_apps > 3 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_multiple_service_principals_created_by_sp_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Certain users or applications may create multiple service principals in a short period of time for legitimate purposes. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1136/003/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_multiple_service_principals_created_by_sp_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multiple Service Principals Created by SP:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_multiple_service_principals_created/o365_multiple_service_principals_created.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_multiple_service_principals_created/o365_multiple_service_principals_created.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multiple Service Principals Created by User", "author": "Mauricio Velazco, Splunk", "date": "2024-02-07", "version": 1, "id": "a34e65d0-54de-4b02-9db8-5a04522067f6", "description": "This detection is tailored to spot occurrences where a single user, rather than a service principal, creates more than three unique OAuth applications within a 10-minute window in the Office 365 environment. Utilizing O365 logs from the Unified Audit Log, it focuses on the 'Add service principal' operation in Azure Active Directory. The query segments events into 10-minute intervals, exclusively monitoring user activities. It calculates the number of distinct OAuth applications initiated by each user, providing SOC teams with essential data for identifying potential security threats. Such activity could suggest that a user account is either compromised or engaged in unauthorized activities, potentially setting the stage for broader network infiltration or privilege escalation. It's important for security teams to adjust the threshold of three applications to fit their operational context.", "tags": {"name": "O365 Multiple Service Principals Created by User", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003"], "nist": ["DE.AE"], "observable": [{"name": "src_user", "type": "User", "role": ["Attacker"]}], "message": "Multiple OAuth applications were created by $src_user$ in a short period of time", "risk_score": 42, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity`  Workload=AzureActiveDirectory Operation=\"Add service principal.\"  | bucket span=10m _time | eval len=mvcount('Actor{}.ID') | eval userType = mvindex('Actor{}.ID',len-1) | search userType = \"User\" | eval displayName = object | stats count earliest(_time) as firstTime latest(_time) as lastTime values(displayName) as displayName dc(displayName) as unique_apps by src_user | where unique_apps > 3 | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_multiple_service_principals_created_by_user_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Certain users or applications may create multiple service principals in a short period of time for legitimate purposes. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1136/003/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_multiple_service_principals_created_by_user_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multiple Service Principals Created by User:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_multiple_service_principals_created/o365_multiple_service_principals_created.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_multiple_service_principals_created/o365_multiple_service_principals_created.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Multiple Users Failing To Authenticate From Ip", "author": "Mauricio Velazco, Splunk", "date": "2024-03-19", "version": 2, "id": "8d486e2e-3235-4cfe-ac35-0d042e24ecb4", "description": "This analytic identifies instances where multiple users (more than 10 unique accounts) have failed to authenticate from a single IP address within a short time span (5 minutes). Such a pattern can be indicative of malicious activities, such as brute-force attacks or password spraying attempts. The detection leverages O365 audit logs, specifically focusing on Azure Active Directory login failures (AzureActiveDirectoryStsLogon). By aggregating these failures based on the source IP address and time, the analytic captures patterns where multiple unique user accounts have authentication failures from the same IP within a 5-minute window. Multiple authentication failures from a single IP address targeting various accounts can be a strong indicator of an attacker trying to gain unauthorized access. It could represent a brute-force attack, password spraying, or other malicious login attempts. Identifying and responding to such patterns promptly is crucial to prevent potential account compromises and unauthorized access to organizational resources. If the detection is a true positive, it suggests that an external entity is actively trying to breach the security by targeting multiple user accounts. While the attempts have been unsuccessful (as indicated by the login failures), it's a clear sign of malicious intent. Immediate action is required to block or monitor the suspicious IP, investigate the nature of the attempts, and potentially notify affected users to take precautionary measures like password changes or enabling multi-factor authentication.", "tags": {"name": "O365 Multiple Users Failing To Authenticate From Ip", "analytic_story": ["Office 365 Account Takeover", "NOBELIUM Group"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1586", "T1586.003", "T1110", "T1110.003", "T1110.004"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "Source Ip $src_ip$ failed to authenticate with 20 users within 5 minutes.", "risk_score": 63, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=AzureActiveDirectory Operation=UserLoginFailed ErrorNumber=50126 |  bucket span=5m _time |  stats dc(user) as unique_accounts values(user) as user values(LogonError) as LogonError values(signature) as signature values(UserAgent) as UserAgent by _time, src_ip |  where unique_accounts > 10 | `o365_multiple_users_failing_to_authenticate_from_ip_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "A source Ip failing to authenticate with multiple users in a short period of time is not common legitimate behavior.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1110/003/", "https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-password-spray", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://docs.microsoft.com/azure/active-directory/reports-monitoring/reference-sign-ins-error-codes"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "o365_multiple_users_failing_to_authenticate_from_ip_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Multiple Users Failing To Authenticate From Ip:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/o365_multiple_users_from_ip/o365_multiple_users_from_ip.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1110.003/o365_multiple_users_from_ip/o365_multiple_users_from_ip.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 New Federated Domain Added", "author": "Rod Soto, Mauricio Velazco Splunk", "date": "2023-08-02", "version": 3, "id": "e155876a-6048-11eb-ae93-0242ac130002", "description": "The following analytic identifies the addition of a new federated domain in an organization's Office 365 environment. This behavior is detected by analyzing the Office 365 management activity logs using the Splunk query o365_management_activity, specifically filtering for the Workload=Exchange and Operation=\"Add-FederatedDomain\" parameters. The addition of a new federated domain can be a significant security concern, as it might indicate unauthorized changes or potential compromises within the Office 365 setup. Attackers, upon gaining sufficient privileges, could add a federated domain to establish a backdoor, bypass security measures, or exfiltrate data. Such unauthorized changes can lead to data breaches, unauthorized access to sensitive data, and potential compromise of organizational infrastructure. When this analytic is triggered, immediate steps should include reviewing the details of the added federated domain, such as the organization name, originating server, user ID, and user key. Concurrent processes or other indicators of compromise should also be investigated to pinpoint the source of the potential breach.", "tags": {"name": "O365 New Federated Domain Added", "analytic_story": ["Office 365 Persistence Mechanisms", "Cloud Federated Credential Abuse"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1136.003", "T1136"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "User $user$ has added a new federated domain $new_value$", "risk_score": 64, "security_domain": "threat", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation IN (\"*add*\", \"*new*\") AND Operation=\"*domain*\" | stats count values(ModifiedProperties{}.NewValue) as new_value by  user user_agent authentication_service action Workload Operation | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_new_federated_domain_added_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity.", "known_false_positives": "The creation of a new Federated domain is not necessarily malicious, however these events need to be followed closely, as it may indicate federated credential abuse or backdoor via federated identities at a similar or different cloud provider.", "check_references": false, "references": ["https://www.fireeye.com/content/dam/fireeye-www/blog/pdfs/wp-m-unc2452-2021-000343-01.pdf", "https://www.cisa.gov/uscert/ncas/alerts/aa21-008a", "https://www.splunk.com/en_us/blog/security/a-golden-saml-journey-solarwinds-continued.html", "https://blog.sygnia.co/detection-and-hunting-of-golden-saml-attack?hsLang=en", "https://o365blog.com/post/aadbackdoor/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_new_federated_domain_added_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 New Federated Domain Added:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_new_federated_domain_added/o365_add_federated_domain.log", "source": "o365", "sourcetype": "o365:management:activity", "update_timestamp": true}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1136.003/o365_new_federated_domain_added/o365_add_federated_domain.log", "source": "o365", "sourcetype": "o365:management:activity", "update_timestamp": true}]}]}, {"name": "O365 New MFA Method Registered", "author": "Mauricio Velazco, Splunk", "date": "2023-10-20", "version": 1, "id": "4e12db1f-f7c7-486d-8152-a221cad6ac2b", "description": "This analytic detects the registration of a new Multi-Factor Authentication (MFA) method associated with a user account within Office 365 by monitoring O365 audit logs and configurations. While adding a new MFA method can be a routine and legitimate action, it can also be indicative of an attacker's attempt to maintain persistence on a compromised account. By registering a new MFA method, attackers can potentially bypass existing security measures, allowing them to authenticate using stolen credentials without raising alarms. Monitoring for such changes is crucial, especially if the addition is not preceded by a user request or if it deviates from typical user behavior. If an attacker successfully registers a new MFA method on a compromised account, they can solidify their access, making it harder for legitimate users to regain control. The attacker can then operate with the privileges of the compromised account, potentially accessing sensitive data, making unauthorized changes, or even escalating their privileges further. Immediate action would be required to verify the legitimacy of the MFA change and, if malicious, to remediate and secure the affected account.", "tags": {"name": "O365 New MFA Method Registered", "analytic_story": ["Office 365 Persistence Mechanisms"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.005"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "A new MFA method was added for $user$", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory  Operation=\"Update user.\"  | eval propertyName = mvindex('ModifiedProperties{}.Name', 0) | search propertyName = StrongAuthenticationMethod | eval oldvalue = mvindex('ModifiedProperties{}.OldValue',0) | eval newvalue = mvindex('ModifiedProperties{}.NewValue',0) | rex field=newvalue max_match=0 \"(?i)(?<new_method_type>\\\"MethodType\\\")\" | rex field=oldvalue max_match=0 \"(?i)(?<old_method_type>\\\"MethodType\\\")\" | eval count_new_method_type = coalesce(mvcount(new_method_type), 0) | eval count_old_method_type = coalesce(mvcount(old_method_type), 0) |  where count_new_method_type > count_old_method_type |  stats earliest(_time) as firstTime latest(_time) as lastTime values(propertyName) by user newvalue oldvalue | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_new_mfa_method_registered_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Users may register MFA methods legitimally, investigate and filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/005/", "https://www.microsoft.com/en-us/security/blog/2023/06/08/detecting-and-mitigating-a-multi-stage-aitm-phishing-and-bec-campaign/", "https://www.csoonline.com/article/573451/sophisticated-bec-scammers-bypass-microsoft-365-multi-factor-authentication.html"], "datamodel": ["Authentication"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_new_mfa_method_registered_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 New MFA Method Registered:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.005/o365_register_new_mfa_method/o365_register_new_mfa_method.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.005/o365_register_new_mfa_method/o365_register_new_mfa_method.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 OAuth App Mailbox Access via EWS", "author": "Mauricio Velazco, Splunk", "date": "2024-01-31", "version": 1, "id": "e600cf1a-0bef-4426-b42e-00176d610a4d", "description": "The following analytic detects when emails are accessed in Office 365 Exchange via Exchange Web Services (EWS), as indicated by the ClientInfoString field starting with \"Client=WebServices;ExchangeWebServices\". It monitors mailbox activities, focusing on OAuth-authenticated applications that interact with EWS. The query aggregates key metrics such as access counts, timing, and client IP addresses, categorized by user, ClientAppId, OperationCount, and AppId. For defenders, it is critical to keep track of OAuth applications using EWS to access emails, as this information is instrumental in identifying and preventing potential abuse or unauthorized data access.", "tags": {"name": "O365 OAuth App Mailbox Access via EWS", "analytic_story": ["Office 365 Collection Techniques", "NOBELIUM Group"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "An OAuth application identified with id $ClientAppId$ accesed mailboxes through the Graph API.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=Exchange Operation=MailItemsAccessed AppId=* ClientAppId=* | regex ClientInfoString=\"^Client=WebServices;ExchangeWebServices\" |  stats count earliest(_time) as firstTime latest(_time) as lastTime values(ClientIPAddress) as src_ip by user ClientAppId OperationCount AppId ClientInfoString | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_oauth_app_mailbox_access_via_ews_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "OAuth applications may access mailboxes for legitimate purposes, you can use the src_ip to add trusted sources to an allow list.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1114/002/", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/", "https://learn.microsoft.com/en-us/exchange/client-developer/exchange-web-services/ews-applications-and-the-exchange-architecture"], "datamodel": ["Web"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_oauth_app_mailbox_access_via_ews_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 OAuth App Mailbox Access via EWS:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_oauth_app_ews_mailbox_access/o365_oauth_app_ews_mailbox_access.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_oauth_app_ews_mailbox_access/o365_oauth_app_ews_mailbox_access.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 OAuth App Mailbox Access via Graph API", "author": "Mauricio Velazco, Splunk", "date": "2024-01-31", "version": 1, "id": "9db0d5b0-4058-4cb7-baaf-77d8143539a2", "description": "This Splunk analytic detects when emails are accessed in Office 365 Exchange via the Microsoft Graph API, identified by the client ID '00000003-0000-0000-c000-000000000000'. It tracks the 'MailItemsAccessed' operation within the Exchange workload, focusing on OAuth-authenticated applications. The query compiles statistics on access frequency, timing, and client IP addresses, organized by user, client application ID, and AppId. For defenders, it's crucial to maintain an inventory of all OAuth applications that read emails, using this data to scrutinize and identify any potential abusive access patterns.", "tags": {"name": "O365 OAuth App Mailbox Access via Graph API", "analytic_story": ["Office 365 Collection Techniques", "NOBELIUM Group"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "An OAuth application identified with id $ClientAppId$ accesed mailboxes through the Graph API.", "risk_score": 42, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=Exchange Operation=MailItemsAccessed AppId=* AppId=00000003-0000-0000-c000-000000000000 |  stats count earliest(_time) as firstTime latest(_time) as lastTime values(ClientIPAddress) by user ClientAppId OperationCount AppId | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_oauth_app_mailbox_access_via_graph_api_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "OAuth applications may access mailboxes for legitimate purposes, you can use the ClientAppId to add trusted applications to an allow list.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1114/002/", "https://learn.microsoft.com/en-us/troubleshoot/azure/active-directory/verify-first-party-apps-sign-in", "https://learn.microsoft.com/en-us/graph/permissions-reference"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_oauth_app_mailbox_access_via_graph_api_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 OAuth App Mailbox Access via Graph API:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_oauth_app_graph_mailbox_access/o365_oauth_app_graph_mailbox_access.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/o365_oauth_app_graph_mailbox_access/o365_oauth_app_graph_mailbox_access.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Privileged Graph API Permission Assigned", "author": "Mauricio Velazco, Splunk", "date": "2024-01-30", "version": 1, "id": "868f3131-d5e1-4bf1-af5b-9b0fbaaaedbb", "description": "This Splunk analytic detects the assignment of critical Graph API permissions in Azure AD using O365 Unified Audit Log as its data source. It focuses on three permissions, Application.ReadWrite.All (Entitlement ID 1bfefb4e-e0b5-418b-a88f-73c46d2cc8e9), AppRoleAssignment.ReadWrite.All (06b708a9-e830-4db3-a914-8e69da51d44f), and RoleManagement.ReadWrite.Directory (9e3f62cf-ca93-4989-b6ce-bf83c28f9fe8). These permissions, crucial for controlling Azure AD settings, pose a high risk if misused. The query monitors Azure Active Directory workload events in the Office 365 Management Activity, specifically 'Update application' operations. It extracts and analyzes data to spot when these permissions are granted, gathering details about the user, object, and user agent involved. Due to the significant control these permissions provide, immediate investigation is crucial upon detection to prevent unauthorized modifications.", "tags": {"name": "O365 Privileged Graph API Permission Assigned", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1003.002"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ assigned privileged Graph API permissions to $object$", "risk_score": 54, "security_domain": "identity", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Update application.\" | eval newvalue = mvindex('ModifiedProperties{}.NewValue',0) | spath input=newvalue  | search \"{}.RequiredAppPermissions{}.EntitlementId\"=\"1bfefb4e-e0b5-418b-a88f-73c46d2cc8e9\" OR \"{}.RequiredAppPermissions{}.EntitlementId\"=\"06b708a9-e830-4db3-a914-8e69da51d44f\" OR \"{}.RequiredAppPermissions{}.EntitlementId\"=\"9e3f62cf-ca93-4989-b6ce-bf83c28f9fe8\"  | eval Permissions = '{}.RequiredAppPermissions{}.EntitlementId' | stats count earliest(_time) as firstTime latest(_time) as lastTime values(Permissions) by user, object, user_agent, Operation | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_privileged_graph_api_permission_assigned_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Privileged Graph API permissions may be assigned for legitimate purposes. Filter as needed.", "check_references": false, "references": ["https://cloudbrothers.info/en/azure-attack-paths/", "https://github.com/mandiant/Mandiant-Azure-AD-Investigator/blob/master/MandiantAzureADInvestigator.json", "https://learn.microsoft.com/en-us/graph/permissions-reference", "https://www.microsoft.com/en-us/security/blog/2024/01/25/midnight-blizzard-guidance-for-responders-on-nation-state-attack/", "https://posts.specterops.io/azure-privilege-escalation-via-azure-api-permissions-abuse-74aee1006f48"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_privileged_graph_api_permission_assigned_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Privileged Graph API Permission Assigned:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_privileged_graph_perm_assigned/o365_privileged_graph_perm_assigned.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_privileged_graph_perm_assigned/o365_privileged_graph_perm_assigned.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 PST export alert", "author": "Rod Soto, Splunk", "date": "2020-12-16", "version": 2, "id": "5f694cc4-a678-4a60-9410-bffca1b647dc", "description": "This analytic detects instances where a user has initiated an eDiscovery search or exported a PST file from the search results in an Office 365 environment. The detection leverages the Office 365 management activity logs, specifically filtering for events categorized under ThreatManagement with the name eDiscovery search started or exported. The initiation of an eDiscovery search or the export of a PST file can be indicative of data exfiltration attempts or unauthorized access to sensitive information. PST files often contain a wealth of sensitive data, including the content of emails. Monitoring for such activities is crucial as they can expose sensitive organizational communications and data. If confirmed as a malicious activity, it suggests that an attacker or insider threat is attempting to gather or exfiltrate data. This can lead to data breaches, loss of intellectual property, or unauthorized access to confidential communications. Immediate investigation is required to determine the scope and intent of the activity and to take appropriate remedial actions.", "tags": {"name": "O365 PST export alert", "analytic_story": ["Office 365 Persistence Mechanisms", "Data Exfiltration"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114"], "nist": ["DE.CM"], "observable": [{"name": "Source", "type": "User", "role": ["Attacker"]}], "message": "User $Source$ has exported a PST file from the search using this operation- $Operation$ with a severity of $Severity$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Category=ThreatManagement Name=\"eDiscovery search started or exported\" | stats count earliest(_time) as firstTime latest(_time) as lastTime by Source Severity AlertEntityId Operation Name |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` | `o365_pst_export_alert_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "PST export can be done for legitimate purposes but due to the sensitive nature of its content it must be monitored.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1114/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_pst_export_alert_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 PST export alert:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114/o365_export_pst_file/o365_export_pst_file.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114/o365_export_pst_file/o365_export_pst_file.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Service Principal New Client Credentials", "author": "Mauricio Velazco, Splunk", "date": "2023-08-31", "version": 1, "id": "a1b229e9-d962-4222-8c62-905a8a010453", "description": "The following analytic identifies the addition of new credentials for Service Principals in addition to existing legitimate credentials within a Office 365 tenant. These credentials include both x509 certificates and passwords. It leverages O365 audit logs, specifically events related to credential modifications or additions within the AzureActiveDirectory workload for service principals. Service principals represent application identities in Office 365 / AzureAD, and their credentials allow applications to authenticate and access resources. Adding new credentials or modifying existing ones can be an indication of configuration changes, but it can also be a sign of malicious intent If an attacker successfully adds or modifies credentials for a service principal, they can potentially use those credentials to authenticate as the application, gaining access to resources and data the application is permitted to access. This can lead to unauthorized data access, data exfiltration, or malicious operations performed under the guise of the application", "tags": {"name": "O365 Service Principal New Client Credentials", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.001"], "nist": ["DE.CM"], "observable": [{"name": "object", "type": "User", "role": ["Victim"]}, {"name": "user", "type": "User", "role": ["Attacker"]}], "message": "New credentials added for Service Principal $object$", "risk_score": 35, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_management_activity` Workload=AzureActiveDirectory Operation=\"Update application*Certificates and secrets management \" |  stats earliest(_time) as firstTime latest(_time) as lastTime by user ModifiedProperties{}.NewValue object ObjectId | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | `o365_service_principal_new_client_credentials_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Service Principal client credential modifications may be part of legitimate administrative operations. Filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/001/", "https://www.mandiant.com/resources/blog/remediation-and-hardening-strategies-for-microsoft-365-to-defend-against-unc2452", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT501/AZT501-2/", "https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/Methodology%20and%20Resources/Cloud%20-%20Azure%20Pentest.md#add-credentials-to-all-enterprise-applications"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_service_principal_new_client_credentials_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Service Principal New Client Credentials:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.001/o365_service_principal_credentials/o365_service_principal_credentials.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.001/o365_service_principal_credentials/o365_service_principal_credentials.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Suspicious Admin Email Forwarding", "author": "Patrick Bareiss, Splunk", "date": "2020-12-16", "version": 1, "id": "7f398cfb-918d-41f4-8db8-2e2474e02c28", "description": "This search detects when an admin configured a forwarding rule for multiple mailboxes to the same destination.", "tags": {"name": "O365 Suspicious Admin Email Forwarding", "analytic_story": ["Office 365 Collection Techniques", "Data Exfiltration"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.003", "T1114"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ has configured a forwarding rule for multiple mailboxes to the same destination $ForwardingAddress$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=Set-Mailbox | spath input=Parameters | rename Identity AS src_user | search ForwardingAddress=* | stats dc(src_user) AS count_src_user earliest(_time) as firstTime latest(_time) as lastTime values(src_user) AS src_user values(user) AS user by ForwardingAddress | where count_src_user > 1 |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`o365_suspicious_admin_email_forwarding_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "unknown", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_suspicious_admin_email_forwarding_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Suspicious Admin Email Forwarding:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.003/o365_mailbox_forwarding_enabled/o365_mailbox_forwarding_enabled.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.003/o365_mailbox_forwarding_enabled/o365_mailbox_forwarding_enabled.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Suspicious Rights Delegation", "author": "Patrick Bareiss, Mauricio Velazco, Splunk", "date": "2020-12-15", "version": 2, "id": "b25d2973-303e-47c8-bacd-52b61604c6a7", "description": "This analytic identifies instances where potentially suspicious rights are delegated within the Office 365 environment. Specifically, it detects when a user is granted FullAccess, SendAs, or SendOnBehalf permissions on another user's mailbox. Such permissions can allow a user to access, send emails from, or send emails on behalf of the target mailbox. The detection leverages O365 audit logs, focusing on the Add-MailboxPermission operation. By parsing the parameters of this operation, the analytic filters for events where FullAccess, SendAs, or SendOnBehalf rights are granted. It then aggregates this data to capture the source user (who was granted the permissions), the destination user (whose mailbox was affected), the specific operation, and the type of access rights granted. Delegating mailbox rights, especially those as powerful as FullAccess, can pose significant security risks. While there are legitimate scenarios for these permissions, such as an executive assistant needing access to an executive's mailbox, there are also malicious scenarios where an attacker or a compromised insider might grant themselves unauthorized access to sensitive mailboxes. Monitoring for these permissions changes is crucial to detect potential insider threats, compromised accounts, or other malicious activities.If the detection is a true positive, it indicates that a user has been granted potentially high-risk permissions on another user's mailbox. This could lead to unauthorized access to sensitive emails, impersonation through sending emails as or on behalf of the mailbox owner, or data manipulation by altering or deleting emails. Immediate investigation is required to validate the legitimacy of the permission change and to assess the potential risks associated with the granted access.", "tags": {"name": "O365 Suspicious Rights Delegation", "analytic_story": ["Office 365 Collection Techniques"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.002", "T1114", "T1098.002", "T1098"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "User $user$ has delegated suspicious rights $AccessRights$ to user $dest_user$ that allow access to sensitive", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=Add-MailboxPermission | spath input=Parameters | rename User AS src_user, Identity AS dest_user | search AccessRights=FullAccess OR AccessRights=SendAs OR AccessRights=SendOnBehalf | stats count earliest(_time) as firstTime latest(_time) as lastTime by user src_user dest_user Operation AccessRights |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`o365_suspicious_rights_delegation_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "While there are legitimate scenarios for these permissions, such as an executive assistant needing access to an executive's mailbox, there are also malicious scenarios. Investigate and filter as needed.", "check_references": false, "references": ["https://www.mandiant.com/resources/blog/remediation-and-hardening-strategies-for-microsoft-365-to-defend-against-unc2452", "https://attack.mitre.org/techniques/T1098/002/", "https://attack.mitre.org/techniques/T1114/002/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_suspicious_rights_delegation_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Suspicious Rights Delegation:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/suspicious_rights_delegation/suspicious_rights_delegation.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.002/suspicious_rights_delegation/suspicious_rights_delegation.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Suspicious User Email Forwarding", "author": "Patrick Bareiss, Splunk", "date": "2020-12-16", "version": 1, "id": "f8dfe015-dbb3-4569-ba75-b13787e06aa4", "description": "The following analytic detects when multiple users have configured a forwarding rule to the same destination to proactively identify and investigate potential security risks related to email forwarding and take appropriate actions to protect the organization's data and prevent unauthorized access or data breaches. This detection is made by a Splunk query to O365 management activity logs with the operation `Set-Mailbox` to gather information about mailbox configurations. Then, the query uses the `spath` function to extract the parameters and rename the \"Identity\" field as \"src_user\" and searches for entries where the \"ForwardingSmtpAddress\" field is not empty, which indicates the presence of a forwarding rule. Next, the analytic uses the `stats` command to group the results by the forwarding email address and count the number of unique source users (`src_user`). Finally, it filters the results and only retains entries where the count of source users (`count_src_user`) is greater than 1, which indicates that multiple users have set up forwarding rules to the same destination. This detection is important because it suggests that multiple users are forwarding emails to the same destination without proper authorization, which can lead to the exposure of sensitive information, loss of data control, or unauthorized access to confidential emails. Investigating and addressing this issue promptly can help prevent data breaches and mitigate potential damage.indicates a potential security risk since multiple users forwarding emails to the same destination can be a sign of unauthorized access, data exfiltration, or a compromised account. Additionally, it also helps to determine if the forwarding rules are legitimate or if they indicate a security incident. False positives can occur if there are legitimate reasons for multiple users to forward emails to the same destination, such as a shared mailbox or a team collaboration scenario. Next steps include further investigation and context analysis to determine the legitimacy of the forwarding rules.", "tags": {"name": "O365 Suspicious User Email Forwarding", "analytic_story": ["Office 365 Collection Techniques", "Data Exfiltration"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1114.003", "T1114"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}, {"name": "ForwardingSmtpAddress", "type": "Email Address", "role": ["Other"]}], "message": "User $user$ configured multiple users $src_user$ with a count of $count_src_user$, a forwarding rule to same destination $ForwardingSmtpAddress$", "risk_score": 48, "security_domain": "threat", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=Set-Mailbox | spath input=Parameters | rename Identity AS src_user | search ForwardingSmtpAddress=* | stats dc(src_user) AS count_src_user earliest(_time) as firstTime latest(_time) as lastTime values(src_user) AS src_user values(user) AS user by ForwardingSmtpAddress | where count_src_user > 1 |`security_content_ctime(firstTime)` |`security_content_ctime(lastTime)` |`o365_suspicious_user_email_forwarding_filter`", "how_to_implement": "You must install splunk Microsoft Office 365 add-on. This search works with o365:management:activity", "known_false_positives": "unknown", "check_references": false, "references": [], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_suspicious_user_email_forwarding_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Suspicious User Email Forwarding:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.003/o365_mailbox_forwarding_enabled/o365_mailbox_forwarding_enabled.json", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1114.003/o365_mailbox_forwarding_enabled/o365_mailbox_forwarding_enabled.json", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 Tenant Wide Admin Consent Granted", "author": "Mauricio Velazco, Splunk", "date": "2023-09-06", "version": 1, "id": "50eaabf8-5180-4e86-bfb2-011472c359fc", "description": "The following analytic identifies instances where admin consent is granted to an application within an Azure AD and Office 365 tenant. It leverages O365 audit logs, specifically events related to the admin consent action within the AzureActiveDirectory workload. The admin consent action allows applications to access data across the entire tenant, potentially encompassing a vast amount of organizational data. Given its broad scope and the sensitivity of some permissions that can only be granted via admin consent, it's crucial to monitor this action. Unauthorized or inadvertent granting of admin consent can lead to significant security risks, including data breaches, unauthorized data access, and potential compliance violations. If an attacker successfully tricks an administrator into granting admin consent to a malicious or compromised application, they can gain extensive and persistent access to organizational data. This can lead to data exfiltration, espionage, further malicious activities within the tenant, and potential breaches of compliance regulations", "tags": {"name": "O365 Tenant Wide Admin Consent Granted", "analytic_story": ["Office 365 Persistence Mechanisms", "NOBELIUM Group"], "asset_type": "Office 365", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1098", "T1098.003"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Attacker"]}], "message": "The $object$ application registration was granted tenant wide admin consent.", "risk_score": 45, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Operation=\"Consent to application.\"  | eval new_field=mvindex('ModifiedProperties{}.NewValue', 4) | rex field=new_field \"ConsentType: (?<ConsentType>[^\\,]+)\" | rex field=new_field \"Scope: (?<Scope>[^\\,]+)\"  | search  ConsentType = \"AllPrincipals\"  | stats count min(_time) as firstTime max(_time) as lastTime by Operation, user, object, ObjectId, ConsentType, Scope | `security_content_ctime(firstTime)`  | `security_content_ctime(lastTime)` | `o365_tenant_wide_admin_consent_granted_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Legitimate applications may be granted tenant wide consent, filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1098/003/", "https://www.mandiant.com/resources/blog/remediation-and-hardening-strategies-for-microsoft-365-to-defend-against-unc2452", "https://learn.microsoft.com/en-us/security/operations/incident-response-playbook-app-consent", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/grant-admin-consent?pivots=portal", "https://microsoft.github.io/Azure-Threat-Research-Matrix/Persistence/AZT501/AZT501-2/"], "datamodel": [], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_tenant_wide_admin_consent_granted_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 Tenant Wide Admin Consent Granted:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_admin_consent/o365_admin_consent.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1098.003/o365_admin_consent/o365_admin_consent.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 User Consent Blocked for Risky Application", "author": "Mauricio Velazco, Splunk", "date": "2023-10-11", "version": 1, "id": "242e4d30-cb59-4051-b0cf-58895e218f40", "description": "The following analytic identifies instances where Office 365 has blocked a user's attempt to grant consent to an application deemed risky or potentially malicious. This suggests that the application has exhibited behaviors or characteristics that are commonly associated with malicious intent or poses a security risk. This detection leverages the O365 audit logs, specifically focusing on events related to user consent actions and system-driven blocks. By filtering for blocked consent actions associated with applications, the analytic highlights instances where O365's built-in security measures have intervened. Applications that are flagged and blocked by O365 typically exhibit suspicious characteristics or behaviors. Monitoring for these blocked consent attempts helps security teams identify potential threats early on and can provide insights into users who might be targeted or susceptible to such risky applications. It's an essential layer of defense in ensuring that malicious or risky applications don't gain access to organizational data. If the detection is a true positive, it indicates that the built-in security measures of O365 successfully prevented a potentially harmful application from gaining access. However, the attempt itself suggests that either a user might be targeted or that there's a presence of malicious applications trying to infiltrate the organization. Immediate investigation is required to understand the context of the block and to take further preventive measures.", "tags": {"name": "O365 User Consent Blocked for Risky Application", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "O365 has blocked $user$ attempt to grant to consent to an application deemed risky.", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "`o365_management_activity` Workload=AzureActiveDirectory Operation=\"Consent to application.\" ResultStatus=Failure | eval permissions =mvindex('ModifiedProperties{}.NewValue', 4) | eval reason =mvindex('ModifiedProperties{}.NewValue', 5) |  search reason = \"Risky application detected\" | rex field=permissions \"Scope: (?<Scope>[^,]+)\" |  stats max(_time) as lastTime by Operation, user, reason, object, Scope | `security_content_ctime(lastTime)` | `o365_user_consent_blocked_for_risky_application_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 management activity events.", "known_false_positives": "Microsofts algorithm to identify risky applications is unknown and may flag legitimate applications.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/protect-against-consent-phishing", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": ["Risk"], "macros": [{"name": "o365_management_activity", "definition": "sourcetype=o365:management:activity", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_user_consent_blocked_for_risky_application_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 User Consent Blocked for Risky Application:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_blocked/o365_user_consent_blocked.log", "source": "o365", "sourcetype": "o365:management:activity"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_blocked/o365_user_consent_blocked.log", "source": "o365", "sourcetype": "o365:management:activity"}]}]}, {"name": "O365 User Consent Denied for OAuth Application", "author": "Mauricio Velazco, Splunk", "date": "2023-10-12", "version": 1, "id": "2d8679ef-b075-46be-8059-c25116cb1072", "description": "The following analytic identifies instances where a user has actively denied consent to an OAuth application seeking permissions within the Office 365 environment. This suggests that the user either recognized something suspicious about the application or chose not to grant it the requested permissions for other reasons. This detection leverages the O365 audit logs, specifically focusing on events related to user consent actions. By filtering for denied consent actions associated with OAuth applications, the analytic captures instances where users have actively rejected permission requests. While user-denied consents can be routine, they can also be indicative of users spotting potentially suspicious or unfamiliar applications. By monitoring these denied consent attempts, security teams can gain insights into applications that might be perceived as risky or untrusted by users. It can also serve as a feedback loop for security awareness training, indicating that users are being cautious about granting permissions. If the detection is a true positive, it indicates that a user has actively prevented an OAuth application from gaining the permissions it requested. While this is a proactive security measure on the user's part, it's essential for security teams to review the context of the denial. Understanding why certain applications are being denied can help in refining application whitelisting policies and ensuring that no malicious applications are attempting to gain access.", "tags": {"name": "O365 User Consent Denied for OAuth Application", "analytic_story": ["Office 365 Account Takeover"], "asset_type": "Office 365 tenant", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1528"], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "src_ip", "type": "IP Address", "role": ["Attacker"]}], "message": "User $user$ denifed consent for an OAuth application.", "risk_score": 30, "security_domain": "identity", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": " `o365_graph` status.errorCode=65004 | rename userPrincipalName as user | rename ipAddress as src_ip | stats max(_time) as lastTime by user src_ip appDisplayName status.failureReason | `security_content_ctime(lastTime)` | `o365_user_consent_denied_for_oauth_application_filter`", "how_to_implement": "You must install the Splunk Microsoft Office 365 Add-on and ingest Office 365 events.", "known_false_positives": "OAuth applications that require mail permissions may be legitimate, investigate and filter as needed.", "check_references": false, "references": ["https://attack.mitre.org/techniques/T1528/", "https://www.microsoft.com/en-us/security/blog/2022/09/22/malicious-oauth-applications-used-to-compromise-email-servers-and-spread-spam/", "https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/protect-against-consent-phishing", "https://learn.microsoft.com/en-us/defender-cloud-apps/investigate-risky-oauth", "https://www.alteredsecurity.com/post/introduction-to-365-stealer", "https://github.com/AlteredSecurity/365-Stealer"], "datamodel": [], "macros": [{"name": "o365_graph", "definition": "sourcetype=o365:graph:api", "description": "customer specific splunk configurations(eg- index, source, sourcetype). Replace the macro definition with configurations for your Splunk Environmnent."}, {"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "o365_user_consent_denied_for_oauth_application_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "providing_technologies": ["Microsoft Office 365"], "enabled_by_default": false, "test_groups": [{"name": "O365 User Consent Denied for OAuth Application:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_declined/o365_user_consent_declined.log", "source": "o365", "sourcetype": "o365:graph:api"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1528/o365_user_consent_declined/o365_user_consent_declined.log", "source": "o365", "sourcetype": "o365:graph:api"}]}]}, {"name": "Risk Rule for Dev Sec Ops by Repository", "author": "Bhavin Patel", "date": "2023-10-27", "version": 1, "id": "161bc0ca-4651-4c13-9c27-27770660cf67", "description": "The following analytic detects by correlating repository and risk score to identify patterns and trends in the data based on the level of risk associated. The analytic adds any null values and calculates the sum of the risk scores for each detection. Then, the analytic captures the source and user information for each detection and sorts the results in ascending order based on the risk score. Finally, the analytic filters the detections with a risk score below 80 and focuses only on high-risk detections.This detection is important because it provides valuable insights into the distribution of high-risk activities across different repositories. It also identifies the most vulnerable repositories that are frequently targeted by potential threats. Additionally, it proactively detects and responds to potential threats, thereby minimizing the impact of attacks and safeguarding critical assets. Finally, it provides a comprehensive view of the risk landscape and helps to make informed decisions to protect the organization's data and infrastructure. False positives might occur so it is important to identify the impact of the attack and prioritize response and mitigation efforts.", "tags": {"name": "Risk Rule for Dev Sec Ops by Repository", "analytic_story": ["Dev Sec Ops"], "asset_type": "Amazon Elastic Container Registry", "cis20": ["CIS 10"], "kill_chain_phases": [], "mitre_attack_id": ["T1204.003", "T1204"], "nist": ["DE.AE"], "observable": [{"name": "risk_object", "type": "Other", "role": ["Victim"]}], "message": "Correlation triggered for repository $risk_object$", "risk_score": 70, "security_domain": "cloud", "risk_severity": "medium", "mitre_attack_enrichments": []}, "search": "| tstats `security_content_summariesonly` min(_time) as firstTime max(_time) as lastTime sum(All_Risk.calculated_risk_score) as sum_risk_score, values(All_Risk.annotations.mitre_attack.mitre_tactic) as annotations.mitre_attack.mitre_tactic, values(All_Risk.annotations.mitre_attack.mitre_technique_id) as annotations.mitre_attack.mitre_technique_id, dc(All_Risk.annotations.mitre_attack.mitre_technique_id) as mitre_technique_id_count values(source) as source, dc(source) as source_count from datamodel=Risk.All_Risk where All_Risk.analyticstories=\"Dev Sec Ops\" All_Risk.risk_object_type = \"other\" by All_Risk.risk_object All_Risk.risk_object_type All_Risk.annotations.mitre_attack.mitre_tactic | `drop_dm_object_name(All_Risk)` | `security_content_ctime(firstTime)` | `security_content_ctime(lastTime)` | where source_count > 3 and sum_risk_score > 100 | `risk_rule_for_dev_sec_ops_by_repository_filter`", "how_to_implement": "Ensure that all relevant detections in the Dev Sec Ops analytic stories are enabled and are configured to create risk events in Enterprise Security.", "known_false_positives": "Unknown", "check_references": false, "references": [], "datamodel": ["Risk"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "security_content_summariesonly", "definition": "summariesonly=false allow_old_summaries=true fillnull_value=null", "description": "search data model's summaries only"}, {"name": "risk_rule_for_dev_sec_ops_by_repository_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "cloud", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": [{"name": "Risk Rule for Dev Sec Ops by Repository:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://raw.githubusercontent.com/splunk/attack_data/master/datasets/attack_techniques/T1204.003/risk_dataset/aws_ecr_risk_dataset.log", "source": "aws_ecr_risk_dataset.log", "sourcetype": "stash"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://raw.githubusercontent.com/splunk/attack_data/master/datasets/attack_techniques/T1204.003/risk_dataset/aws_ecr_risk_dataset.log", "source": "aws_ecr_risk_dataset.log", "sourcetype": "stash"}]}]}]}