{"detections": [{"name": "Testing123", "author": "Bhavin Patel, Splunk", "date": "2017-09-12", "version": 1, "id": "7b26f1a3-72d6-4e28-a8bf-5cf25d02a3a9", "description": "The search queries the authentication logs for assets that are categorized as routers in the ES Assets and Identity Framework, to identify connections that have not been seen before in the last 30 days.", "tags": {"name": "Detect New Login Attempts to Routers", "analytic_story": ["Router and Infrastructure Security"], "asset_type": "Endpoint", "cis20": ["CIS 13"], "kill_chain_phases": [], "nist": ["DE.CM"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}, {"name": "dest", "type": "Hostname", "role": ["Victim"]}], "message": "tbd", "risk_score": 25, "security_domain": "network", "risk_severity": "low", "mitre_attack_enrichments": []}, "search": "| tstats `security_content_summariesonly` count earliest(_time) as earliest latest(_time) as latest from datamodel=Authentication where Authentication.dest_category=router by Authentication.dest Authentication.user| eval isOutlier=if(earliest >= relative_time(now(), \"-30d@d\"), 1, 0) | where isOutlier=1| `security_content_ctime(earliest)`| `security_content_ctime(latest)` | `drop_dm_object_name(\"Authentication\")` | `detect_new_login_attempts_to_routers_filter`", "how_to_implement": "To successfully implement this search, you must ensure the network router devices are categorized as \"router\" in the Assets and identity table. You must also populate the Authentication data model with logs related to users authenticating to routing infrastructure.", "known_false_positives": "Legitimate router connections may appear as new connections", "check_references": false, "references": [], "datamodel": ["Authentication"], "macros": [{"name": "security_content_ctime", "definition": "convert timeformat=\"%Y-%m-%dT%H:%M:%S\" ctime($field$)", "description": "convert epoch time to string", "arguments": ["field"]}, {"name": "security_content_summariesonly", "definition": "summariesonly=false allow_old_summaries=true fillnull_value=null", "description": "search data model's summaries only"}, {"name": "detect_new_login_attempts_to_routers_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "application", "nes_fields": "user,dest", "enabled_by_default": false, "test_groups": []}, {"name": "Testi_1ng123", "author": "Abhinav Mishra, Kumar Sharad, Namratha Sreekanta and Xiao Lin, Splunk", "date": "2022-06-16", "version": 1, "id": "bfa4f662-8755-4f7e-b07f-19d0842f7b4d", "description": "The following analytic uses a pretrained machine learning text classifier to detect potentially risky commands. The model is trained independently and then the model file is packaged within ESCU for usage. A command is deemed risky based on the presence of certain trigger keywords, along with the context and the role of the user (please see references). The model uses custom features to predict whether a SPL is risky using text classification. The model takes as input the command text, user and search type and outputs a risk score between [0,1]. A high score indicates higher likelihood of a command being risky. This model is on-prem only.", "tags": {"name": "Detect Risky SPL using Pretrained ML Model", "analytic_story": ["Splunk Vulnerabilities"], "asset_type": "Web Server", "cis20": ["CIS 10"], "kill_chain_phases": ["Installation"], "mitre_attack_id": ["T1059"], "nist": ["DE.AE"], "observable": [{"name": "user", "type": "User", "role": ["Victim"]}], "message": "A potentially risky Splunk command has been run by $user$, kindly review.", "risk_score": 20, "security_domain": "audit", "risk_severity": "low", "mitre_attack_enrichments": [{"mitre_attack_id": "T1059", "mitre_attack_technique": "Command and Scripting Interpreter", "mitre_attack_tactics": ["Execution"], "mitre_attack_groups": ["APT19", "APT32", "APT37", "APT39", "Dragonfly", "FIN5", "FIN6", "FIN7", "Fox Kitten", "Ke3chang", "OilRig", "Stealth Falcon", "Whitefly", "Windigo"]}]}, "search": "| tstats `security_content_summariesonly` count min(_time) as firstTime max(_time) as lastTime from datamodel=Splunk_Audit.Search_Activity where Search_Activity.search_type=adhoc Search_Activity.user!=splunk-system-user by Search_Activity.search Search_Activity.user Search_Activity.search_type | eval spl_text = 'Search_Activity.search'. \" \" .'Search_Activity.user'. \" \" .'Search_Activity.search_type'| dedup spl_text | apply risky_spl_pre_trained_model | where risk_score > 0.5 | `drop_dm_object_name(Search_Activity)` | table search, user, search_type, risk_score | `detect_risky_spl_using_pretrained_ml_model_filter`", "how_to_implement": "This detection depends on the MLTK app which can be found here - https://splunkbase.splunk.com/app/2890/ and the Splunk Audit datamodel which can be found here - https://splunkbase.splunk.com/app/1621/. Additionally, you need to be ingesting logs which include Search_Activity.search, Search_Activity.user, Search_Activity.search_type from your endpoints. The risk score threshold should be adjusted based on the environment. The detection uses a custom MLTK model hence we need a few more steps for deployment, as outlined here - https://gist.github.com/ksharad-splunk/be2a62227966049047f5e5c4f2adcabb.", "known_false_positives": "False positives may be present if suspicious behavior is observed, as determined by frequent usage of risky keywords.", "check_references": false, "references": ["https://docs.splunk.com/Documentation/Splunk/latest/Security/SPLsafeguards#Commands_that_trigger_the_warning"], "datamodel": ["Splunk_Audit"], "macros": [{"name": "security_content_summariesonly", "definition": "summariesonly=false allow_old_summaries=true fillnull_value=null", "description": "search data model's summaries only"}, {"name": "detect_risky_spl_using_pretrained_ml_model_filter", "definition": "search *", "description": "Update this macro to limit the output results to filter out false positives."}], "lookups": [], "source": "application", "enabled_by_default": false, "test_groups": [{"name": "Detect Risky SPL using Pretrained ML Model:True Positive Test", "unit_test": {"name": "True Positive Test", "test_type": "unit", "baselines": [], "attack_data": [{"data": "https://github.com/splunk/attack_data/raw/master/datasets/attack_techniques/T1203/search_activity.txt", "source": "audittrail", "sourcetype": "audittrail", "update_timestamp": true, "custom_index": "_audit"}]}, "integration_test": {"name": "True Positive Test", "test_type": "integration"}, "attack_data": [{"data": "https://github.com/splunk/attack_data/raw/master/datasets/attack_techniques/T1203/search_activity.txt", "source": "audittrail", "sourcetype": "audittrail", "update_timestamp": true, "custom_index": "_audit"}]}]}]}
